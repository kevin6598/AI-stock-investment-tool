{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Market Quantitative Research Pipeline — v3 TEST\n",
    "## US-only, 18 tickers, reduced params — Dataset Diversity Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "_RESTART_FLAG = \"/tmp/_quant_v3_restarted\"\n",
    "\n",
    "if not os.path.exists(_RESTART_FLAG):\n",
    "    # First run: install everything, then force restart\n",
    "    os.system(\"pip install -q --upgrade numpy pandas scipy scikit-learn\")\n",
    "    os.system(\"pip install -q yfinance matplotlib pyarrow joblib pykrx finance-datareader statsmodels\")\n",
    "    open(_RESTART_FLAG, \"w\").write(\"done\")\n",
    "    print(\"Packages installed. Restarting runtime to pick up new binaries...\")\n",
    "    os.kill(os.getpid(), 9)  # force kernel restart\n",
    "else:\n",
    "    print(\"Packages already installed, runtime already restarted. Continuing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, gc, logging, warnings\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Central configuration — v3 with 20+ parameter groups.\"\"\"\n",
    "\n",
    "    # --- 1. Markets ---\n",
    "    markets: List[str] = field(default_factory=lambda: [\"US\", \"KOSPI\", \"KOSDAQ\"])\n",
    "    base_currency: str = \"USD\"\n",
    "    apply_fx_conversion: bool = True\n",
    "    us_tickers: List[str] = field(default_factory=lambda: [\n",
    "        \"AAPL\",\"MSFT\",\"GOOGL\",\"AMZN\",\"NVDA\",\"META\",\"TSLA\",\"BRK-B\",\n",
    "        \"JPM\",\"JNJ\",\"V\",\"PG\",\"UNH\",\"HD\",\"MA\",\"DIS\",\"BAC\",\"NFLX\",\n",
    "        \"ADBE\",\"CRM\",\"XOM\",\"VZ\",\"KO\",\"INTC\",\"PEP\",\"ABT\",\"CSCO\",\n",
    "        \"COST\",\"MRK\",\"WMT\",\"AVGO\",\"ACN\",\"CVX\",\"NKE\",\"LLY\",\"MCD\",\n",
    "        \"QCOM\",\"UPS\",\"BMY\",\"LIN\",\"NEE\",\"ORCL\",\"RTX\",\"HON\",\"TXN\",\n",
    "        \"AMD\",\"PYPL\",\"CMCSA\",\"TMO\",\"DHR\",\n",
    "    ])\n",
    "    kospi_tickers: List[str] = field(default_factory=lambda: [\n",
    "        \"005930\",\"000660\",\"373220\",\"207940\",\"005380\",\"000270\",\n",
    "        \"035420\",\"006400\",\"105560\",\"051910\",\"005490\",\"034730\",\n",
    "        \"068270\",\"055550\",\"035720\",\"086790\",\"012330\",\"003550\",\n",
    "        \"028260\",\"033780\",\"000810\",\"032830\",\"017670\",\"010950\",\n",
    "        \"316140\",\"066570\",\"009150\",\"018260\",\"011200\",\"034020\",\n",
    "    ])\n",
    "    kosdaq_tickers: List[str] = field(default_factory=lambda: [\n",
    "        \"247540\",\"086520\",\"028300\",\"196170\",\"403870\",\"035900\",\n",
    "        \"263750\",\"293490\",\"053800\",\"112040\",\"041510\",\"145020\",\n",
    "        \"257720\",\"036930\",\"058470\",\"950160\",\"383310\",\"322000\",\n",
    "        \"214150\",\"108320\",\n",
    "    ])\n",
    "    market_index: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"US\": \"SPY\", \"KOSPI\": \"^KS11\", \"KOSDAQ\": \"^KQ11\",\n",
    "    })\n",
    "\n",
    "    # --- 2. Dynamic Universe ---\n",
    "    use_dynamic_universe: bool = True\n",
    "    rebuild_universe_each_fold: bool = False\n",
    "    min_avg_volume: float = 100000\n",
    "    max_universe_size: int = 50\n",
    "\n",
    "    # --- 3. Features ---\n",
    "    momentum_windows: List[int] = field(default_factory=lambda: [5, 20, 60, 120])\n",
    "    volatility_windows: List[int] = field(default_factory=lambda: [20, 60])\n",
    "    regime_window: int = 60\n",
    "    adaptive_quantiles: bool = True\n",
    "    min_bin_size: int = 20\n",
    "\n",
    "    # --- 4. Forward Returns ---\n",
    "    forward_days_list: List[int] = field(default_factory=lambda: [5, 21, 63])\n",
    "\n",
    "    # --- 5. Tri-state Labeling (NEW v3) ---\n",
    "    tristate_thresholds_pct: Dict[int, float] = field(default_factory=lambda: {\n",
    "        5: 0.5, 21: 1.0, 63: 2.0,\n",
    "    })\n",
    "\n",
    "    # --- 6. Candidates ---\n",
    "    max_candidates_total: int = 3000\n",
    "    max_candidates_per_feature_pair: int = 200\n",
    "    min_sample_size: int = 300\n",
    "\n",
    "    # --- 7. Trees ---\n",
    "    n_trees: int = 20\n",
    "    tree_feature_subsample: float = 0.5\n",
    "    tree_max_depth: int = 2\n",
    "    tree_min_samples_leaf: int = 500\n",
    "\n",
    "    # --- 8. Walk-Forward ---\n",
    "    wf_train_years: int = 3\n",
    "    wf_test_months: int = 12\n",
    "    wf_step_months: int = 6\n",
    "    wf_embargo_days: int = 5\n",
    "    wf_min_folds: int = 4\n",
    "\n",
    "    # --- 9. Overfitting ---\n",
    "    min_stability: float = 0.5\n",
    "    min_sharpe: float = 0.5\n",
    "    min_win_rate: float = 0.52\n",
    "\n",
    "    # --- 10. Conditional Metrics (NEW v3) ---\n",
    "    min_precision_buy: float = 0.60\n",
    "    min_ev_per_trade: float = 0.0\n",
    "    max_cvar_to_avgwin_ratio: float = 3.0\n",
    "    max_single_loss_to_median_ratio: float = 5.0\n",
    "\n",
    "    # --- 11. Bootstrap ---\n",
    "    bootstrap_n: int = 1000\n",
    "    bootstrap_ci: float = 0.95\n",
    "    bootstrap_min_samples: int = 200\n",
    "\n",
    "    # --- 12. Transaction Costs ---\n",
    "    transaction_cost_bps: float = 5.0\n",
    "    slippage_bps: float = 2.0\n",
    "    cost_stress_scenarios: List[Tuple[float, float]] = field(default_factory=lambda: [\n",
    "        (5, 2), (10, 5), (15, 5),\n",
    "    ])\n",
    "    min_cost_scenarios_survived: int = 2\n",
    "\n",
    "    # --- 13. Turnover ---\n",
    "    penalty_turnover: float = 0.1\n",
    "    max_turnover: float = 12.0\n",
    "\n",
    "    # --- 14. Correlation / De-duplication ---\n",
    "    max_strategy_correlation: float = 0.85\n",
    "    cluster_strategies: bool = True\n",
    "    signal_overlap_threshold: float = 0.80\n",
    "\n",
    "    # --- 15. Portfolio ---\n",
    "    portfolio_max_strategies: int = 10\n",
    "    portfolio_weight_method: str = \"equal\"\n",
    "    max_strategy_risk_budget_pct: float = 30.0\n",
    "\n",
    "    # --- 16. Regime ---\n",
    "    evaluate_by_regime: bool = True\n",
    "    min_regime_performance_ratio: float = 0.7\n",
    "\n",
    "    # --- 17. Multiple Testing ---\n",
    "    apply_multiple_testing_correction: bool = True\n",
    "    mtc_method: str = \"fdr\"\n",
    "\n",
    "    # --- 18. Meta-Model (NEW v3) ---\n",
    "    use_meta_model: bool = True\n",
    "    meta_model_threshold: float = 0.50\n",
    "\n",
    "    # --- 19. Bayesian Auto Rule Tuning (NEW v3) ---\n",
    "    use_bayesian_tuning: bool = True\n",
    "    n_bayes_iterations: int = 200\n",
    "\n",
    "    # --- 20. Memory ---\n",
    "    use_float32: bool = True\n",
    "    gc_every_n_candidates: int = 100\n",
    "\n",
    "    # --- 21. Data Module Flags ---\n",
    "    enable_liquidity_features: bool = True\n",
    "    enable_fundamental_features: bool = True\n",
    "    enable_macro_features: bool = True\n",
    "    enable_sector_features: bool = True\n",
    "    enable_sentiment_proxy: bool = False  # optional, off by default\n",
    "\n",
    "    # --- 22. Axis A: Liquidity ---\n",
    "    liquidity_dollar_vol_windows: List[int] = field(default_factory=lambda: [20, 60])\n",
    "    amihud_window: int = 60\n",
    "\n",
    "    # --- 23. Axis C: Macro ---\n",
    "    macro_tickers: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"tnx\": \"^TNX\", \"irx\": \"^IRX\", \"vix\": \"^VIX\",\n",
    "        \"gold\": \"GC=F\", \"oil\": \"CL=F\", \"dxy\": \"DX-Y.NYB\",\n",
    "    })\n",
    "    macro_veto_vix_multiple: float = 2.0\n",
    "\n",
    "    # --- 24. Axis B: Fundamentals ---\n",
    "    fundamental_fields: List[str] = field(default_factory=lambda: [\n",
    "        \"marketCap\", \"trailingPE\", \"priceToBook\",\n",
    "        \"returnOnEquity\", \"returnOnAssets\", \"revenueGrowth\", \"earningsGrowth\",\n",
    "    ])\n",
    "\n",
    "    # --- Scoring weights ---\n",
    "    w_stability: float = 0.25\n",
    "    w_sharpe: float = 0.25\n",
    "    w_precision: float = 0.20\n",
    "    w_lift: float = 0.15\n",
    "    w_sample: float = 0.15\n",
    "\n",
    "    # --- Paths ---\n",
    "    drive_root: str = \"/content/drive/MyDrive/quant_pipeline_v3\"\n",
    "    data_period: str = \"10y\"\n",
    "    seed: int = 42\n",
    "    logistic_top_pct: float = 0.20\n",
    "\n",
    "    def data_dir(self, m): return os.path.join(self.drive_root, \"data\", m)\n",
    "    def features_dir(self, m): return os.path.join(self.drive_root, \"features\", m)\n",
    "    def candidates_dir(self, m): return os.path.join(self.drive_root, \"candidates\", m)\n",
    "    def evaluation_dir(self, m): return os.path.join(self.drive_root, \"evaluation\", m)\n",
    "    def walkforward_dir(self, m): return os.path.join(self.drive_root, \"walkforward\", m)\n",
    "    @property\n",
    "    def global_eval_dir(self): return os.path.join(self.drive_root, \"evaluation\", \"_global\")\n",
    "    @property\n",
    "    def logs_dir(self): return os.path.join(self.drive_root, \"logs\")\n",
    "    @property\n",
    "    def state_path(self): return os.path.join(self.drive_root, \"state.json\")\n",
    "    @property\n",
    "    def total_cost_bps(self): return self.transaction_cost_bps + self.slippage_bps\n",
    "\n",
    "\n",
    "CFG = PipelineConfig()\n",
    "print(\"Config v3 created.  Root:\", CFG.drive_root)\n",
    "print(\"Markets:\", CFG.markets, \"| Horizons:\", CFG.forward_days_list)\n",
    "print(\"Tri-state thresholds:\", CFG.tristate_thresholds_pct)\n",
    "print(\"Cost stress scenarios:\", CFG.cost_stress_scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST OVERRIDES: US-only, 18 tickers, reduced params ===\n",
    "CFG.markets = [\"US\"]\n",
    "CFG.us_tickers = [\n",
    "    \"AAPL\",\"MSFT\",\"GOOGL\",\"AMZN\",\"NVDA\",\"META\",\"TSLA\",\"BRK-B\",\"JPM\",\n",
    "    \"JNJ\",\"V\",\"PG\",\"UNH\",\"HD\",\"MA\",\"DIS\",\"BAC\",\"NFLX\",\n",
    "]\n",
    "CFG.max_universe_size = 18\n",
    "CFG.data_period = \"5y\"\n",
    "CFG.forward_days_list = [21]\n",
    "CFG.tristate_thresholds_pct = {21: 1.0}\n",
    "CFG.n_trees = 10\n",
    "CFG.max_candidates_total = 500\n",
    "CFG.max_candidates_per_feature_pair = 50\n",
    "CFG.min_sample_size = 100\n",
    "CFG.tree_min_samples_leaf = 200\n",
    "CFG.wf_train_years = 2\n",
    "CFG.wf_test_months = 12\n",
    "CFG.wf_min_folds = 2\n",
    "CFG.bootstrap_n = 200\n",
    "CFG.n_bayes_iterations = 50\n",
    "CFG.enable_sentiment_proxy = True  # test all axes\n",
    "CFG.drive_root = \"/tmp/quant_pipeline_v3_test\"\n",
    "print(\"TEST CONFIG: US-only, 18 tickers, 1 horizon, reduced params\")\n",
    "print(\"Markets:\", CFG.markets)\n",
    "print(\"Tickers:\", len(CFG.us_tickers))\n",
    "print(\"Horizons:\", CFG.forward_days_list)\n",
    "print(\"All 5 axes enabled:\", all([\n",
    "    CFG.enable_liquidity_features, CFG.enable_fundamental_features,\n",
    "    CFG.enable_macro_features, CFG.enable_sector_features,\n",
    "    CFG.enable_sentiment_proxy]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persistence & Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVE_MOUNTED = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', timeout_ms=60000)\n",
    "    DRIVE_MOUNTED = True\n",
    "    print(\"Google Drive mounted.\")\n",
    "except Exception as e:\n",
    "    print(\"Drive mount failed: %s\" % str(e)[:80])\n",
    "    if CFG.drive_root.startswith(\"/content/drive\"):\n",
    "        CFG.drive_root = \"/tmp/quant_pipeline_v3\"\n",
    "\n",
    "for mkt in CFG.markets:\n",
    "    for d in [CFG.data_dir(mkt), CFG.features_dir(mkt), CFG.candidates_dir(mkt),\n",
    "              CFG.evaluation_dir(mkt), CFG.walkforward_dir(mkt)]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "os.makedirs(CFG.global_eval_dir, exist_ok=True)\n",
    "os.makedirs(CFG.logs_dir, exist_ok=True)\n",
    "print(\"Directories ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressTracker:\n",
    "    \"\"\"JSON checkpoint system for resumable execution.\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.state_path = path\n",
    "        self.state = self._load()\n",
    "    def _load(self):\n",
    "        if os.path.exists(self.state_path):\n",
    "            with open(self.state_path) as f: return json.load(f)\n",
    "        return {\"completed_steps\": {}, \"metadata\": {}}\n",
    "    def _save(self):\n",
    "        with open(self.state_path, 'w') as f: json.dump(self.state, f, indent=2, default=str)\n",
    "    def is_completed(self, step): return self.state[\"completed_steps\"].get(step, False)\n",
    "    def mark_completed(self, step, meta=None):\n",
    "        self.state[\"completed_steps\"][step] = True\n",
    "        if meta: self.state[\"metadata\"][step] = meta\n",
    "        self._save()\n",
    "        print(\"  [CHECKPOINT] %s\" % step)\n",
    "    def get_metadata(self, step): return self.state[\"metadata\"].get(step, {})\n",
    "    def reset(self, step=None):\n",
    "        if step:\n",
    "            self.state[\"completed_steps\"].pop(step, None)\n",
    "            self.state[\"metadata\"].pop(step, None)\n",
    "        else:\n",
    "            self.state = {\"completed_steps\": {}, \"metadata\": {}}\n",
    "        self._save()\n",
    "    def summary(self):\n",
    "        done = [k for k,v in self.state[\"completed_steps\"].items() if v]\n",
    "        print(\"=== Progress (%d steps done) ===\" % len(done))\n",
    "        for s in done: print(\"  [DONE] %s\" % s)\n",
    "\n",
    "tracker = ProgressTracker(CFG.state_path)\n",
    "tracker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log_file = os.path.join(CFG.logs_dir, \"pipeline.log\")\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "                    datefmt=\"%H:%M:%S\",\n",
    "                    handlers=[logging.StreamHandler(), logging.FileHandler(log_file, mode='a')])\n",
    "logger = logging.getLogger(\"pipeline\")\n",
    "logger.info(\"Pipeline v3 started\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Market Configuration & Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET_REGISTRY = {\n",
    "    \"US\":    {\"data_source\": \"yfinance\", \"index_ticker\": \"SPY\",   \"currency\": \"USD\", \"pykrx_market\": None},\n",
    "    \"KOSPI\": {\"data_source\": \"pykrx\",   \"index_ticker\": \"^KS11\", \"currency\": \"KRW\", \"pykrx_market\": \"KOSPI\"},\n",
    "    \"KOSDAQ\":{\"data_source\": \"pykrx\",   \"index_ticker\": \"^KQ11\", \"currency\": \"KRW\", \"pykrx_market\": \"KOSDAQ\"},\n",
    "}\n",
    "\n",
    "def get_static_tickers(market):\n",
    "    return {\"US\": list(CFG.us_tickers), \"KOSPI\": list(CFG.kospi_tickers),\n",
    "            \"KOSDAQ\": list(CFG.kosdaq_tickers)}.get(market, [])\n",
    "\n",
    "def download_fx_rates(period=\"10y\"):\n",
    "    import yfinance as yf\n",
    "    try:\n",
    "        fx = yf.download(\"USDKRW=X\", period=period, progress=False, auto_adjust=True)\n",
    "        if isinstance(fx.columns, pd.MultiIndex): fx.columns = fx.columns.get_level_values(0)\n",
    "        fx = fx[[\"Close\"]].copy(); fx.columns = [\"usdkrw\"]\n",
    "        fx.index = pd.to_datetime(fx.index).tz_localize(None)\n",
    "        return fx\n",
    "    except: return pd.DataFrame(columns=[\"usdkrw\"])\n",
    "\n",
    "def convert_krw_to_usd(df, fx):\n",
    "    if fx.empty: return df\n",
    "    fx_al = fx[\"usdkrw\"].reindex(df.index.get_level_values(0), method=\"ffill\")\n",
    "    fx_al.index = df.index\n",
    "    for c in [\"open\",\"high\",\"low\",\"close\"]:\n",
    "        if c in df.columns: df[c] = df[c] / fx_al\n",
    "    return df\n",
    "\n",
    "print(\"Market registry ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_universe(market, ref_date=None, config=None):\n",
    "    \"\"\"Point-in-time ticker universe.\"\"\"\n",
    "    if config is None: config = CFG\n",
    "    reg = MARKET_REGISTRY[market]\n",
    "    if reg[\"data_source\"] == \"pykrx\" and config.use_dynamic_universe:\n",
    "        try:\n",
    "            from pykrx import stock\n",
    "            import datetime\n",
    "            if ref_date is None: ref_date = datetime.datetime.now()\n",
    "            ds = pd.Timestamp(ref_date).strftime(\"%Y%m%d\")\n",
    "            tickers = stock.get_market_ticker_list(ds, market=reg[\"pykrx_market\"])\n",
    "            if not tickers: raise ValueError(\"Empty\")\n",
    "            try:\n",
    "                cap = stock.get_market_cap_by_ticker(ds, market=reg[\"pykrx_market\"])\n",
    "                if not cap.empty:\n",
    "                    if config.min_avg_volume > 0: cap = cap[cap.iloc[:,-1] >= config.min_avg_volume]\n",
    "                    cap = cap.sort_values(cap.columns[0], ascending=False)\n",
    "                    tickers = cap.head(config.max_universe_size).index.tolist()\n",
    "            except: tickers = tickers[:config.max_universe_size]\n",
    "            logger.info(\"Dynamic universe %s: %d tickers (ref %s)\" % (market, len(tickers), ds))\n",
    "            return tickers\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Dynamic universe failed %s: %s\" % (market, str(e)[:60]))\n",
    "    static = get_static_tickers(market)\n",
    "    logger.info(\"Static universe %s: %d tickers\" % (market, len(static)))\n",
    "    return static\n",
    "\n",
    "print(\"Universe builder ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "ohlcv_data = {}\n",
    "market_indices = {}\n",
    "fx_rates = pd.DataFrame()\n",
    "\n",
    "fx_path = os.path.join(CFG.drive_root, \"data\", \"fx_usdkrw.parquet\")\n",
    "if os.path.exists(fx_path):\n",
    "    fx_rates = pd.read_parquet(fx_path)\n",
    "else:\n",
    "    if any(MARKET_REGISTRY[m][\"currency\"]==\"KRW\" for m in CFG.markets):\n",
    "        fx_rates = download_fx_rates(CFG.data_period)\n",
    "        if not fx_rates.empty: fx_rates.to_parquet(fx_path)\n",
    "\n",
    "for market in CFG.markets:\n",
    "    STEP = \"data_load_%s\" % market\n",
    "    pp = os.path.join(CFG.data_dir(market), \"processed.parquet\")\n",
    "    ip = os.path.join(CFG.data_dir(market), \"market_index.parquet\")\n",
    "    reg = MARKET_REGISTRY[market]\n",
    "\n",
    "    if tracker.is_completed(STEP):\n",
    "        logger.info(\"[SKIP] %s\" % STEP)\n",
    "        ohlcv_data[market] = pd.read_parquet(pp)\n",
    "        market_indices[market] = pd.read_parquet(ip)\n",
    "        continue\n",
    "\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    tickers = build_universe(market)\n",
    "    all_dfs, failed = [], []\n",
    "\n",
    "    if reg[\"data_source\"] == \"yfinance\":\n",
    "        for i, tk in enumerate(tickers):\n",
    "            if (i+1)%10==0 or i==0: print(\"  [%d/%d] %s\"%(i+1,len(tickers),tk))\n",
    "            try:\n",
    "                df = yf.download(tk, period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "                if df.empty or len(df)<252: failed.append(tk); continue\n",
    "                if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)\n",
    "                df = df[[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]].copy()\n",
    "                df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "                df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "                df[\"ticker\"] = tk; all_dfs.append(df)\n",
    "            except: failed.append(tk)\n",
    "    elif reg[\"data_source\"] == \"pykrx\":\n",
    "        import datetime as _dt\n",
    "        es = _dt.datetime.now().strftime(\"%Y%m%d\")\n",
    "        ss = (_dt.datetime.now()-_dt.timedelta(days=365*10)).strftime(\"%Y%m%d\")\n",
    "        for i, tk in enumerate(tickers):\n",
    "            if (i+1)%10==0 or i==0: print(\"  [%d/%d] %s\"%(i+1,len(tickers),tk))\n",
    "            try:\n",
    "                from pykrx import stock as ps\n",
    "                df = ps.get_market_ohlcv_by_date(ss, es, tk)\n",
    "                if df.empty or len(df)<252: raise ValueError(\"short\")\n",
    "                rm = {}\n",
    "                for c in df.columns:\n",
    "                    cl = c.strip()\n",
    "                    if cl in (\"시가\",\"Open\"): rm[c]=\"open\"\n",
    "                    elif cl in (\"고가\",\"High\"): rm[c]=\"high\"\n",
    "                    elif cl in (\"저가\",\"Low\"): rm[c]=\"low\"\n",
    "                    elif cl in (\"종가\",\"Close\"): rm[c]=\"close\"\n",
    "                    elif cl in (\"거래량\",\"Volume\"): rm[c]=\"volume\"\n",
    "                df = df.rename(columns=rm)[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].copy()\n",
    "                df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "                df[\"ticker\"] = tk; all_dfs.append(df)\n",
    "            except:\n",
    "                try:\n",
    "                    import FinanceDataReader as fdr\n",
    "                    df2 = fdr.DataReader(tk, ss[:4]+\"-\"+ss[4:6]+\"-\"+ss[6:])\n",
    "                    if df2.empty or len(df2)<252: failed.append(tk); continue\n",
    "                    df2 = df2.rename(columns={\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "                    df2 = df2[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].copy()\n",
    "                    df2.index = pd.to_datetime(df2.index).tz_localize(None)\n",
    "                    df2[\"ticker\"] = tk; all_dfs.append(df2)\n",
    "                except: failed.append(tk)\n",
    "\n",
    "    if not all_dfs: logger.warning(\"No data for %s\"%market); continue\n",
    "    panel = pd.concat(all_dfs)\n",
    "    panel = panel.set_index([panel.index, \"ticker\"])\n",
    "    panel.index.names = [\"date\",\"ticker\"]; panel = panel.sort_index()\n",
    "    if reg[\"currency\"]==\"KRW\" and CFG.apply_fx_conversion and not fx_rates.empty:\n",
    "        panel = convert_krw_to_usd(panel, fx_rates)\n",
    "    if CFG.use_float32:\n",
    "        for c in [\"open\",\"high\",\"low\",\"close\"]: panel[c] = panel[c].astype(np.float32)\n",
    "        panel[\"volume\"] = panel[\"volume\"].astype(np.float64)\n",
    "    panel.to_parquet(pp); ohlcv_data[market] = panel\n",
    "\n",
    "    try:\n",
    "        idx = yf.download(reg[\"index_ticker\"], period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "        if isinstance(idx.columns, pd.MultiIndex): idx.columns = idx.columns.get_level_values(0)\n",
    "        idx = idx[[\"Close\"]].copy(); idx.columns = [\"close\"]\n",
    "        idx.index = pd.to_datetime(idx.index).tz_localize(None)\n",
    "        if reg[\"currency\"]==\"KRW\" and CFG.apply_fx_conversion and not fx_rates.empty:\n",
    "            fx_al = fx_rates[\"usdkrw\"].reindex(idx.index, method=\"ffill\")\n",
    "            idx[\"close\"] = idx[\"close\"] / fx_al\n",
    "    except: idx = pd.DataFrame(columns=[\"close\"])\n",
    "    idx.to_parquet(ip); market_indices[market] = idx\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n\":len(all_dfs),\"failed\":failed[:5],\"time\":elapsed})\n",
    "    print(\"%s: %d/%d tickers (%.0fs)\" % (market,len(all_dfs),len(tickers),elapsed))\n",
    "    gc.collect()\n",
    "\n",
    "for m in ohlcv_data:\n",
    "    p = ohlcv_data[m]; tks = p.index.get_level_values(1).unique()\n",
    "    dts = p.index.get_level_values(0).unique()\n",
    "    print(\"%s: %s | %d tickers | %s to %s\" % (m,str(p.shape),len(tks),dts.min().date(),dts.max().date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Fundamental & Sector Data (Axes B + D)\n",
    "\n",
    "**Axis B** — Fundamentals: log_market_cap, PE, PB, ROE from yfinance / pykrx (cached).\n",
    "**Axis D** — Cross-Sectional: sector-relative 20d returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_cache = {}  # {market: {ticker: {field: value}}}\n",
    "sector_mean_returns = {}  # {market: {sector: mean_20d_return}}\n",
    "\n",
    "US_SECTOR_MAP = {\n",
    "    \"AAPL\":\"Tech\",\"MSFT\":\"Tech\",\"GOOGL\":\"Tech\",\"AMZN\":\"Consumer\",\"NVDA\":\"Tech\",\n",
    "    \"META\":\"Tech\",\"TSLA\":\"Consumer\",\"BRK-B\":\"Financials\",\"JPM\":\"Financials\",\n",
    "    \"JNJ\":\"Healthcare\",\"V\":\"Financials\",\"PG\":\"Consumer\",\"UNH\":\"Healthcare\",\n",
    "    \"HD\":\"Consumer\",\"MA\":\"Financials\",\"DIS\":\"Consumer\",\"BAC\":\"Financials\",\n",
    "    \"NFLX\":\"Consumer\",\"ADBE\":\"Tech\",\"CRM\":\"Tech\",\"XOM\":\"Energy\",\"VZ\":\"Telecom\",\n",
    "    \"KO\":\"Consumer\",\"INTC\":\"Tech\",\"PEP\":\"Consumer\",\"ABT\":\"Healthcare\",\n",
    "    \"CSCO\":\"Tech\",\"COST\":\"Consumer\",\"MRK\":\"Healthcare\",\"WMT\":\"Consumer\",\n",
    "    \"AVGO\":\"Tech\",\"ACN\":\"Tech\",\"CVX\":\"Energy\",\"NKE\":\"Consumer\",\"LLY\":\"Healthcare\",\n",
    "    \"MCD\":\"Consumer\",\"QCOM\":\"Tech\",\"UPS\":\"Industrials\",\"BMY\":\"Healthcare\",\n",
    "    \"LIN\":\"Materials\",\"NEE\":\"Utilities\",\"ORCL\":\"Tech\",\"RTX\":\"Industrials\",\n",
    "    \"HON\":\"Industrials\",\"TXN\":\"Tech\",\"AMD\":\"Tech\",\"PYPL\":\"Tech\",\n",
    "    \"CMCSA\":\"Telecom\",\"TMO\":\"Healthcare\",\"DHR\":\"Healthcare\",\n",
    "}\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in ohlcv_data:\n",
    "        continue\n",
    "    STEP = \"fundamental_data_%s\" % market\n",
    "    fund_path = os.path.join(CFG.data_dir(market), \"fundamentals.parquet\")\n",
    "\n",
    "    if tracker.is_completed(STEP) and os.path.exists(fund_path):\n",
    "        logger.info(\"[SKIP] %s\" % STEP)\n",
    "        _fdf = pd.read_parquet(fund_path)\n",
    "        fundamental_cache[market] = {\n",
    "            tk: _fdf.loc[tk].to_dict() for tk in _fdf.index if tk in _fdf.index\n",
    "        }\n",
    "        continue\n",
    "\n",
    "    if not CFG.enable_fundamental_features:\n",
    "        fundamental_cache[market] = {}\n",
    "        tracker.mark_completed(STEP, {\"skipped\": True})\n",
    "        continue\n",
    "\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    reg = MARKET_REGISTRY[market]\n",
    "    panel = ohlcv_data[market]\n",
    "    tickers = panel.index.get_level_values(1).unique().tolist()\n",
    "    fund_rows = {}\n",
    "\n",
    "    if reg[\"data_source\"] == \"yfinance\":\n",
    "        for i, tk in enumerate(tickers):\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(\"  Fundamental [%d/%d] %s\" % (i + 1, len(tickers), tk))\n",
    "            try:\n",
    "                info = yf.Ticker(tk).info\n",
    "                row = {}\n",
    "                for fld in CFG.fundamental_fields:\n",
    "                    v = info.get(fld)\n",
    "                    row[fld] = float(v) if v is not None else np.nan\n",
    "                row[\"sector\"] = info.get(\"sector\", US_SECTOR_MAP.get(tk, \"Other\"))\n",
    "                fund_rows[tk] = row\n",
    "            except Exception as _e:\n",
    "                logger.debug(\"Fund fetch fail %s: %s\" % (tk, str(_e)[:60]))\n",
    "                fund_rows[tk] = {fld: np.nan for fld in CFG.fundamental_fields}\n",
    "                fund_rows[tk][\"sector\"] = US_SECTOR_MAP.get(tk, \"Other\")\n",
    "            time.sleep(0.1)  # rate-limit\n",
    "    elif reg[\"data_source\"] == \"pykrx\":\n",
    "        try:\n",
    "            from pykrx import stock as _pks\n",
    "            import datetime as _dt\n",
    "            ds = _dt.datetime.now().strftime(\"%Y%m%d\")\n",
    "            fund_df = _pks.get_market_fundamental_by_ticker(ds, market=reg.get(\"pykrx_market\", market))\n",
    "            if fund_df is not None and not fund_df.empty:\n",
    "                col_map = {}\n",
    "                for c in fund_df.columns:\n",
    "                    cl = c.strip()\n",
    "                    if cl in (\"PER\", \"trailingPE\"):\n",
    "                        col_map[c] = \"trailingPE\"\n",
    "                    elif cl in (\"PBR\", \"priceToBook\"):\n",
    "                        col_map[c] = \"priceToBook\"\n",
    "                    elif cl in (\"DIV\", \"dividendYield\"):\n",
    "                        col_map[c] = \"dividendYield\"\n",
    "                    elif cl in (\"EPS\",):\n",
    "                        col_map[c] = \"EPS\"\n",
    "                fund_df = fund_df.rename(columns=col_map)\n",
    "                for tk in tickers:\n",
    "                    if tk in fund_df.index:\n",
    "                        row = {}\n",
    "                        for fld in CFG.fundamental_fields:\n",
    "                            v = fund_df.loc[tk].get(fld, np.nan)\n",
    "                            row[fld] = float(v) if v is not None and not (isinstance(v, float) and np.isnan(v)) else np.nan\n",
    "                        row[\"sector\"] = \"KR_\" + market\n",
    "                        fund_rows[tk] = row\n",
    "                    else:\n",
    "                        fund_rows[tk] = {fld: np.nan for fld in CFG.fundamental_fields}\n",
    "                        fund_rows[tk][\"sector\"] = \"KR_\" + market\n",
    "        except Exception as _e:\n",
    "            logger.warning(\"pykrx fundamental fetch failed: %s\" % str(_e)[:80])\n",
    "            for tk in tickers:\n",
    "                fund_rows[tk] = {fld: np.nan for fld in CFG.fundamental_fields}\n",
    "                fund_rows[tk][\"sector\"] = \"KR_\" + market\n",
    "\n",
    "    fundamental_cache[market] = fund_rows\n",
    "    if fund_rows:\n",
    "        fdf = pd.DataFrame.from_dict(fund_rows, orient=\"index\")\n",
    "        fdf.to_parquet(fund_path)\n",
    "\n",
    "    # Compute sector mean 20d returns for Axis D\n",
    "    if CFG.enable_sector_features and fund_rows:\n",
    "        ticker_sectors = {tk: fund_rows.get(tk, {}).get(\"sector\", \"Other\") for tk in tickers}\n",
    "        sector_rets = {}\n",
    "        for tk in tickers:\n",
    "            try:\n",
    "                td = panel.loc[(slice(None), tk), :].droplevel(1)\n",
    "                r20 = td[\"close\"].pct_change(20).iloc[-1] if len(td) > 20 else 0.0\n",
    "                sec = ticker_sectors.get(tk, \"Other\")\n",
    "                sector_rets.setdefault(sec, []).append(float(r20) if not np.isnan(r20) else 0.0)\n",
    "            except Exception:\n",
    "                pass\n",
    "        sector_mean_returns[market] = {sec: float(np.mean(vals)) for sec, vals in sector_rets.items()}\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_tickers\": len(fund_rows), \"time\": elapsed})\n",
    "    print(\"%s fundamentals: %d tickers (%.0fs)\" % (market, len(fund_rows), elapsed))\n",
    "\n",
    "print(\"Fundamental cache:\", {m: len(v) for m, v in fundamental_cache.items()})\n",
    "print(\"Sector mean returns:\", {m: len(v) for m, v in sector_mean_returns.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Macro Data (Axis C)\n",
    "\n",
    "Download 6 macro series: Treasury yields, VIX, Gold, Oil, DXY.\n",
    "Derived features: yield_curve_slope, vix_regime, commodity/DXY momentum.\n",
    "Used in **meta-model** and **macro veto** only (Tier 2 — no candidate generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_data = pd.DataFrame()\n",
    "STEP = \"macro_data\"\n",
    "macro_path = os.path.join(CFG.drive_root, \"data\", \"macro.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP) and os.path.exists(macro_path):\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "    macro_data = pd.read_parquet(macro_path)\n",
    "elif not CFG.enable_macro_features:\n",
    "    logger.info(\"[SKIP] macro (disabled)\")\n",
    "    tracker.mark_completed(STEP, {\"skipped\": True})\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    raw_macro = {}\n",
    "    for name, ticker in CFG.macro_tickers.items():\n",
    "        try:\n",
    "            df = yf.download(ticker, period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            if not df.empty and \"Close\" in df.columns:\n",
    "                s = df[\"Close\"].copy()\n",
    "                s.index = pd.to_datetime(s.index).tz_localize(None)\n",
    "                raw_macro[name] = s\n",
    "                logger.info(\"Macro %s: %d rows\" % (name, len(s)))\n",
    "        except Exception as _e:\n",
    "            logger.warning(\"Macro download fail %s: %s\" % (name, str(_e)[:60]))\n",
    "\n",
    "    if raw_macro:\n",
    "        macro_data = pd.DataFrame(raw_macro)\n",
    "        macro_data = macro_data.sort_index().ffill()\n",
    "\n",
    "        # Derived features\n",
    "        if \"tnx\" in macro_data.columns and \"irx\" in macro_data.columns:\n",
    "            macro_data[\"yield_curve_slope\"] = macro_data[\"tnx\"] - macro_data[\"irx\"]\n",
    "            macro_data[\"yield_curve_inverted\"] = (macro_data[\"yield_curve_slope\"] < 0).astype(float)\n",
    "        else:\n",
    "            macro_data[\"yield_curve_slope\"] = 0.0\n",
    "            macro_data[\"yield_curve_inverted\"] = 0.0\n",
    "\n",
    "        if \"vix\" in macro_data.columns:\n",
    "            vix_median = macro_data[\"vix\"].rolling(252, min_periods=60).median()\n",
    "            macro_data[\"vix_regime\"] = macro_data[\"vix\"] / vix_median.replace(0, np.nan)\n",
    "        else:\n",
    "            macro_data[\"vix_regime\"] = 1.0\n",
    "\n",
    "        for asset in [\"dxy\", \"gold\", \"oil\"]:\n",
    "            if asset in macro_data.columns:\n",
    "                macro_data[\"%s_mom_60d\" % asset] = macro_data[asset].pct_change(60)\n",
    "            else:\n",
    "                macro_data[\"%s_mom_60d\" % asset] = 0.0\n",
    "\n",
    "        macro_data.to_parquet(macro_path)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_series\": len(raw_macro), \"time\": elapsed})\n",
    "\n",
    "print(\"Macro data:\", macro_data.shape if len(macro_data) > 0 else \"empty\")\n",
    "if len(macro_data) > 0:\n",
    "    print(\"  Columns:\", list(macro_data.columns))\n",
    "    print(\"  Latest yield_curve_slope:\", macro_data[\"yield_curve_slope\"].iloc[-1] if \"yield_curve_slope\" in macro_data.columns else \"N/A\")\n",
    "    print(\"  Latest vix_regime:\", macro_data[\"vix_regime\"].iloc[-1] if \"vix_regime\" in macro_data.columns else \"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Sentiment Proxy (Axis E — Optional)\n",
    "\n",
    "VIX term structure = VIX / VIX3M − 1.\n",
    "Positive = backwardation (fear). Used in **meta-model** only (Tier 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_data = pd.DataFrame()\n",
    "STEP = \"sentiment_proxy_data\"\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    sp = os.path.join(CFG.drive_root, \"data\", \"sentiment_proxy.parquet\")\n",
    "    if os.path.exists(sp):\n",
    "        sentiment_data = pd.read_parquet(sp)\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "elif not CFG.enable_sentiment_proxy:\n",
    "    logger.info(\"[SKIP] sentiment proxy (disabled)\")\n",
    "    tracker.mark_completed(STEP, {\"skipped\": True})\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        vix3m = yf.download(\"^VIX3M\", period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "        if isinstance(vix3m.columns, pd.MultiIndex):\n",
    "            vix3m.columns = vix3m.columns.get_level_values(0)\n",
    "        if not vix3m.empty and \"Close\" in vix3m.columns:\n",
    "            vix3m_close = vix3m[\"Close\"].copy()\n",
    "            vix3m_close.index = pd.to_datetime(vix3m_close.index).tz_localize(None)\n",
    "\n",
    "            if len(macro_data) > 0 and \"vix\" in macro_data.columns:\n",
    "                vix_close = macro_data[\"vix\"]\n",
    "            else:\n",
    "                _vix_raw = yf.download(\"^VIX\", period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "                if isinstance(_vix_raw.columns, pd.MultiIndex):\n",
    "                    _vix_raw.columns = _vix_raw.columns.get_level_values(0)\n",
    "                vix_close = _vix_raw[\"Close\"].copy()\n",
    "                vix_close.index = pd.to_datetime(vix_close.index).tz_localize(None)\n",
    "\n",
    "            aligned = pd.DataFrame({\"vix\": vix_close, \"vix3m\": vix3m_close}).ffill().dropna()\n",
    "            if len(aligned) > 0:\n",
    "                sentiment_data = pd.DataFrame(index=aligned.index)\n",
    "                sentiment_data[\"vix_term_structure\"] = aligned[\"vix\"] / aligned[\"vix3m\"].replace(0, np.nan) - 1\n",
    "                sp = os.path.join(CFG.drive_root, \"data\", \"sentiment_proxy.parquet\")\n",
    "                sentiment_data.to_parquet(sp)\n",
    "    except Exception as _e:\n",
    "        logger.warning(\"Sentiment proxy failed: %s\" % str(_e)[:80])\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_rows\": len(sentiment_data), \"time\": elapsed})\n",
    "\n",
    "print(\"Sentiment proxy:\", sentiment_data.shape if len(sentiment_data) > 0 else \"empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engine + Tri-State Labeling\n",
    "\n",
    "**Part 1**: Tri-state labels replace binary labels:\n",
    "- `+1` = BUY (excess return ≥ threshold)\n",
    "- ` 0` = NO TRADE (uncertain)\n",
    "- `−1` = AVOID (excess return ≤ −threshold)\n",
    "\n",
    "Thresholds are horizon-aware. Excess return is market-neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_momentum_features(close, windows):\n",
    "    return pd.DataFrame({\"mom_%dd\"%w: close.pct_change(w) for w in windows}, index=close.index)\n",
    "\n",
    "def compute_volatility_features(close, windows):\n",
    "    dr = close.pct_change()\n",
    "    feats = {\"vol_%dd\"%w: dr.rolling(w).std() for w in windows}\n",
    "    if len(windows)>=2:\n",
    "        feats[\"vol_change\"] = dr.rolling(windows[0]).std() / dr.rolling(windows[-1]).std().replace(0,np.nan) - 1\n",
    "    return pd.DataFrame(feats, index=close.index)\n",
    "\n",
    "def compute_regime_features(mkt_close, rw):\n",
    "    mr = mkt_close.pct_change()\n",
    "    feats = {\"market_mom_%dd\"%rw: mkt_close.pct_change(rw),\n",
    "             \"market_vol_%dd\"%rw: mr.rolling(rw).std()}\n",
    "    mom = feats[\"market_mom_%dd\"%rw]; vol = feats[\"market_vol_%dd\"%rw]\n",
    "    vm = vol.rolling(252, min_periods=60).median()\n",
    "    feats[\"regime_bull\"] = ((mom>0)&(vol<vm)).astype(float)\n",
    "    return pd.DataFrame(feats, index=mkt_close.index)\n",
    "\n",
    "def adaptive_n_bins(n, cfg):\n",
    "    if not cfg.adaptive_quantiles: return 10\n",
    "    return 5 if n < 5 * cfg.min_bin_size else 10\n",
    "\n",
    "def to_cross_sectional_deciles(s, date_level, n_bins=10):\n",
    "    def rank_date(g):\n",
    "        v = g.dropna()\n",
    "        if len(v)<n_bins: return pd.Series(np.nan, index=g.index)\n",
    "        r = v.rank(method='first')\n",
    "        return pd.cut(r, bins=n_bins, labels=False).reindex(g.index)\n",
    "    return s.groupby(level=date_level).transform(rank_date)\n",
    "\n",
    "def compute_tristate_labels(excess_return, threshold_pct):\n",
    "    \"\"\"Tri-state labeling: +1 BUY, 0 NO TRADE, -1 AVOID.\"\"\"\n",
    "    th = threshold_pct / 100.0\n",
    "    labels = np.zeros(len(excess_return), dtype=np.float32)\n",
    "    vals = excess_return.values if hasattr(excess_return, 'values') else excess_return\n",
    "    labels[vals >= th] = 1\n",
    "    labels[vals <= -th] = -1\n",
    "    return labels\n",
    "\n",
    "def check_class_balance(labels):\n",
    "    \"\"\"Check tri-state label distribution. Returns (ok, distribution_dict).\"\"\"\n",
    "    s = pd.Series(labels)\n",
    "    counts = s.value_counts(normalize=True)\n",
    "    dist = {\"buy\": counts.get(1,0), \"notrade\": counts.get(0,0), \"avoid\": counts.get(-1,0)}\n",
    "    ok = 0.40 <= dist[\"notrade\"] <= 0.90 and dist[\"buy\"] >= 0.03 and dist[\"avoid\"] >= 0.03\n",
    "    return ok, dist\n",
    "\n",
    "print(\"Feature functions + tri-state labeler defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_liquidity_features(ohlcv_df, cfg):\n",
    "    \"\"\"Axis A: Liquidity features from existing OHLCV — zero new downloads.\n",
    "\n",
    "    Returns DataFrame with:\n",
    "      - log_dollar_vol_{w}d: log of rolling dollar volume\n",
    "      - amihud: Amihud illiquidity ratio (|return| / dollar_volume)\n",
    "      - vol_imbalance: (up_vol - down_vol) / total_vol rolling\n",
    "      - turnover_ratio: volume / rolling mean volume\n",
    "      - gap_freq: frequency of overnight gaps > 1%\n",
    "    \"\"\"\n",
    "    close = ohlcv_df[\"close\"]\n",
    "    volume = ohlcv_df[\"volume\"]\n",
    "    feats = pd.DataFrame(index=ohlcv_df.index)\n",
    "\n",
    "    dollar_vol = close * volume\n",
    "    for w in cfg.liquidity_dollar_vol_windows:\n",
    "        rdv = dollar_vol.rolling(w, min_periods=max(1, w // 2)).mean()\n",
    "        feats[\"log_dollar_vol_%dd\" % w] = np.log1p(rdv)\n",
    "\n",
    "    # Amihud illiquidity: mean(|ret| / dollar_vol) over window\n",
    "    abs_ret = close.pct_change().abs()\n",
    "    dv_safe = dollar_vol.replace(0, np.nan)\n",
    "    amihud_raw = abs_ret / dv_safe\n",
    "    feats[\"amihud\"] = amihud_raw.rolling(cfg.amihud_window, min_periods=20).mean()\n",
    "\n",
    "    # Volume imbalance: (up_vol - down_vol) / total_vol, 20d rolling\n",
    "    ret = close.pct_change()\n",
    "    up_vol = volume.where(ret > 0, 0).rolling(20).sum()\n",
    "    dn_vol = volume.where(ret <= 0, 0).rolling(20).sum()\n",
    "    total = (up_vol + dn_vol).replace(0, np.nan)\n",
    "    feats[\"vol_imbalance\"] = (up_vol - dn_vol) / total\n",
    "\n",
    "    # Turnover ratio: current volume / 60d mean volume\n",
    "    mean_vol = volume.rolling(60, min_periods=20).mean().replace(0, np.nan)\n",
    "    feats[\"turnover_ratio\"] = volume / mean_vol\n",
    "\n",
    "    # Gap frequency: fraction of days with overnight gap > 1% in past 60 days\n",
    "    if \"open\" in ohlcv_df.columns:\n",
    "        gap = (ohlcv_df[\"open\"] / close.shift(1) - 1).abs()\n",
    "        feats[\"gap_freq\"] = (gap > 0.01).astype(float).rolling(60, min_periods=20).mean()\n",
    "\n",
    "    return feats\n",
    "\n",
    "print(\"Liquidity feature function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_panels = {}\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in ohlcv_data: continue\n",
    "    STEP = \"features_%s\" % market\n",
    "    fpath = os.path.join(CFG.features_dir(market), \"all_features.parquet\")\n",
    "\n",
    "    if tracker.is_completed(STEP):\n",
    "        logger.info(\"[SKIP] %s\" % STEP)\n",
    "        feature_panels[market] = pd.read_parquet(fpath)\n",
    "        continue\n",
    "\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    panel = ohlcv_data[market]\n",
    "    valid_tickers = panel.index.get_level_values(1).unique().tolist()\n",
    "    n_bins = adaptive_n_bins(len(valid_tickers), CFG)\n",
    "\n",
    "    mkt_close = market_indices.get(market, pd.DataFrame()).get(\"close\", pd.Series(dtype=float))\n",
    "    regime_feats = compute_regime_features(mkt_close, CFG.regime_window) if len(mkt_close)>0 else pd.DataFrame()\n",
    "    market_ret_20d = mkt_close.pct_change(20) if len(mkt_close)>0 else pd.Series(dtype=float)\n",
    "\n",
    "    # Pre-compute market forward returns for excess calculation\n",
    "    mkt_fwd = {}\n",
    "    for fd in CFG.forward_days_list:\n",
    "        if len(mkt_close) > 0:\n",
    "            mkt_fwd[fd] = mkt_close.pct_change(fd).shift(-fd)\n",
    "        else:\n",
    "            mkt_fwd[fd] = pd.Series(dtype=float)\n",
    "\n",
    "    all_features = []\n",
    "    for ticker in valid_tickers:\n",
    "        try:\n",
    "            td = panel.loc[(slice(None), ticker), :].droplevel(1)\n",
    "            close = td[\"close\"]\n",
    "            mom = compute_momentum_features(close, CFG.momentum_windows)\n",
    "            if len(market_ret_20d) > 0:\n",
    "                s20 = close.pct_change(20)\n",
    "                ma = market_ret_20d.reindex(close.index, method='ffill')\n",
    "                mom[\"market_relative_20d\"] = s20 - ma\n",
    "            vol = compute_volatility_features(close, CFG.volatility_windows)\n",
    "            reg = regime_feats.reindex(close.index, method='ffill') if len(regime_feats)>0 else pd.DataFrame(index=close.index)\n",
    "\n",
    "            # --- Axis A: Liquidity features ---\n",
    "            liq = compute_liquidity_features(td, CFG) if CFG.enable_liquidity_features else pd.DataFrame(index=close.index)\n",
    "\n",
    "            # --- Axis B: Fundamental features ---\n",
    "            fund = pd.DataFrame(index=close.index)\n",
    "            if CFG.enable_fundamental_features:\n",
    "                # high_52w_pct: current price as % of 52-week high\n",
    "                high_52w = close.rolling(252, min_periods=60).max()\n",
    "                fund[\"high_52w_pct\"] = close / high_52w.replace(0, np.nan)\n",
    "                # Static fundamentals from cache\n",
    "                fund_info = fundamental_cache.get(market, {}).get(ticker, {})\n",
    "                if fund_info:\n",
    "                    mc = fund_info.get(\"marketCap\", np.nan)\n",
    "                    fund[\"log_market_cap\"] = np.log1p(mc) if not (isinstance(mc, float) and np.isnan(mc)) else np.nan\n",
    "                    for fld in [\"trailingPE\", \"priceToBook\", \"returnOnEquity\"]:\n",
    "                        fund[fld] = fund_info.get(fld, np.nan)\n",
    "\n",
    "            # --- Axis D: Sector relative ---\n",
    "            sect = pd.DataFrame(index=close.index)\n",
    "            if CFG.enable_sector_features:\n",
    "                fund_info_s = fundamental_cache.get(market, {}).get(ticker, {})\n",
    "                ticker_sector = fund_info_s.get(\"sector\", \"Other\") if fund_info_s else \"Other\"\n",
    "                sect_means = sector_mean_returns.get(market, {})\n",
    "                sect_mean = sect_means.get(ticker_sector, 0.0)\n",
    "                s20 = close.pct_change(20)\n",
    "                sect[\"sector_relative_20d\"] = s20 - sect_mean\n",
    "\n",
    "            combined = pd.concat([mom, vol, reg, liq, fund, sect], axis=1)\n",
    "\n",
    "            for fd in CFG.forward_days_list:\n",
    "                raw_fwd = close.pct_change(fd).shift(-fd)\n",
    "                net_fwd = raw_fwd - 2 * CFG.total_cost_bps / 10000\n",
    "                combined[\"fwd_return_%dd\" % fd] = net_fwd\n",
    "\n",
    "                # Excess return & tri-state label\n",
    "                mf = mkt_fwd[fd].reindex(close.index, method='ffill') if len(mkt_fwd[fd])>0 else 0\n",
    "                excess = net_fwd - mf\n",
    "                th_pct = CFG.tristate_thresholds_pct.get(fd, 1.0)\n",
    "                combined[\"label_%dd\" % fd] = compute_tristate_labels(excess, th_pct)\n",
    "\n",
    "            combined[\"ticker\"] = ticker\n",
    "            combined.index.name = \"date\"\n",
    "            all_features.append(combined)\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Feature err %s/%s: %s\" % (market, ticker, str(e)[:60]))\n",
    "\n",
    "    if not all_features: continue\n",
    "    fp = pd.concat(all_features).reset_index().set_index([\"date\",\"ticker\"]).sort_index()\n",
    "    fwd_cols = [c for c in fp.columns if c.startswith(\"fwd_return_\")]\n",
    "    label_cols = [c for c in fp.columns if c.startswith(\"label_\")]\n",
    "    feat_cols = [c for c in fp.columns if c not in fwd_cols and c not in label_cols]\n",
    "    fp = fp.dropna(subset=feat_cols, how='all')\n",
    "    if CFG.use_float32:\n",
    "        for c in fp.select_dtypes(include=['float64']).columns: fp[c] = fp[c].astype(np.float32)\n",
    "\n",
    "    logger.info(\"Computing deciles for %s...\" % market)\n",
    "    for col in feat_cols:\n",
    "        fp[col+\"_decile\"] = to_cross_sectional_deciles(fp[col], \"date\", n_bins)\n",
    "\n",
    "    fp.to_parquet(fpath); feature_panels[market] = fp\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_feat\": len(feat_cols), \"n_rows\": len(fp), \"time\": elapsed})\n",
    "\n",
    "    # Class balance check\n",
    "    for fd in CFG.forward_days_list:\n",
    "        lc = \"label_%dd\" % fd\n",
    "        if lc in fp.columns:\n",
    "            ok, dist = check_class_balance(fp[lc].dropna().values)\n",
    "            status = \"OK\" if ok else \"WARN\"\n",
    "            print(\"  %s label_%dd: BUY=%.1f%% NO_TRADE=%.1f%% AVOID=%.1f%% [%s]\" % (\n",
    "                market, fd, dist[\"buy\"]*100, dist[\"notrade\"]*100, dist[\"avoid\"]*100, status))\n",
    "    gc.collect()\n",
    "\n",
    "for m, fp in feature_panels.items():\n",
    "    fwd = [c for c in fp.columns if c.startswith(\"fwd_return_\")]\n",
    "    lab = [c for c in fp.columns if c.startswith(\"label_\")]\n",
    "    feat = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "    print(\"%s: %d features, %d deciles, horizons: %s, labels: %s\" % (m, len(feat), len([c for c in fp.columns if c.endswith(\"_decile\")]), fwd, lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Candidate Generator\n",
    "\n",
    "- **Decile**: single & 2-feature combos (unchanged)\n",
    "- **Trees**: trained on **tri-state labels** (multiclass); only BUY leaves kept\n",
    "- **Logistic**: **multinomial**; strategies from BUY-class probability quintiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "all_candidates_list = []\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in feature_panels: continue\n",
    "    fp = feature_panels[market]\n",
    "    fwd_cols = sorted([c for c in fp.columns if c.startswith(\"fwd_return_\")])\n",
    "    decile_cols = [c for c in fp.columns if c.endswith(\"_decile\")]\n",
    "\n",
    "    for fwd_col in fwd_cols:\n",
    "        ht = fwd_col.replace(\"fwd_return_\",\"\")\n",
    "        STEP = \"cand_decile_%s_%s\" % (market, ht)\n",
    "        sp = os.path.join(CFG.candidates_dir(market), \"decile_%s.parquet\" % ht)\n",
    "        if tracker.is_completed(STEP):\n",
    "            all_candidates_list.append(pd.read_parquet(sp)); continue\n",
    "\n",
    "        logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "        valid = fp.dropna(subset=[fwd_col]).copy()\n",
    "        n_bins = int(valid[decile_cols[0]].dropna().max())+1 if decile_cols else 10\n",
    "        cands = []\n",
    "\n",
    "        for col in decile_cols:\n",
    "            for dv in range(n_bins):\n",
    "                mask = valid[col]==dv; nt = int(mask.sum())\n",
    "                if nt < CFG.min_sample_size: continue\n",
    "                ret = valid.loc[mask, fwd_col]\n",
    "                mr = float(ret.mean())\n",
    "                if mr <= 0: continue\n",
    "                cands.append({\"strategy_id\":\"%s_%s_%s_d%d\"%(market,ht,col,dv),\n",
    "                    \"market\":market,\"horizon\":ht,\"type\":\"single_decile\",\n",
    "                    \"features\":col,\"condition\":\"== %d\"%dv,\n",
    "                    \"n_trades\":nt,\"mean_return\":mr,\"win_rate\":float((ret>0).mean())})\n",
    "\n",
    "        extreme = [0,1,n_bins-2,n_bins-1] if n_bins>=4 else list(range(n_bins))\n",
    "        for ca, cb in combinations(decile_cols, 2):\n",
    "            pc = 0\n",
    "            for da in extreme:\n",
    "                for db in extreme:\n",
    "                    if pc >= CFG.max_candidates_per_feature_pair: break\n",
    "                    mask = (valid[ca]==da)&(valid[cb]==db); nt = int(mask.sum())\n",
    "                    if nt < CFG.min_sample_size: continue\n",
    "                    ret = valid.loc[mask, fwd_col]; mr = float(ret.mean())\n",
    "                    std_r = float(ret.std())\n",
    "                    if std_r>1e-8 and mr/std_r<0: continue\n",
    "                    cands.append({\"strategy_id\":\"%s_%s_%s_d%d_AND_%s_d%d\"%(market,ht,ca,da,cb,db),\n",
    "                        \"market\":market,\"horizon\":ht,\"type\":\"combo_decile\",\n",
    "                        \"features\":\"%s, %s\"%(ca,cb),\"condition\":\"%s==%d AND %s==%d\"%(ca,da,cb,db),\n",
    "                        \"n_trades\":nt,\"mean_return\":mr,\"win_rate\":float((ret>0).mean())})\n",
    "                    pc += 1\n",
    "            if len(cands) >= CFG.max_candidates_total: break\n",
    "\n",
    "        dc = pd.DataFrame(cands); dc.to_parquet(sp); all_candidates_list.append(dc)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(dc),\"time\":time.time()-t0})\n",
    "        gc.collect()\n",
    "\n",
    "print(\"Decile candidates: %d\" % sum(len(d) for d in all_candidates_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in feature_panels: continue\n",
    "    fp = feature_panels[market]\n",
    "    fwd_cols = sorted([c for c in fp.columns if c.startswith(\"fwd_return_\")])\n",
    "    feat_cols = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "\n",
    "    for fwd_col in fwd_cols:\n",
    "        ht = fwd_col.replace(\"fwd_return_\",\"\")\n",
    "        label_col = \"label_%s\" % ht\n",
    "        STEP = \"cand_tree_%s_%s\" % (market, ht)\n",
    "        sp = os.path.join(CFG.candidates_dir(market), \"tree_%s.parquet\" % ht)\n",
    "        if tracker.is_completed(STEP):\n",
    "            all_candidates_list.append(pd.read_parquet(sp)); continue\n",
    "\n",
    "        logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "        valid = fp.dropna(subset=[fwd_col]+feat_cols).copy()\n",
    "        X = valid[feat_cols].values.astype(np.float32)\n",
    "        # v3: multiclass tri-state labels\n",
    "        y = valid[label_col].values.astype(int) if label_col in valid.columns else (valid[fwd_col].values > 0).astype(int)\n",
    "        n_feat = len(feat_cols); n_sub = max(3, int(n_feat * CFG.tree_feature_subsample))\n",
    "        strats = []\n",
    "\n",
    "        for ti in range(CFG.n_trees):\n",
    "            fi = np.random.choice(n_feat, n_sub, replace=False)\n",
    "            fn = [feat_cols[j] for j in fi]\n",
    "            Xs = X[:, fi]\n",
    "            si = np.random.choice(len(Xs), min(len(Xs),50000), replace=False)\n",
    "            tree = DecisionTreeClassifier(max_depth=CFG.tree_max_depth,\n",
    "                min_samples_leaf=CFG.tree_min_samples_leaf, random_state=CFG.seed+ti)\n",
    "            tree.fit(Xs[si], y[si])\n",
    "\n",
    "            leaf_ids = tree.apply(X[:, fi])\n",
    "            for leaf in np.unique(leaf_ids):\n",
    "                lm = tree.apply(X[:, fi])==leaf; nt = int(lm.sum())\n",
    "                if nt < CFG.min_sample_size: continue\n",
    "                leaf_labels = y[lm]\n",
    "                # Only keep BUY-majority leaves\n",
    "                if (leaf_labels==1).sum() <= (leaf_labels==-1).sum(): continue\n",
    "                ret = valid[fwd_col].values[lm]; mr = float(np.nanmean(ret))\n",
    "                if mr <= 0: continue\n",
    "                strats.append({\"strategy_id\":\"%s_%s_tree_%d_leaf_%d\"%(market,ht,ti,leaf),\n",
    "                    \"market\":market,\"horizon\":ht,\"type\":\"decision_tree\",\n",
    "                    \"features\":\", \".join(fn[:5]),\"condition\":\"tree_%d/leaf_%d\"%(ti,leaf),\n",
    "                    \"n_trades\":nt,\"mean_return\":mr,\"win_rate\":float((ret>0).mean())})\n",
    "\n",
    "            tp = os.path.join(CFG.candidates_dir(market), \"tree_model_%s_%d.pkl\"%(ht,ti))\n",
    "            with open(tp,'wb') as f: pickle.dump({\"tree\":tree,\"features\":fn,\"feat_idx\":fi.tolist()}, f)\n",
    "\n",
    "        tc = pd.DataFrame(strats); tc.to_parquet(sp); all_candidates_list.append(tc)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(tc),\"time\":time.time()-t0})\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in feature_panels: continue\n",
    "    fp = feature_panels[market]\n",
    "    fwd_cols = sorted([c for c in fp.columns if c.startswith(\"fwd_return_\")])\n",
    "    feat_cols = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "\n",
    "    for fwd_col in fwd_cols:\n",
    "        ht = fwd_col.replace(\"fwd_return_\",\"\")\n",
    "        label_col = \"label_%s\" % ht\n",
    "        STEP = \"cand_logistic_%s_%s\" % (market, ht)\n",
    "        sp = os.path.join(CFG.candidates_dir(market), \"logistic_%s.parquet\" % ht)\n",
    "        if tracker.is_completed(STEP):\n",
    "            all_candidates_list.append(pd.read_parquet(sp)); continue\n",
    "\n",
    "        logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "        valid = fp.dropna(subset=[fwd_col]+feat_cols).copy()\n",
    "        X = valid[feat_cols].values.astype(np.float32)\n",
    "        # v3: multinomial on tri-state labels\n",
    "        y = valid[label_col].values.astype(int) if label_col in valid.columns else (valid[fwd_col].values > 0).astype(int)\n",
    "        scaler = StandardScaler(); Xs = scaler.fit_transform(X)\n",
    "        ds = valid.index.get_level_values(0)\n",
    "        sd = ds.unique()[int(len(ds.unique())*0.8)]\n",
    "        tm = ds <= sd\n",
    "\n",
    "        lr = LogisticRegression(max_iter=1000, C=0.1, penalty='l2', random_state=CFG.seed,\n",
    "                                solver='lbfgs')\n",
    "        lr.fit(Xs[tm], y[tm])\n",
    "\n",
    "        # P(BUY) = class +1 probability\n",
    "        classes = list(lr.classes_)\n",
    "        buy_idx = classes.index(1) if 1 in classes else -1\n",
    "        if buy_idx < 0:\n",
    "            logger.warning(\"No BUY class learned for %s/%s\" % (market, ht))\n",
    "            tracker.mark_completed(STEP, {\"n\":0}); continue\n",
    "\n",
    "        proba_buy = lr.predict_proba(Xs)[:, buy_idx]\n",
    "        qe = np.percentile(proba_buy, [0,20,40,60,80,100]).tolist()\n",
    "\n",
    "        strats = []\n",
    "        for q in range(5):\n",
    "            qm = (proba_buy>=qe[q])&(proba_buy<qe[q+1]) if q<4 else proba_buy>=qe[q]\n",
    "            nt = int(qm.sum())\n",
    "            if nt < CFG.min_sample_size: continue\n",
    "            ret = valid[fwd_col].values[qm]\n",
    "            strats.append({\"strategy_id\":\"%s_%s_logistic_q%d\"%(market,ht,q+1),\n",
    "                \"market\":market,\"horizon\":ht,\"type\":\"logistic_rank\",\n",
    "                \"features\":\"all\",\"condition\":\"logistic_q%d\"%(q+1),\n",
    "                \"n_trades\":nt,\"mean_return\":float(np.nanmean(ret)),\"win_rate\":float((ret>0).mean())})\n",
    "\n",
    "        mp = os.path.join(CFG.candidates_dir(market), \"logistic_model_%s.pkl\"%ht)\n",
    "        with open(mp,'wb') as f:\n",
    "            pickle.dump({\"model\":lr,\"scaler\":scaler,\"features\":feat_cols,\"quintile_edges\":qe,\"buy_class_idx\":buy_idx}, f)\n",
    "        lc = pd.DataFrame(strats); lc.to_parquet(sp); all_candidates_list.append(lc)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(lc),\"time\":time.time()-t0})\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_candidates = pd.concat(all_candidates_list, ignore_index=True) if all_candidates_list else pd.DataFrame()\n",
    "print(\"=== All Candidates: %d ===\" % len(all_candidates))\n",
    "if len(all_candidates) > 0:\n",
    "    print(all_candidates.groupby([\"market\",\"horizon\",\"type\"]).size().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conditional Edge Evaluation (Part 2)\n",
    "\n",
    "Metrics per strategy:\n",
    "- **Precision(BUY)**: P(label=+1 | strategy selects)\n",
    "- **Trade Coverage**: fraction of universe selected\n",
    "- **EV per trade**: mean return conditional on selection\n",
    "- **Max Loss**: worst single trade\n",
    "- **CVaR(95%)**: mean of worst 5% outcomes\n",
    "\n",
    "Hard rejection: Precision(BUY) < 0.60, EV ≤ 0, CVaR explodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_strategy_edge_v3(returns, labels=None, horizon_days=21):\n",
    "    \"\"\"Edge metrics with conditional metrics for v3.\"\"\"\n",
    "    returns = returns[~np.isnan(returns)]\n",
    "    n = len(returns)\n",
    "    if n < 30: return None\n",
    "    mr = float(np.mean(returns)); sr = float(np.std(returns, ddof=1))\n",
    "    wr = float((returns>0).mean())\n",
    "    aw = float(np.mean(returns[returns>0])) if (returns>0).any() else 0.0\n",
    "    al = float(np.mean(returns[returns<=0])) if (returns<=0).any() else 0.0\n",
    "    sharpe = (mr/sr*np.sqrt(252/horizon_days)) if sr>1e-8 else 0.0\n",
    "    cum = np.cumsum(returns); rm = np.maximum.accumulate(cum)\n",
    "    mdd = float(np.min(cum-rm)) if len(cum)>0 else 0.0\n",
    "    exp = aw*wr + al*(1-wr)\n",
    "\n",
    "    # CVaR(95%)\n",
    "    so = np.sort(returns); nt = max(1, int(0.05*len(so)))\n",
    "    cvar95 = float(so[:nt].mean())\n",
    "    max_loss = float(returns.min())\n",
    "    median_ret = float(np.median(returns))\n",
    "\n",
    "    result = {\"n_trades\":n, \"mean_return\":mr, \"std_return\":sr, \"win_rate\":wr,\n",
    "              \"avg_win\":aw, \"avg_loss\":al, \"sharpe\":float(sharpe),\n",
    "              \"max_drawdown\":mdd, \"expectancy\":float(exp),\n",
    "              \"cvar_95\":cvar95, \"max_loss\":max_loss, \"median_return\":median_ret}\n",
    "\n",
    "    if labels is not None:\n",
    "        labels = labels[:len(returns)]\n",
    "        result[\"precision_buy\"] = float((labels==1).mean())\n",
    "        result[\"avoid_rate\"] = float((labels==-1).mean())\n",
    "        buy_mask = labels==1\n",
    "        result[\"ev_buy\"] = float(returns[buy_mask].mean()) if buy_mask.any() else 0.0\n",
    "    else:\n",
    "        result[\"precision_buy\"] = wr\n",
    "        result[\"avoid_rate\"] = 0.0\n",
    "        result[\"ev_buy\"] = mr\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_mask(data, stype, cand_row, sid, market, ht, feat_cols_list):\n",
    "    \"\"\"Build boolean mask for strategy on data.\"\"\"\n",
    "    if stype == \"single_decile\":\n",
    "        return data[cand_row[\"features\"]] == int(cand_row[\"condition\"].split(\"== \")[1])\n",
    "    elif stype == \"combo_decile\":\n",
    "        parts = cand_row[\"condition\"].split(\" AND \")\n",
    "        ca, va = parts[0].split(\"==\"); cb, vb = parts[1].split(\"==\")\n",
    "        return (data[ca.strip()]==int(va)) & (data[cb.strip()]==int(vb))\n",
    "    elif stype == \"decision_tree\":\n",
    "        parts = sid.split(\"_\"); tn = ll = None\n",
    "        for i,p in enumerate(parts):\n",
    "            if p==\"tree\": tn=parts[i+1]\n",
    "            if p==\"leaf\": ll=int(parts[i+1])\n",
    "        tp = os.path.join(CFG.candidates_dir(market), \"tree_model_%s_%s.pkl\"%(ht,tn))\n",
    "        with open(tp,'rb') as f: td = pickle.load(f)\n",
    "        missing = [fn for fn in td[\"features\"] if fn not in feat_cols_list]\n",
    "        if missing: raise ValueError(\"Missing: %s\"%missing)\n",
    "        fi = [feat_cols_list.index(fn) for fn in td[\"features\"]]\n",
    "        X = data[feat_cols_list].values[:,fi].astype(np.float32); np.nan_to_num(X, copy=False)\n",
    "        return pd.Series(td[\"tree\"].apply(X)==ll, index=data.index)\n",
    "    elif stype == \"logistic_rank\":\n",
    "        qn = int(sid.split(\"_q\")[1])\n",
    "        mp = os.path.join(CFG.candidates_dir(market), \"logistic_model_%s.pkl\"%ht)\n",
    "        with open(mp,'rb') as f: ld = pickle.load(f)\n",
    "        X = data[feat_cols_list].values.astype(np.float32); np.nan_to_num(X, copy=False)\n",
    "        proba = ld[\"model\"].predict_proba(ld[\"scaler\"].transform(X))[:,ld[\"buy_class_idx\"]]\n",
    "        edges = ld[\"quintile_edges\"]\n",
    "        if qn==5: return pd.Series(proba>=edges[qn-1], index=data.index)\n",
    "        return pd.Series((proba>=edges[qn-1])&(proba<edges[qn]), index=data.index)\n",
    "    return pd.Series(False, index=data.index)\n",
    "\n",
    "print(\"v3 edge eval + mask builder defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EDGE_COLS = [\"strategy_id\",\"market\",\"horizon\",\"type\",\"n_trades\",\"mean_return\",\n",
    "              \"std_return\",\"win_rate\",\"sharpe\",\"max_drawdown\",\"expectancy\",\n",
    "              \"cvar_95\",\"max_loss\",\"median_return\",\"precision_buy\",\"avoid_rate\",\n",
    "              \"ev_buy\",\"lift\"]\n",
    "all_edge_results = []\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in feature_panels: continue\n",
    "    fp = feature_panels[market]\n",
    "    fwd_cols = sorted([c for c in fp.columns if c.startswith(\"fwd_return_\")])\n",
    "    feat_cols = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "\n",
    "    for fwd_col in fwd_cols:\n",
    "        ht = fwd_col.replace(\"fwd_return_\",\"\")\n",
    "        label_col = \"label_%s\" % ht\n",
    "        STEP = \"edge_%s_%s\" % (market, ht)\n",
    "        ep = os.path.join(CFG.evaluation_dir(market), \"edge_%s.parquet\"%ht)\n",
    "        if tracker.is_completed(STEP):\n",
    "            all_edge_results.append(pd.read_parquet(ep)); continue\n",
    "\n",
    "        logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "        valid = fp.dropna(subset=[fwd_col]+feat_cols).copy()\n",
    "        um = float(valid[fwd_col].mean())\n",
    "        mh = all_candidates[(all_candidates[\"market\"]==market)&(all_candidates[\"horizon\"]==ht)]\n",
    "        rows = []\n",
    "\n",
    "        for idx, (_, row) in enumerate(mh.iterrows()):\n",
    "            sid = row[\"strategy_id\"]; stype = row[\"type\"]\n",
    "            try:\n",
    "                mask = build_mask(valid, stype, row, sid, market, ht, feat_cols)\n",
    "                rets = valid.loc[mask, fwd_col].values\n",
    "                labs = valid.loc[mask, label_col].values if label_col in valid.columns else None\n",
    "                _hd = int(ht.replace(\"d\",\"\"))\n",
    "                edge = evaluate_strategy_edge_v3(rets, labs, horizon_days=_hd)\n",
    "                if edge is None: continue\n",
    "\n",
    "                # Hard rejection (Part 2)\n",
    "                if edge[\"precision_buy\"] < CFG.min_precision_buy * 0.8: continue  # soft pre-filter\n",
    "                if edge[\"ev_buy\"] <= CFG.min_ev_per_trade: continue\n",
    "\n",
    "                edge[\"lift\"] = edge[\"mean_return\"] - um\n",
    "                edge[\"strategy_id\"] = sid; edge[\"market\"] = market\n",
    "                edge[\"horizon\"] = ht; edge[\"type\"] = stype\n",
    "                rows.append(edge)\n",
    "            except Exception as _e:\n",
    "                logger.debug(\"Edge eval err %s: %s\" % (sid, str(_e)[:80]))\n",
    "\n",
    "            if (idx+1) % CFG.gc_every_n_candidates == 0:\n",
    "                pd.DataFrame(rows).to_parquet(ep) if rows else None\n",
    "                gc.collect()\n",
    "\n",
    "        edf = pd.DataFrame(rows) if rows else pd.DataFrame(columns=_EDGE_COLS)\n",
    "        edf.to_parquet(ep); all_edge_results.append(edf)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(edf),\"time\":time.time()-t0})\n",
    "        gc.collect()\n",
    "\n",
    "edge_results = pd.concat(all_edge_results, ignore_index=True) if all_edge_results else pd.DataFrame(columns=_EDGE_COLS)\n",
    "print(\"Edge results: %d\" % len(edge_results))\n",
    "if len(edge_results)>0:\n",
    "    print(edge_results[[\"precision_buy\",\"ev_buy\",\"cvar_95\",\"sharpe\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "_WF_COLS = [\"strategy_id\",\"market\",\"horizon\",\"fold_idx\",\"n_trades\",\"mean_return\",\n",
    "            \"win_rate\",\"sharpe\",\"max_drawdown\",\"turnover\",\"precision_buy\",\n",
    "            \"cvar_95\",\"ev_buy\",\"test_start\",\"test_end\"]\n",
    "all_wf_results = []\n",
    "\n",
    "for market in CFG.markets:\n",
    "    if market not in feature_panels: continue\n",
    "    fp = feature_panels[market]\n",
    "    fwd_cols = sorted([c for c in fp.columns if c.startswith(\"fwd_return_\")])\n",
    "    feat_cols = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "\n",
    "    for fwd_col in fwd_cols:\n",
    "        ht = fwd_col.replace(\"fwd_return_\",\"\")\n",
    "        label_col = \"label_%s\" % ht\n",
    "        STEP = \"wf_%s_%s\" % (market, ht)\n",
    "        wp = os.path.join(CFG.walkforward_dir(market), \"wf_%s.parquet\"%ht)\n",
    "        if tracker.is_completed(STEP):\n",
    "            all_wf_results.append(pd.read_parquet(wp)); continue\n",
    "\n",
    "        logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "        valid = fp.dropna(subset=[fwd_col]).copy()\n",
    "        mh_edge = edge_results[(edge_results[\"market\"]==market)&(edge_results[\"horizon\"]==ht)]\n",
    "        if len(mh_edge)>200: top_ids = mh_edge.nlargest(200,\"sharpe\")[\"strategy_id\"].tolist()\n",
    "        elif len(mh_edge)>0: top_ids = mh_edge.nlargest(min(50,len(mh_edge)),\"sharpe\")[\"strategy_id\"].tolist()\n",
    "        else: top_ids = []\n",
    "        if not top_ids: tracker.mark_completed(STEP,{\"n\":0}); continue\n",
    "\n",
    "        ad = valid.index.get_level_values(0).unique().sort_values()\n",
    "        folds = []\n",
    "        ts = ad.min()\n",
    "        while True:\n",
    "            te = ts+relativedelta(years=CFG.wf_train_years)\n",
    "            vs = te+pd.Timedelta(days=CFG.wf_embargo_days)\n",
    "            ve = vs+relativedelta(months=CFG.wf_test_months)\n",
    "            if ve > ad.max(): break\n",
    "            folds.append((ts,te,vs,ve)); ts += relativedelta(months=CFG.wf_step_months)\n",
    "        if len(folds) < CFG.wf_min_folds:\n",
    "            tracker.mark_completed(STEP,{\"n\":0,\"reason\":\"insufficient_folds\"}); continue\n",
    "\n",
    "        mh_cands = all_candidates[(all_candidates[\"market\"]==market)&(all_candidates[\"horizon\"]==ht)]\n",
    "        pp = os.path.join(CFG.walkforward_dir(market), \"wf_partial_%s.parquet\"%ht)\n",
    "        wf_rows = []; ck = set()\n",
    "        if os.path.exists(pp):\n",
    "            pdf = pd.read_parquet(pp); wf_rows = pdf.to_dict('records')\n",
    "            ck = set(zip(pdf[\"strategy_id\"], pdf[\"fold_idx\"].astype(int)))\n",
    "\n",
    "        for fi, (ts,te,vs,ve) in enumerate(folds):\n",
    "            di = valid.index.get_level_values(0)\n",
    "            test_data = valid[(di>=vs)&(di<ve)]\n",
    "            for sid in top_ids:\n",
    "                if (sid,fi) in ck: continue\n",
    "                try:\n",
    "                    cr = mh_cands[mh_cands[\"strategy_id\"]==sid].iloc[0]\n",
    "                    tm = build_mask(test_data, cr[\"type\"], cr, sid, market, ht, feat_cols)\n",
    "                    tr = test_data.loc[tm, fwd_col].values\n",
    "                    tl = test_data.loc[tm, label_col].values if label_col in test_data.columns else None\n",
    "                    if len(tr)<20: continue\n",
    "                    _hd2 = int(ht.replace(\"d\",\"\"))\n",
    "                    edge = evaluate_strategy_edge_v3(tr, tl, horizon_days=_hd2)\n",
    "                    if edge is None: continue\n",
    "\n",
    "                    # Turnover\n",
    "                    td_dates = test_data.index.get_level_values(0).unique().sort_values()\n",
    "                    rd = td_dates[::21]; tos = []; ps = None\n",
    "                    for dt in rd:\n",
    "                        try:\n",
    "                            dix = test_data.index.get_level_values(0)==dt\n",
    "                            ds = tm[dix]; sel = set(test_data.index[dix][ds].get_level_values(1))\n",
    "                        except: continue\n",
    "                        if ps is not None and (ps or sel):\n",
    "                            u = len(ps|sel)\n",
    "                            if u>0: tos.append(len(ps^sel)/u)\n",
    "                        ps = sel\n",
    "                    at = float(np.mean(tos)*252/21) if tos else 0.0\n",
    "\n",
    "                    edge[\"strategy_id\"]=sid; edge[\"market\"]=market; edge[\"horizon\"]=ht\n",
    "                    edge[\"fold_idx\"]=fi; edge[\"turnover\"]=at\n",
    "                    edge[\"test_start\"]=str(vs.date()); edge[\"test_end\"]=str(ve.date())\n",
    "                    wf_rows.append(edge)\n",
    "                except Exception as _e:\n",
    "                    logger.debug(\"WF err %s fold %d: %s\" % (sid, fi, str(_e)[:80]))\n",
    "            if wf_rows: pd.DataFrame(wf_rows).to_parquet(pp)\n",
    "            print(\"    Fold %d/%d\" % (fi+1, len(folds)))\n",
    "\n",
    "        wdf = pd.DataFrame(wf_rows) if wf_rows else pd.DataFrame(columns=_WF_COLS)\n",
    "        wdf.to_parquet(wp); all_wf_results.append(wdf)\n",
    "        if os.path.exists(pp): os.remove(pp)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(wdf),\"folds\":len(folds),\"time\":time.time()-t0})\n",
    "        gc.collect()\n",
    "\n",
    "wf_results = pd.concat(all_wf_results, ignore_index=True) if all_wf_results else pd.DataFrame(columns=_WF_COLS)\n",
    "print(\"WF results: %d | Strategies: %d\" % (len(wf_results), wf_results[\"strategy_id\"].nunique() if len(wf_results)>0 else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Overfitting Control + FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"overfitting\"\n",
    "fp_ov = os.path.join(CFG.global_eval_dir, \"filtered.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    filtered = pd.read_parquet(fp_ov); print(\"Loaded %d filtered\"%len(filtered))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP); t0 = time.time()\n",
    "    if len(wf_results)==0:\n",
    "        filtered = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "    else:\n",
    "        stats = []\n",
    "        for sid, g in wf_results.groupby(\"strategy_id\"):\n",
    "            nf = len(g)\n",
    "            if nf<2: continue\n",
    "            fr = g[\"mean_return\"].values; fs = g[\"sharpe\"].values; fw = g[\"win_rate\"].values\n",
    "            ft = g[\"turnover\"].values if \"turnover\" in g.columns else np.zeros(nf)\n",
    "            fp_buy = g[\"precision_buy\"].values if \"precision_buy\" in g.columns else fw\n",
    "            fc = g[\"cvar_95\"].values if \"cvar_95\" in g.columns else np.zeros(nf)\n",
    "\n",
    "            stability = float((fr>0).mean())\n",
    "            an = g[\"n_trades\"].values; tt = int(an.sum())\n",
    "\n",
    "            from scipy import stats as sp\n",
    "            if tt >= CFG.bootstrap_min_samples:\n",
    "                tw = int((fw*an).sum())\n",
    "                bs = np.random.binomial(tt, tw/max(1,tt), CFG.bootstrap_n)/tt\n",
    "                ci_lo = float(np.percentile(bs, (1-CFG.bootstrap_ci)/2*100))\n",
    "            else: ci_lo = 0.0\n",
    "\n",
    "            if tt>0:\n",
    "                tw_int = int((fw*an).sum())\n",
    "                pval = sp.binomtest(tw_int, tt, 0.5, alternative='greater').pvalue\n",
    "            else: pval = 1.0\n",
    "\n",
    "            mkt = g[\"market\"].iloc[0] if \"market\" in g.columns else \"\"\n",
    "            hor = g[\"horizon\"].iloc[0] if \"horizon\" in g.columns else \"\"\n",
    "            stats.append({\n",
    "                \"strategy_id\":sid, \"market\":mkt, \"horizon\":hor,\n",
    "                \"n_folds\":nf, \"stability\":stability,\n",
    "                \"mean_sharpe\":float(np.mean(fs)), \"mean_win_rate\":float(np.mean(fw)),\n",
    "                \"mean_precision_buy\":float(np.mean(fp_buy)),\n",
    "                \"mean_cvar_95\":float(np.mean(fc)),\n",
    "                \"mean_turnover\":float(np.mean(ft)),\n",
    "                \"total_trades\":tt, \"wr_ci_low\":ci_lo, \"pval\":pval,\n",
    "                \"mean_return\":float(np.mean(fr)),\n",
    "            })\n",
    "\n",
    "        sdf = pd.DataFrame(stats)\n",
    "        if CFG.apply_multiple_testing_correction and len(sdf)>0:\n",
    "            from statsmodels.stats.multitest import multipletests\n",
    "            rej, pc, _, _ = multipletests(sdf[\"pval\"].fillna(1).values, alpha=0.05, method='fdr_bh')\n",
    "            sdf[\"fdr_reject\"] = rej\n",
    "        else: sdf[\"fdr_reject\"] = True\n",
    "\n",
    "        mask = (\n",
    "            (sdf[\"stability\"]>=CFG.min_stability) &\n",
    "            (sdf[\"mean_sharpe\"]>=CFG.min_sharpe) &\n",
    "            (sdf[\"mean_win_rate\"]>=CFG.min_win_rate) &\n",
    "            (sdf[\"mean_precision_buy\"]>=CFG.min_precision_buy) &\n",
    "            (sdf[\"wr_ci_low\"]>=0.48) &\n",
    "            (sdf[\"fdr_reject\"]==True)\n",
    "        )\n",
    "        filtered = sdf[mask].sort_values(\"mean_sharpe\", ascending=False).copy()\n",
    "        print(\"Overfitting: %d -> %d\" % (len(sdf), len(filtered)))\n",
    "        filtered.to_parquet(fp_ov)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(filtered),\"time\":time.time()-t0})\n",
    "        gc.collect()\n",
    "\n",
    "print(\"Filtered: %d\" % len(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Beta-Neutral Analysis (Part 4)\n",
    "\n",
    "Strip market beta from each strategy. Reject if Sharpe collapses\n",
    "(beta-driven performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"beta_neutral\"\n",
    "bn_path = os.path.join(CFG.global_eval_dir, \"beta_neutral.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    beta_filtered = pd.read_parquet(bn_path); print(\"Loaded %d beta-neutral\"%len(beta_filtered))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if len(filtered)==0:\n",
    "        beta_filtered = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "    else:\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        bn_stats = []\n",
    "        for _, row in filtered.iterrows():\n",
    "            sid = row[\"strategy_id\"]; mkt = row[\"market\"]\n",
    "            sg = wf_results[wf_results[\"strategy_id\"]==sid].sort_values(\"fold_idx\")\n",
    "            if len(sg)<2: continue\n",
    "\n",
    "            # Get market returns for each fold's test period\n",
    "            mkt_idx = market_indices.get(mkt, pd.DataFrame())\n",
    "            if \"close\" not in mkt_idx.columns or mkt_idx.empty:\n",
    "                bn_stats.append({**row.to_dict(), \"beta\":0.0, \"sharpe_neutral\":row[\"mean_sharpe\"]})\n",
    "                continue\n",
    "\n",
    "            strat_rets = []; mkt_rets = []\n",
    "            for _, fr in sg.iterrows():\n",
    "                ts = pd.Timestamp(fr[\"test_start\"]); te = pd.Timestamp(fr[\"test_end\"])\n",
    "                mp = mkt_idx[\"close\"].loc[ts:te]\n",
    "                if len(mp)>=2:\n",
    "                    mr = (mp.iloc[-1]/mp.iloc[0])-1\n",
    "                    strat_rets.append(fr[\"mean_return\"]); mkt_rets.append(mr)\n",
    "\n",
    "            if len(strat_rets)<3:\n",
    "                bn_stats.append({**row.to_dict(), \"beta\":0.0, \"sharpe_neutral\":row[\"mean_sharpe\"]})\n",
    "                continue\n",
    "\n",
    "            sr = np.array(strat_rets); mkr = np.array(mkt_rets)\n",
    "            lr = LinearRegression().fit(mkr.reshape(-1,1), sr)\n",
    "            beta = float(lr.coef_[0])\n",
    "            excess = sr - beta * mkr\n",
    "            es = float(np.std(excess, ddof=1))\n",
    "            sharpe_n = float(np.mean(excess)/es*np.sqrt(252/21)) if es>1e-8 else 0.0\n",
    "\n",
    "            d = row.to_dict()\n",
    "            d[\"beta\"] = beta; d[\"sharpe_neutral\"] = sharpe_n\n",
    "            bn_stats.append(d)\n",
    "\n",
    "        bdf = pd.DataFrame(bn_stats)\n",
    "        # Reject if neutral Sharpe < 50% of raw Sharpe (beta-driven)\n",
    "        before = len(bdf)\n",
    "        beta_filtered = bdf[bdf[\"sharpe_neutral\"] >= bdf[\"mean_sharpe\"]*0.5].copy()\n",
    "        print(\"Beta-neutral: %d -> %d (rejected %d beta-driven)\" % (before, len(beta_filtered), before-len(beta_filtered)))\n",
    "        beta_filtered.to_parquet(bn_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(beta_filtered)})\n",
    "\n",
    "print(\"Beta-neutral strategies: %d\" % len(beta_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Return Distribution Safety (Part 5)\n",
    "\n",
    "Reject strategies where:\n",
    "- CVaR > 3× average win\n",
    "- Single loss > 5× median gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"dist_safety\"\n",
    "ds_path = os.path.join(CFG.global_eval_dir, \"dist_safe.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    dist_safe = pd.read_parquet(ds_path); print(\"Loaded %d dist-safe\"%len(dist_safe))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if len(beta_filtered)==0:\n",
    "        dist_safe = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "    else:\n",
    "        # Use edge_results for detailed return stats\n",
    "        er_map = edge_results.set_index(\"strategy_id\")[[\"cvar_95\",\"max_loss\",\"median_return\"]].to_dict('index') if len(edge_results)>0 else {}\n",
    "        safe_ids = []\n",
    "        for _, row in beta_filtered.iterrows():\n",
    "            sid = row[\"strategy_id\"]\n",
    "            er = er_map.get(sid, {})\n",
    "            cvar = abs(er.get(\"cvar_95\", 0))\n",
    "            avg_win = abs(row.get(\"mean_return\", 0.001))\n",
    "            max_loss = abs(er.get(\"max_loss\", 0))\n",
    "            med_gain = abs(er.get(\"median_return\", 0.001))\n",
    "\n",
    "            reject = False\n",
    "            if avg_win > 1e-8 and cvar > CFG.max_cvar_to_avgwin_ratio * avg_win:\n",
    "                reject = True\n",
    "            if med_gain > 1e-8 and max_loss > CFG.max_single_loss_to_median_ratio * med_gain:\n",
    "                reject = True\n",
    "            if not reject:\n",
    "                safe_ids.append(sid)\n",
    "\n",
    "        dist_safe = beta_filtered[beta_filtered[\"strategy_id\"].isin(safe_ids)].copy()\n",
    "        print(\"Distribution safety: %d -> %d\" % (len(beta_filtered), len(dist_safe)))\n",
    "        dist_safe.to_parquet(ds_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(dist_safe)})\n",
    "\n",
    "print(\"Distribution-safe: %d\" % len(dist_safe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Transaction Cost Stress Test (Part 6)\n",
    "\n",
    "Re-evaluate under multiple cost scenarios: (5,2), (10,5), (15,5) bps.\n",
    "Strategy must survive ≥ 2 scenarios with positive EV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"cost_stress\"\n",
    "cs_path = os.path.join(CFG.global_eval_dir, \"cost_stressed.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    cost_survived = pd.read_parquet(cs_path); print(\"Loaded %d cost-stressed\"%len(cost_survived))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if len(dist_safe)==0:\n",
    "        cost_survived = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "    else:\n",
    "        base_cost = CFG.total_cost_bps\n",
    "        survival_count = {}\n",
    "\n",
    "        for cost_bps, slip_bps in CFG.cost_stress_scenarios:\n",
    "            new_total = cost_bps + slip_bps\n",
    "            cost_delta = 2 * (new_total - base_cost) / 10000  # per-trade adjustment\n",
    "\n",
    "            for sid in dist_safe[\"strategy_id\"]:\n",
    "                sg = wf_results[wf_results[\"strategy_id\"]==sid]\n",
    "                if sg.empty: continue\n",
    "                adj_ret = sg[\"mean_return\"] - cost_delta\n",
    "                if adj_ret.mean() > 0:\n",
    "                    survival_count[sid] = survival_count.get(sid, 0) + 1\n",
    "\n",
    "        survived_ids = [sid for sid, cnt in survival_count.items()\n",
    "                        if cnt >= CFG.min_cost_scenarios_survived]\n",
    "        cost_survived = dist_safe[dist_safe[\"strategy_id\"].isin(survived_ids)].copy()\n",
    "        cost_survived[\"cost_scenarios_survived\"] = cost_survived[\"strategy_id\"].map(\n",
    "            lambda s: survival_count.get(s, 0))\n",
    "        print(\"Cost stress: %d -> %d (need %d/%d scenarios)\" % (\n",
    "            len(dist_safe), len(cost_survived), CFG.min_cost_scenarios_survived,\n",
    "            len(CFG.cost_stress_scenarios)))\n",
    "        cost_survived.to_parquet(cs_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(cost_survived)})\n",
    "\n",
    "print(\"Cost-survived: %d\" % len(cost_survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Strategy De-duplication + Signal Diversity (Parts 3 & 9)\n",
    "\n",
    "1. **Correlation matrix**: |corr| > 0.85 → equivalent\n",
    "2. **Hierarchical clustering**: keep best per cluster\n",
    "3. **Signal diversity**: cluster by entry-timing overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "STEP = \"dedup_diversity\"\n",
    "dd_path = os.path.join(CFG.global_eval_dir, \"deduped.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    deduped = pd.read_parquet(dd_path); print(\"Loaded %d deduped\"%len(deduped))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if len(cost_survived)<5:\n",
    "        deduped = cost_survived.copy()\n",
    "    else:\n",
    "        pivot = wf_results.pivot_table(values=\"mean_return\", index=\"fold_idx\",\n",
    "                                       columns=\"strategy_id\", aggfunc=\"first\")\n",
    "        sids = cost_survived[\"strategy_id\"].tolist()\n",
    "        pivot = pivot[[c for c in pivot.columns if c in sids]].dropna(axis=1,how='all').fillna(0)\n",
    "\n",
    "        if pivot.shape[1]>=5:\n",
    "            corr = pivot.corr().values\n",
    "            dist = 1-np.abs(corr); np.fill_diagonal(dist,0); dist = np.maximum(dist,0)\n",
    "            nc = max(3, min(20, len(pivot.columns)//3))\n",
    "            try:\n",
    "                cl = AgglomerativeClustering(n_clusters=nc, metric='precomputed', linkage='average')\n",
    "            except TypeError:\n",
    "                cl = AgglomerativeClustering(n_clusters=nc, affinity='precomputed', linkage='average')\n",
    "            labels = cl.fit_predict(dist)\n",
    "            cm = dict(zip(pivot.columns, labels))\n",
    "            df = cost_survived.copy()\n",
    "            df[\"cluster\"] = df[\"strategy_id\"].map(cm)\n",
    "            df = df.sort_values(\"mean_sharpe\", ascending=False)\n",
    "            best = df.dropna(subset=[\"cluster\"]).groupby(\"cluster\").first().reset_index(drop=True)\n",
    "            uncl = df[df[\"cluster\"].isna()]\n",
    "            deduped = pd.concat([best,uncl], ignore_index=True)\n",
    "            print(\"Clustering: %d clusters, %d -> %d strategies\" % (nc, len(cost_survived), len(deduped)))\n",
    "        else:\n",
    "            deduped = cost_survived.copy()\n",
    "\n",
    "    if len(deduped)>0: deduped.to_parquet(dd_path)\n",
    "    tracker.mark_completed(STEP, {\"n\":len(deduped)})\n",
    "\n",
    "print(\"Deduped: %d\" % len(deduped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Regime Robustness (Part 7)\n",
    "\n",
    "Evaluate in 4 regimes: bull, bear, high-vol, low-vol.\n",
    "Worst regime must be ≥ 70% of overall mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"regime\"\n",
    "rg_path = os.path.join(CFG.global_eval_dir, \"regime_filtered.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    regime_ok = pd.read_parquet(rg_path); print(\"Loaded %d regime-ok\"%len(regime_ok))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if not CFG.evaluate_by_regime or len(deduped)==0 or len(wf_results)==0:\n",
    "        regime_ok = deduped.copy() if len(deduped)>0 else pd.DataFrame()\n",
    "        if len(regime_ok)>0: regime_ok.to_parquet(rg_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(regime_ok)}); print(\"Regime: skipped\")\n",
    "    else:\n",
    "        wr = wf_results.copy(); wr[\"regime\"] = \"unknown\"\n",
    "        for idx, row in wr.iterrows():\n",
    "            mkt = row.get(\"market\",\"US\")\n",
    "            ts = pd.Timestamp(row[\"test_start\"]); te = pd.Timestamp(row[\"test_end\"])\n",
    "            mi = market_indices.get(mkt, pd.DataFrame())\n",
    "            if \"close\" not in mi.columns or mi.empty: continue\n",
    "            mc = mi[\"close\"]; period = mc.loc[ts:te]\n",
    "            if len(period)<2: continue\n",
    "            ret = (period.iloc[-1]/period.iloc[0])-1\n",
    "            vol = period.pct_change().std() * np.sqrt(252)\n",
    "            mc_pre = mc.loc[:ts]  # only use data up to test start (no lookahead)\n",
    "            vol_med = mc_pre.pct_change().rolling(252).std().median() * np.sqrt(252) if len(mc_pre)>252 else vol\n",
    "            if ret>0 and vol<=vol_med: wr.at[idx,\"regime\"] = \"bull_lowvol\"\n",
    "            elif ret>0: wr.at[idx,\"regime\"] = \"bull_highvol\"\n",
    "            elif vol<=vol_med: wr.at[idx,\"regime\"] = \"bear_lowvol\"\n",
    "            else: wr.at[idx,\"regime\"] = \"bear_highvol\"\n",
    "\n",
    "        sids = set(deduped[\"strategy_id\"])\n",
    "        regime_stats = []\n",
    "        for sid, g in wr[wr[\"strategy_id\"].isin(sids)].groupby(\"strategy_id\"):\n",
    "            overall = g[\"sharpe\"].mean()\n",
    "            regimes = g.groupby(\"regime\")[\"sharpe\"].mean()\n",
    "            worst = regimes.min() if len(regimes)>0 else 0\n",
    "            ratio = worst/overall if abs(overall)>1e-8 else 0\n",
    "            regime_stats.append({\"strategy_id\":sid, \"regime_ratio\":ratio, \"worst_regime_sharpe\":worst})\n",
    "\n",
    "        rdf = pd.DataFrame(regime_stats)\n",
    "        merged = deduped.merge(rdf, on=\"strategy_id\", how=\"left\")\n",
    "        merged[\"regime_ratio\"] = merged[\"regime_ratio\"].fillna(0)\n",
    "        before = len(merged)\n",
    "        regime_ok = merged[merged[\"regime_ratio\"]>=CFG.min_regime_performance_ratio].copy()\n",
    "        if len(regime_ok)==0 and len(merged)>0:\n",
    "            regime_ok = merged.nlargest(max(1,len(merged)//2), \"regime_ratio\").copy()\n",
    "            logger.warning(\"Regime filter relaxed\")\n",
    "        print(\"Regime: %d -> %d\" % (before, len(regime_ok)))\n",
    "        regime_ok.to_parquet(rg_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(regime_ok)})\n",
    "\n",
    "print(\"Regime-ok: %d\" % len(regime_ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Turnover Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"turnover\"\n",
    "to_path = os.path.join(CFG.global_eval_dir, \"turnover_ok.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    turnover_ok = pd.read_parquet(to_path); print(\"Loaded %d turnover-ok\"%len(turnover_ok))\n",
    "else:\n",
    "    if len(regime_ok)==0:\n",
    "        turnover_ok = pd.DataFrame()\n",
    "    else:\n",
    "        before = len(regime_ok)\n",
    "        turnover_ok = regime_ok[regime_ok[\"mean_turnover\"]<=CFG.max_turnover].copy()\n",
    "        print(\"Turnover: %d -> %d\" % (before, len(turnover_ok)))\n",
    "    if len(turnover_ok)>0: turnover_ok.to_parquet(to_path)\n",
    "    tracker.mark_completed(STEP, {\"n\":len(turnover_ok)})\n",
    "\n",
    "print(\"Turnover-ok: %d\" % len(turnover_ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Meta-Model Gate (Part 8)\n",
    "\n",
    "Train a secondary model to predict P(strategy success | market state).\n",
    "If meta-score < threshold → FORCE NO TRADE. Overrides all signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"meta_model\"\n",
    "mm_path = os.path.join(CFG.global_eval_dir, \"meta_scored.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    meta_scored = pd.read_parquet(mm_path); print(\"Loaded %d meta-scored\"%len(meta_scored))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if not CFG.use_meta_model or len(turnover_ok)==0 or len(wf_results)==0:\n",
    "        meta_scored = turnover_ok.copy()\n",
    "        if len(meta_scored)>0: meta_scored[\"meta_score\"] = 1.0\n",
    "        tracker.mark_completed(STEP, {\"n\":len(meta_scored),\"skipped\":True})\n",
    "    else:\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "        def _build_meta_features(ts_date):\n",
    "            \"\"\"Build 12-dim meta-feature vector at a given timestamp.\n",
    "\n",
    "            [0-3] market: 20d mom, 60d mom, 20d vol, 60d vol\n",
    "            [4-8] macro: yield_curve_slope, vix_regime, dxy_mom_60d, gold_mom_60d, oil_mom_60d\n",
    "            [9]   sentiment: vix_term_structure\n",
    "            [10-11] reserved padding (zeros)\n",
    "            \"\"\"\n",
    "            mf = [0.0] * 12\n",
    "            # Market features (original 4)\n",
    "            for _mkt_name in CFG.markets:\n",
    "                _mi = market_indices.get(_mkt_name, pd.DataFrame())\n",
    "                if \"close\" not in _mi.columns or _mi.empty:\n",
    "                    continue\n",
    "                _mc = _mi[\"close\"]\n",
    "                _pre = _mc.loc[:ts_date]\n",
    "                if len(_pre) < 60:\n",
    "                    continue\n",
    "                mf[0] = float(_pre.pct_change(20).iloc[-1]) if len(_pre) > 20 else 0\n",
    "                mf[1] = float(_pre.pct_change(60).iloc[-1]) if len(_pre) > 60 else 0\n",
    "                mf[2] = float(_pre.pct_change().rolling(20).std().iloc[-1]) if len(_pre) > 20 else 0\n",
    "                mf[3] = float(_pre.pct_change().rolling(60).std().iloc[-1]) if len(_pre) > 60 else 0\n",
    "                break  # use first available market\n",
    "\n",
    "            # Macro features (5 new)\n",
    "            if len(macro_data) > 0:\n",
    "                _md = macro_data.loc[:ts_date]\n",
    "                if len(_md) > 0:\n",
    "                    last = _md.iloc[-1]\n",
    "                    mf[4] = float(last.get(\"yield_curve_slope\", 0)) if not np.isnan(last.get(\"yield_curve_slope\", 0)) else 0\n",
    "                    mf[5] = float(last.get(\"vix_regime\", 1)) if not np.isnan(last.get(\"vix_regime\", 1)) else 1\n",
    "                    mf[6] = float(last.get(\"dxy_mom_60d\", 0)) if not np.isnan(last.get(\"dxy_mom_60d\", 0)) else 0\n",
    "                    mf[7] = float(last.get(\"gold_mom_60d\", 0)) if not np.isnan(last.get(\"gold_mom_60d\", 0)) else 0\n",
    "                    mf[8] = float(last.get(\"oil_mom_60d\", 0)) if not np.isnan(last.get(\"oil_mom_60d\", 0)) else 0\n",
    "\n",
    "            # Sentiment feature (1 new)\n",
    "            if len(sentiment_data) > 0:\n",
    "                _sd = sentiment_data.loc[:ts_date]\n",
    "                if len(_sd) > 0:\n",
    "                    mf[9] = float(_sd[\"vix_term_structure\"].iloc[-1]) if not np.isnan(_sd[\"vix_term_structure\"].iloc[-1]) else 0\n",
    "\n",
    "            # [10-11] reserved padding = 0\n",
    "            return np.nan_to_num(mf).tolist()\n",
    "\n",
    "        # Build training data: per-fold meta-features → success label\n",
    "        sids = set(turnover_ok[\"strategy_id\"])\n",
    "        meta_X = []; meta_y = []\n",
    "        for _, row in wf_results[wf_results[\"strategy_id\"].isin(sids)].iterrows():\n",
    "            ts = pd.Timestamp(row[\"test_start\"])\n",
    "            mf = _build_meta_features(ts)\n",
    "            # Check that at least the market features are available\n",
    "            if all(v == 0 for v in mf[:4]):\n",
    "                mkt = row.get(\"market\",\"US\")\n",
    "                mi = market_indices.get(mkt, pd.DataFrame())\n",
    "                if \"close\" not in mi.columns or mi.empty: continue\n",
    "                mc = mi[\"close\"]; pre = mc.loc[:ts]\n",
    "                if len(pre)<60: continue\n",
    "                mf[0] = float(pre.pct_change(20).iloc[-1]) if len(pre)>20 else 0\n",
    "                mf[1] = float(pre.pct_change(60).iloc[-1]) if len(pre)>60 else 0\n",
    "                mf[2] = float(pre.pct_change().rolling(20).std().iloc[-1]) if len(pre)>20 else 0\n",
    "                mf[3] = float(pre.pct_change().rolling(60).std().iloc[-1]) if len(pre)>60 else 0\n",
    "                mf = np.nan_to_num(mf).tolist()\n",
    "            meta_X.append(mf)\n",
    "            meta_y.append(1 if row[\"mean_return\"]>0 else 0)\n",
    "\n",
    "        if len(meta_X) >= 30:\n",
    "            MX = np.array(meta_X, dtype=np.float32); MY = np.array(meta_y)\n",
    "            np.nan_to_num(MX, copy=False)\n",
    "            print(\"Meta-model input dim: %d features x %d samples\" % (MX.shape[1], MX.shape[0]))\n",
    "            # Time-based split (70/30)\n",
    "            split = int(len(MX)*0.7)\n",
    "            gb = GradientBoostingClassifier(n_estimators=50, max_depth=2, random_state=CFG.seed)\n",
    "            gb.fit(MX[:split], MY[:split])\n",
    "            test_acc = float((gb.predict(MX[split:])==MY[split:]).mean())\n",
    "            logger.info(\"Meta-model test accuracy: %.2f (12-dim features)\" % test_acc)\n",
    "\n",
    "            # Score each surviving strategy's average meta-score\n",
    "            strat_meta = {}\n",
    "            for sid in sids:\n",
    "                sg = wf_results[wf_results[\"strategy_id\"]==sid]\n",
    "                scores = []\n",
    "                for _, r in sg.iterrows():\n",
    "                    mkt = r.get(\"market\",\"US\"); ts = pd.Timestamp(r[\"test_start\"])\n",
    "                    mf = _build_meta_features(ts)\n",
    "                    # Fallback: fill market features from per-market index\n",
    "                    if all(v == 0 for v in mf[:4]):\n",
    "                        mi = market_indices.get(mkt, pd.DataFrame())\n",
    "                        if \"close\" not in mi.columns: continue\n",
    "                        mc = mi[\"close\"]; pre = mc.loc[:ts]\n",
    "                        if len(pre)<60: continue\n",
    "                        mf[0] = float(pre.pct_change(20).iloc[-1]) if len(pre)>20 else 0\n",
    "                        mf[1] = float(pre.pct_change(60).iloc[-1]) if len(pre)>60 else 0\n",
    "                        mf[2] = float(pre.pct_change().rolling(20).std().iloc[-1]) if len(pre)>20 else 0\n",
    "                        mf[3] = float(pre.pct_change().rolling(60).std().iloc[-1]) if len(pre)>60 else 0\n",
    "                    mf = np.nan_to_num(mf).tolist()\n",
    "                    scores.append(gb.predict_proba(np.array([mf]))[0][1])\n",
    "                strat_meta[sid] = float(np.mean(scores)) if scores else 0.5\n",
    "\n",
    "            meta_scored = turnover_ok.copy()\n",
    "            meta_scored[\"meta_score\"] = meta_scored[\"strategy_id\"].map(strat_meta).fillna(0.5)\n",
    "\n",
    "            # Gate: remove low meta-score strategies\n",
    "            before = len(meta_scored)\n",
    "            meta_scored = meta_scored[meta_scored[\"meta_score\"]>=CFG.meta_model_threshold].copy()\n",
    "            print(\"Meta-model gate: %d -> %d (threshold=%.2f)\" % (before, len(meta_scored), CFG.meta_model_threshold))\n",
    "        else:\n",
    "            logger.warning(\"Insufficient data for meta-model (%d samples)\" % len(meta_X))\n",
    "            meta_scored = turnover_ok.copy()\n",
    "            meta_scored[\"meta_score\"] = 1.0\n",
    "\n",
    "        if len(meta_scored)>0: meta_scored.to_parquet(mm_path)\n",
    "        tracker.mark_completed(STEP, {\"n\":len(meta_scored)})\n",
    "\n",
    "print(\"Meta-scored: %d\" % len(meta_scored))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Auto Rule Tuning (Part 10)\n",
    "\n",
    "Data-driven optimization of rule thresholds via random search.\n",
    "Objective: maximize EV subject to Precision ≥ 0.6, CVaR ≤ limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"rule_tuning\"\n",
    "rt_path = os.path.join(CFG.global_eval_dir, \"tuned_rules.json\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    with open(rt_path) as f: tuned_rules = json.load(f)\n",
    "    print(\"Loaded tuned rules:\", tuned_rules)\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if not CFG.use_bayesian_tuning or len(meta_scored)==0 or len(wf_results)==0:\n",
    "        tuned_rules = {\"precision_th\": CFG.min_precision_buy, \"turnover_th\": CFG.max_turnover,\n",
    "                       \"regime_th\": CFG.min_regime_performance_ratio}\n",
    "        tracker.mark_completed(STEP, tuned_rules)\n",
    "    else:\n",
    "        best_ev = -999; best_params = None\n",
    "        np.random.seed(CFG.seed)\n",
    "\n",
    "        for _ in range(CFG.n_bayes_iterations):\n",
    "            prec_th = np.random.uniform(0.50, 0.75)\n",
    "            turn_th = np.random.uniform(1.0, CFG.max_turnover)\n",
    "            regime_th = np.random.uniform(0.3, 0.9)\n",
    "\n",
    "            mask = (\n",
    "                (meta_scored[\"mean_precision_buy\"]>=prec_th) &\n",
    "                (meta_scored[\"mean_turnover\"]<=turn_th)\n",
    "            )\n",
    "            if \"regime_ratio\" in meta_scored.columns:\n",
    "                mask = mask & (meta_scored[\"regime_ratio\"]>=regime_th)\n",
    "\n",
    "            subset = meta_scored[mask]\n",
    "            if len(subset)<2: continue\n",
    "\n",
    "            sids = set(subset[\"strategy_id\"])\n",
    "            sw = wf_results[wf_results[\"strategy_id\"].isin(sids)]\n",
    "            if sw.empty: continue\n",
    "\n",
    "            port_ret = sw.groupby(\"fold_idx\")[\"mean_return\"].mean()\n",
    "            ev = float(port_ret.mean())\n",
    "            pr = float(subset[\"mean_precision_buy\"].mean())\n",
    "\n",
    "            if pr >= 0.6 and ev > best_ev:\n",
    "                best_ev = ev\n",
    "                best_params = {\"precision_th\":round(prec_th,3), \"turnover_th\":round(turn_th,2),\n",
    "                               \"regime_th\":round(regime_th,3), \"ev\":round(ev,6), \"n_strats\":len(subset)}\n",
    "\n",
    "        tuned_rules = best_params if best_params else {\n",
    "            \"precision_th\": CFG.min_precision_buy, \"turnover_th\": CFG.max_turnover,\n",
    "            \"regime_th\": CFG.min_regime_performance_ratio}\n",
    "        print(\"Tuned rules:\", tuned_rules)\n",
    "        with open(rt_path,'w') as f: json.dump(tuned_rules, f, indent=2)\n",
    "        tracker.mark_completed(STEP, tuned_rules)\n",
    "\n",
    "print(\"Tuned rules:\", tuned_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Final Strategy Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"scoring\"\n",
    "sc_path = os.path.join(CFG.global_eval_dir, \"scored.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    scored = pd.read_parquet(sc_path); print(\"Loaded %d scored\"%len(scored))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    if len(meta_scored)==0:\n",
    "        scored = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "    else:\n",
    "        # Apply tuned rules\n",
    "        df = meta_scored.copy()\n",
    "        prec_th = tuned_rules.get(\"precision_th\", CFG.min_precision_buy)\n",
    "        turn_th = tuned_rules.get(\"turnover_th\", CFG.max_turnover)\n",
    "\n",
    "        mask = (df[\"mean_precision_buy\"]>=prec_th) & (df[\"mean_turnover\"]<=turn_th)\n",
    "        df = df[mask].copy()\n",
    "\n",
    "        if len(df)==0:\n",
    "            scored = pd.DataFrame(); tracker.mark_completed(STEP,{\"n\":0})\n",
    "        else:\n",
    "            def norm(s):\n",
    "                r = s.max()-s.min()\n",
    "                return (s-s.min())/r if r>1e-8 else pd.Series(0.5,index=s.index)\n",
    "\n",
    "            df[\"s_stability\"] = norm(df[\"stability\"])\n",
    "            df[\"s_sharpe\"] = norm(df[\"mean_sharpe\"])\n",
    "            df[\"s_precision\"] = norm(df[\"mean_precision_buy\"])\n",
    "            lift_map = edge_results.set_index(\"strategy_id\")[\"lift\"].to_dict() if len(edge_results)>0 else {}\n",
    "            df[\"lift\"] = df[\"strategy_id\"].map(lift_map).fillna(0)\n",
    "            df[\"s_lift\"] = norm(df[\"lift\"])\n",
    "            df[\"s_sample\"] = norm(np.log1p(df[\"total_trades\"]))\n",
    "            to_norm = norm(df[\"mean_turnover\"]) if \"mean_turnover\" in df.columns else 0\n",
    "\n",
    "            df[\"composite\"] = (\n",
    "                CFG.w_stability*df[\"s_stability\"] + CFG.w_sharpe*df[\"s_sharpe\"]\n",
    "                + CFG.w_precision*df[\"s_precision\"] + CFG.w_lift*df[\"s_lift\"]\n",
    "                + CFG.w_sample*df[\"s_sample\"] - CFG.penalty_turnover*to_norm\n",
    "            )\n",
    "\n",
    "            # --- Macro Veto: halve scores during extreme macro stress ---\n",
    "            if CFG.enable_macro_features and len(macro_data) > 0:\n",
    "                try:\n",
    "                    latest_macro = macro_data.iloc[-1]\n",
    "                    vr = latest_macro.get(\"vix_regime\", 1.0)\n",
    "                    yc_inv = latest_macro.get(\"yield_curve_inverted\", 0.0)\n",
    "                    if not np.isnan(vr) and not np.isnan(yc_inv):\n",
    "                        if vr > CFG.macro_veto_vix_multiple and yc_inv > 0.5:\n",
    "                            before_veto = df[\"composite\"].mean()\n",
    "                            df[\"composite\"] = df[\"composite\"] * 0.5\n",
    "                            print(\"MACRO VETO: VIX regime=%.2f (>%.1fx), yield curve inverted -> composite halved (%.4f -> %.4f)\" % (\n",
    "                                vr, CFG.macro_veto_vix_multiple, before_veto, df[\"composite\"].mean()))\n",
    "                        else:\n",
    "                            print(\"Macro check: VIX regime=%.2f, yield_inverted=%s -> no veto\" % (vr, bool(yc_inv > 0.5)))\n",
    "                except Exception as _e:\n",
    "                    logger.debug(\"Macro veto check error: %s\" % str(_e)[:60])\n",
    "\n",
    "            # Keep top N per market\n",
    "            parts = []\n",
    "            for (m,h), g in df.groupby([\"market\",\"horizon\"]):\n",
    "                parts.append(g.nlargest(CFG.portfolio_max_strategies, \"composite\"))\n",
    "            scored = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame()\n",
    "            scored = scored.sort_values(\"composite\", ascending=False).reset_index(drop=True)\n",
    "            scored[\"rank\"] = range(1, len(scored)+1)\n",
    "            scored.to_parquet(sc_path)\n",
    "            tracker.mark_completed(STEP, {\"n\":len(scored)})\n",
    "\n",
    "print(\"Scored: %d\" % len(scored))\n",
    "if len(scored)>0:\n",
    "    print(scored[[\"rank\",\"strategy_id\",\"market\",\"horizon\",\"composite\",\n",
    "                  \"mean_sharpe\",\"mean_precision_buy\",\"mean_turnover\"]].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Portfolio-Level Validation (Part 12)\n",
    "\n",
    "Evaluate the **system**, not individual strategies:\n",
    "- Max portfolio drawdown\n",
    "- Monthly consistency\n",
    "- Cost-adjusted Sharpe\n",
    "- Capital concentration risk (no strategy > 30% risk budget)\n",
    "- Portfolio CVaR must improve vs any single strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"portfolio\"\n",
    "pp = os.path.join(CFG.global_eval_dir, \"portfolio.json\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    with open(pp) as f: portfolio_results = json.load(f)\n",
    "    print(\"Portfolio loaded.\")\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    portfolio_results = {\"per_market\":{}, \"cross_market\":{}, \"validation\":{}}\n",
    "    final_ids = scored[\"strategy_id\"].tolist() if len(scored)>0 else []\n",
    "\n",
    "    for mkt in CFG.markets:\n",
    "        mi = [s for s in final_ids if s.startswith(mkt+\"_\")]\n",
    "        if not mi: continue\n",
    "        mw = wf_results[wf_results[\"strategy_id\"].isin(mi)]\n",
    "        if mw.empty: continue\n",
    "        pr = mw.groupby(\"fold_idx\")[\"mean_return\"].mean()\n",
    "        ps = float(pr.mean()/pr.std()*np.sqrt(252/21)) if pr.std()>1e-8 else 0\n",
    "        # Concentration check\n",
    "        n_strats = len(mi)\n",
    "        max_weight = 100.0/n_strats if n_strats>0 else 100\n",
    "        conc_ok = max_weight <= CFG.max_strategy_risk_budget_pct\n",
    "\n",
    "        # Portfolio CVaR\n",
    "        so = np.sort(pr.values); nt = max(1,int(0.05*len(so)))\n",
    "        port_cvar = float(so[:nt].mean()) if len(so)>0 else 0\n",
    "        # Best single strategy CVaR (most negative = worst tail)\n",
    "        best_cvar = -np.inf\n",
    "        for sid in mi:\n",
    "            sg = wf_results[wf_results[\"strategy_id\"]==sid]\n",
    "            if len(sg)>0:\n",
    "                sr = sg[\"mean_return\"].values\n",
    "                sso = np.sort(sr); snt = max(1,int(0.05*len(sso)))\n",
    "                sc = float(sso[:snt].mean()) if len(sso)>0 else 0\n",
    "                best_cvar = max(best_cvar, sc)\n",
    "        cvar_improved = port_cvar > best_cvar  # portfolio tail better than best individual\n",
    "\n",
    "        portfolio_results[\"per_market\"][mkt] = {\n",
    "            \"n_strategies\":len(mi), \"sharpe\":round(ps,4),\n",
    "            \"total_return\":round(float(pr.sum()),6),\n",
    "            \"win_folds\":int((pr>0).sum()), \"total_folds\":len(pr),\n",
    "            \"concentration_ok\":conc_ok, \"max_weight_pct\":round(max_weight,1),\n",
    "            \"portfolio_cvar\":round(port_cvar,6), \"cvar_improved\":cvar_improved,\n",
    "        }\n",
    "\n",
    "    if final_ids and len(wf_results)>0:\n",
    "        cw = wf_results[wf_results[\"strategy_id\"].isin(final_ids)]\n",
    "        if not cw.empty:\n",
    "            cr = cw.groupby(\"fold_idx\")[\"mean_return\"].mean()\n",
    "            cs = float(cr.mean()/cr.std()*np.sqrt(252/21)) if cr.std()>1e-8 else 0\n",
    "            mdd_cum = np.cumsum(cr.values); mdd_rm = np.maximum.accumulate(mdd_cum)\n",
    "            mdd = float(np.min(mdd_cum-mdd_rm))\n",
    "            portfolio_results[\"cross_market\"] = {\n",
    "                \"n_strategies\":len(final_ids), \"sharpe\":round(cs,4),\n",
    "                \"total_return\":round(float(cr.sum()),6), \"max_drawdown\":round(mdd,6),\n",
    "                \"win_folds\":int((cr>0).sum()), \"total_folds\":len(cr),\n",
    "                \"monthly_consistency\":round(float((cr>0).mean()),3),\n",
    "            }\n",
    "\n",
    "    # Validation summary\n",
    "    portfolio_results[\"validation\"] = {\n",
    "        \"answers_when_to_trade\": len(scored)>0,\n",
    "        \"answers_when_not_to_trade\": CFG.use_meta_model,\n",
    "        \"answers_how_much_to_risk\": CFG.max_strategy_risk_budget_pct<100,\n",
    "        \"answers_regime_shifts\": CFG.evaluate_by_regime,\n",
    "        \"answers_what_fails_first\": True,\n",
    "    }\n",
    "\n",
    "    with open(pp,'w') as f: json.dump(portfolio_results, f, indent=2)\n",
    "    tracker.mark_completed(STEP, portfolio_results)\n",
    "\n",
    "print(json.dumps(portfolio_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Signal → Rule → Portfolio Architecture (Part 11)\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Model Output (decile/tree/logistic probs)  │\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  ▼\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Signal Layer: Tri-state (+1 / 0 / -1)     │\n",
    "│  BUY only if excess return ≥ threshold      │\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  ▼\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Meta-Model Gate: P(success | market state) │\n",
    "│  If meta-score < threshold → NO TRADE       │\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  ▼\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Rule Layer (data-tuned thresholds):        │\n",
    "│  • Precision(BUY) ≥ tuned threshold         │\n",
    "│  • CVaR ≤ 3× avg win                        │\n",
    "│  • Beta-neutral Sharpe check                │\n",
    "│  • Cost survival ≥ 2 scenarios              │\n",
    "│  • Regime ratio ≥ 70%                        │\n",
    "│  • Turnover ≤ max                            │\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  ▼\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Trade Signal: BUY / NO TRADE               │\n",
    "│  (AVOID signals → skip entirely)            │\n",
    "└─────────────────┬───────────────────────────┘\n",
    "                  ▼\n",
    "┌─────────────────────────────────────────────┐\n",
    "│  Portfolio Engine:                           │\n",
    "│  • Equal-weight allocation                   │\n",
    "│  • No strategy > 30% risk budget            │\n",
    "│  • Cross-market diversification             │\n",
    "│  • CVaR must improve vs single strategy     │\n",
    "└─────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19b. Ablation & Module Impact Analysis\n",
    "\n",
    "Audit which data modules are active and their contribution to the feature set.\n",
    "Saves baseline on first run for future comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODULE IMPACT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "active_modules = {\n",
    "    \"axis_a_liquidity\": CFG.enable_liquidity_features,\n",
    "    \"axis_b_fundamentals\": CFG.enable_fundamental_features,\n",
    "    \"axis_c_macro\": CFG.enable_macro_features,\n",
    "    \"axis_d_sectors\": CFG.enable_sector_features,\n",
    "    \"axis_e_sentiment\": CFG.enable_sentiment_proxy,\n",
    "}\n",
    "print(\"\\nActive modules:\")\n",
    "for mod, on in active_modules.items():\n",
    "    print(\"  %s: %s\" % (mod, \"ON\" if on else \"OFF\"))\n",
    "\n",
    "# Count features by axis in the feature panels\n",
    "axis_counts = {\"price_volume\": 0, \"liquidity\": 0, \"fundamental\": 0, \"sector\": 0, \"other\": 0}\n",
    "sample_market = list(feature_panels.keys())[0] if feature_panels else None\n",
    "if sample_market:\n",
    "    fp = feature_panels[sample_market]\n",
    "    feat_cols = [c for c in fp.columns if not c.startswith(\"fwd_\") and not c.startswith(\"label_\") and not c.endswith(\"_decile\")]\n",
    "    for col in feat_cols:\n",
    "        if any(col.startswith(p) for p in [\"log_dollar_vol\", \"amihud\", \"vol_imbalance\", \"turnover_ratio\", \"gap_freq\"]):\n",
    "            axis_counts[\"liquidity\"] += 1\n",
    "        elif any(col.startswith(p) for p in [\"high_52w_pct\", \"log_market_cap\", \"trailingPE\", \"priceToBook\", \"returnOnEquity\"]):\n",
    "            axis_counts[\"fundamental\"] += 1\n",
    "        elif col.startswith(\"sector_relative\"):\n",
    "            axis_counts[\"sector\"] += 1\n",
    "        elif any(col.startswith(p) for p in [\"mom_\", \"vol_\", \"vol_change\", \"market_mom\", \"market_vol\", \"regime_\", \"market_relative\"]):\n",
    "            axis_counts[\"price_volume\"] += 1\n",
    "        else:\n",
    "            axis_counts[\"other\"] += 1\n",
    "    print(\"\\nFeature count by axis (base features, excl. deciles):\")\n",
    "    for axis, cnt in axis_counts.items():\n",
    "        print(\"  %-20s: %d\" % (axis, cnt))\n",
    "    print(\"  %-20s: %d\" % (\"TOTAL\", sum(axis_counts.values())))\n",
    "    print(\"  %-20s: %d\" % (\"+ decile versions\", len([c for c in fp.columns if c.endswith(\"_decile\")])))\n",
    "\n",
    "# Meta-model dimension check\n",
    "print(\"\\nMeta-model feature vector: 12 dimensions\")\n",
    "print(\"  [0-3]  Market: 20d mom, 60d mom, 20d vol, 60d vol\")\n",
    "print(\"  [4-8]  Macro: yield_curve_slope, vix_regime, dxy/gold/oil momentum\")\n",
    "print(\"  [9]    Sentiment: vix_term_structure\")\n",
    "print(\"  [10-11] Reserved padding\")\n",
    "\n",
    "# Macro veto status\n",
    "if CFG.enable_macro_features and len(macro_data) > 0:\n",
    "    latest = macro_data.iloc[-1]\n",
    "    print(\"\\nLatest macro state:\")\n",
    "    print(\"  yield_curve_slope: %.4f\" % latest.get(\"yield_curve_slope\", 0))\n",
    "    print(\"  yield_curve_inverted: %s\" % bool(latest.get(\"yield_curve_inverted\", 0) > 0.5))\n",
    "    print(\"  vix_regime: %.2f\" % latest.get(\"vix_regime\", 1))\n",
    "\n",
    "# Save/compare baseline\n",
    "baseline_path = os.path.join(CFG.drive_root, \"ablation_baseline.json\")\n",
    "current_report = {\n",
    "    \"active_modules\": active_modules,\n",
    "    \"feature_counts\": axis_counts,\n",
    "    \"n_scored\": len(scored),\n",
    "    \"mean_composite\": float(scored[\"composite\"].mean()) if len(scored) > 0 else 0,\n",
    "    \"mean_sharpe\": float(scored[\"mean_sharpe\"].mean()) if len(scored) > 0 and \"mean_sharpe\" in scored.columns else 0,\n",
    "}\n",
    "if os.path.exists(baseline_path):\n",
    "    with open(baseline_path) as f:\n",
    "        baseline = json.load(f)\n",
    "    print(\"\\nComparison vs baseline:\")\n",
    "    for k in [\"n_scored\", \"mean_composite\", \"mean_sharpe\"]:\n",
    "        bv = baseline.get(k, 0); cv = current_report.get(k, 0)\n",
    "        delta = cv - bv\n",
    "        print(\"  %s: %.4f -> %.4f (%+.4f)\" % (k, bv, cv, delta))\n",
    "else:\n",
    "    with open(baseline_path, \"w\") as f:\n",
    "        json.dump(current_report, f, indent=2)\n",
    "    print(\"\\nBaseline saved to %s (first run)\" % baseline_path)\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "if len(scored)==0:\n",
    "    print(\"No strategies to visualize.\")\n",
    "else:\n",
    "    fig = plt.figure(figsize=(22,20))\n",
    "    gs = gridspec.GridSpec(3,2, hspace=0.40, wspace=0.30)\n",
    "\n",
    "    # P1: Composite score\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    t20 = scored.head(20)\n",
    "    cols = ['#4CAF50' if s>=0.7 else '#FFC107' if s>=0.4 else '#F44336' for s in t20['composite']]\n",
    "    ax1.barh(range(len(t20)), t20['composite'], color=cols, edgecolor='white')\n",
    "    ax1.set_yticks(range(len(t20)))\n",
    "    ax1.set_yticklabels((t20['market']+\"/\"+t20['strategy_id'].str[-20:]), fontsize=6)\n",
    "    ax1.set_xlabel('Composite Score'); ax1.set_title('Strategy Rankings', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    # P2: Precision(BUY) vs Sharpe scatter\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    if \"mean_precision_buy\" in scored.columns:\n",
    "        ax2.scatter(scored[\"mean_precision_buy\"], scored[\"mean_sharpe\"],\n",
    "                    c=scored[\"composite\"], cmap='RdYlGn', s=60, edgecolors='k', linewidth=0.5)\n",
    "        ax2.axvline(x=CFG.min_precision_buy, color='r', ls='--', alpha=0.5, label='Min precision')\n",
    "        ax2.axhline(y=CFG.min_sharpe, color='b', ls='--', alpha=0.5, label='Min Sharpe')\n",
    "        ax2.set_xlabel('Precision(BUY)'); ax2.set_ylabel('Mean Sharpe')\n",
    "        ax2.set_title('Precision vs Sharpe', fontweight='bold'); ax2.legend(fontsize=8)\n",
    "        ax2.grid(alpha=0.3)\n",
    "\n",
    "    # P3: Equity curves\n",
    "    ax3 = fig.add_subplot(gs[1,0])\n",
    "    top5 = scored.head(5)\n",
    "    for _, r in top5.iterrows():\n",
    "        fd = wf_results[wf_results[\"strategy_id\"]==r[\"strategy_id\"]].sort_values(\"fold_idx\")\n",
    "        if len(fd)>0:\n",
    "            cum = np.cumsum(fd[\"mean_return\"].values)\n",
    "            ax3.plot(range(len(cum)), cum, 'o-', label=r[\"strategy_id\"][:25], linewidth=2)\n",
    "    ax3.axhline(y=0, color='gray', ls='--', lw=0.5)\n",
    "    ax3.set_xlabel('Fold'); ax3.set_ylabel('Cumulative Return (net)')\n",
    "    ax3.set_title('Equity Curves (Top 5)', fontweight='bold')\n",
    "    ax3.legend(fontsize=6); ax3.grid(alpha=0.3)\n",
    "\n",
    "    # P4: Per-market portfolios\n",
    "    ax4 = fig.add_subplot(gs[1,1])\n",
    "    final_ids = scored[\"strategy_id\"].tolist()\n",
    "    for mkt in CFG.markets:\n",
    "        mi = [s for s in final_ids if s.startswith(mkt+\"_\")]\n",
    "        if not mi: continue\n",
    "        mw = wf_results[wf_results[\"strategy_id\"].isin(mi)]\n",
    "        if mw.empty: continue\n",
    "        pr = mw.groupby(\"fold_idx\")[\"mean_return\"].mean().sort_index()\n",
    "        cum = np.cumsum(pr.values)\n",
    "        ax4.plot(range(len(cum)), cum, 'o-', label=\"%s (%d)\" % (mkt,len(mi)), linewidth=2)\n",
    "    ax4.axhline(y=0, color='gray', ls='--', lw=0.5)\n",
    "    ax4.set_xlabel('Fold'); ax4.set_ylabel('Cumulative Return')\n",
    "    ax4.set_title('Per-Market Portfolios', fontweight='bold')\n",
    "    ax4.legend(fontsize=8); ax4.grid(alpha=0.3)\n",
    "\n",
    "    # P5: Funnel chart (strategy count at each filter stage)\n",
    "    ax5 = fig.add_subplot(gs[2,0])\n",
    "    stages = [\"Candidates\",\"Edge\",\"WF Top\",\"Overfitting\",\"Beta-neutral\",\n",
    "              \"Dist-safe\",\"Cost-stress\",\"Deduped\",\"Regime\",\"Turnover\",\"Meta-gate\",\"Scored\"]\n",
    "    counts = [\n",
    "        len(all_candidates), len(edge_results),\n",
    "        wf_results[\"strategy_id\"].nunique() if len(wf_results)>0 else 0,\n",
    "        len(filtered), len(beta_filtered), len(dist_safe),\n",
    "        len(cost_survived), len(deduped), len(regime_ok),\n",
    "        len(turnover_ok), len(meta_scored), len(scored),\n",
    "    ]\n",
    "    ax5.barh(range(len(stages)), counts, color='steelblue', edgecolor='white')\n",
    "    ax5.set_yticks(range(len(stages))); ax5.set_yticklabels(stages, fontsize=8)\n",
    "    ax5.set_xlabel('Count'); ax5.set_title('Strategy Funnel', fontweight='bold')\n",
    "    ax5.invert_yaxis()\n",
    "    for i, v in enumerate(counts):\n",
    "        ax5.text(v+max(counts)*0.01, i, str(v), va='center', fontsize=8)\n",
    "\n",
    "    # P6: Diversification\n",
    "    ax6 = fig.add_subplot(gs[2,1])\n",
    "    sharpes = []; lbls = []\n",
    "    for mkt in CFG.markets:\n",
    "        pm = portfolio_results.get(\"per_market\",{}).get(mkt,{})\n",
    "        if pm: sharpes.append(pm[\"sharpe\"]); lbls.append(mkt)\n",
    "    cm = portfolio_results.get(\"cross_market\",{})\n",
    "    if cm: sharpes.append(cm[\"sharpe\"]); lbls.append(\"Cross-Mkt\")\n",
    "    if sharpes:\n",
    "        bc = ['#2196F3']*(len(sharpes)-1)+['#4CAF50'] if len(sharpes)>1 else ['#2196F3']\n",
    "        ax6.bar(lbls, sharpes, color=bc, edgecolor='white')\n",
    "        ax6.set_ylabel('Sharpe'); ax6.set_title('Diversification Benefit', fontweight='bold')\n",
    "        ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "    fig.suptitle('Pipeline v3 — Gap Closure Results', fontsize=16, fontweight='bold', y=1.01)\n",
    "    plt.savefig(os.path.join(CFG.drive_root, 'pipeline_v3.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Dashboard saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PIPELINE v3 COMPLETE — POST-REPORT GAP CLOSURE\")\n",
    "print(\"=\"*70)\n",
    "tracker.summary()\n",
    "\n",
    "if len(scored)>0:\n",
    "    b = scored.iloc[0]\n",
    "    print(\"\\n=== Top Strategy ===\")\n",
    "    print(\"  ID:          \", b[\"strategy_id\"])\n",
    "    print(\"  Market:      \", b.get(\"market\",\"\"))\n",
    "    print(\"  Horizon:     \", b.get(\"horizon\",\"\"))\n",
    "    print(\"  Composite:    %.4f\" % b[\"composite\"])\n",
    "    print(\"  Sharpe:       %.2f (neutral: %.2f)\" % (b[\"mean_sharpe\"], b.get(\"sharpe_neutral\", b[\"mean_sharpe\"])))\n",
    "    print(\"  Precision:    %.2f%%\" % (b[\"mean_precision_buy\"]*100))\n",
    "    print(\"  Win Rate:     %.2f%%\" % (b[\"mean_win_rate\"]*100))\n",
    "    print(\"  Turnover:     %.2f\" % b.get(\"mean_turnover\",0))\n",
    "    print(\"  Meta-score:   %.2f\" % b.get(\"meta_score\",1))\n",
    "\n",
    "    print(\"\\n=== Portfolio ===\")\n",
    "    for mk, pm in portfolio_results.get(\"per_market\",{}).items():\n",
    "        print(\"  %s: Sharpe=%.2f  Strats=%d  CVaR_improved=%s\" % (\n",
    "            mk, pm[\"sharpe\"], pm[\"n_strategies\"], pm.get(\"cvar_improved\",\"\")))\n",
    "    cm = portfolio_results.get(\"cross_market\",{})\n",
    "    if cm:\n",
    "        print(\"  CROSS: Sharpe=%.2f  MaxDD=%.4f  Consistency=%.0f%%\" % (\n",
    "            cm[\"sharpe\"], cm.get(\"max_drawdown\",0), cm.get(\"monthly_consistency\",0)*100))\n",
    "\n",
    "    print(\"\\n=== Deployment Checklist ===\")\n",
    "    v = portfolio_results.get(\"validation\",{})\n",
    "    for q, a in v.items():\n",
    "        print(\"  %s: %s\" % (q.replace(\"_\",\" \").title(), \"YES\" if a else \"NO\"))\n",
    "\n",
    "    print(\"\\n=== Tuned Rules ===\")\n",
    "    print(json.dumps(tuned_rules, indent=2))\n",
    "\n",
    "    report = {\n",
    "        \"version\":\"v3\", \"markets\":CFG.markets, \"horizons\":CFG.forward_days_list,\n",
    "        \"tri_state_thresholds\":CFG.tristate_thresholds_pct,\n",
    "        \"cost_stress_scenarios\":[list(s) for s in CFG.cost_stress_scenarios],\n",
    "        \"funnel\":{\"candidates\":len(all_candidates),\"edge\":len(edge_results),\n",
    "                  \"wf\":wf_results[\"strategy_id\"].nunique() if len(wf_results)>0 else 0,\n",
    "                  \"filtered\":len(filtered),\"beta_neutral\":len(beta_filtered),\n",
    "                  \"dist_safe\":len(dist_safe),\"cost_survived\":len(cost_survived),\n",
    "                  \"deduped\":len(deduped),\"regime\":len(regime_ok),\n",
    "                  \"turnover\":len(turnover_ok),\"meta_gated\":len(meta_scored),\n",
    "                  \"scored\":len(scored)},\n",
    "        \"tuned_rules\":tuned_rules, \"portfolio\":portfolio_results,\n",
    "        \"top_strategy\":b[\"strategy_id\"],\n",
    "        \"active_modules\": {\n",
    "            \"axis_a_liquidity\": CFG.enable_liquidity_features,\n",
    "            \"axis_b_fundamentals\": CFG.enable_fundamental_features,\n",
    "            \"axis_c_macro\": CFG.enable_macro_features,\n",
    "            \"axis_d_sectors\": CFG.enable_sector_features,\n",
    "            \"axis_e_sentiment\": CFG.enable_sentiment_proxy,\n",
    "        },\n",
    "    }\n",
    "    rp = os.path.join(CFG.drive_root, 'report_v3.json')\n",
    "    with open(rp,'w') as f: json.dump(report, f, indent=2)\n",
    "    print(\"\\nReport:\", rp)\n",
    "else:\n",
    "    print(\"\\nNo viable strategies. The filters correctly identified no edge.\")\n",
    "    print(\"This is a VALID outcome — better than false positives.\")\n",
    "print(\"\\n\"+\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}