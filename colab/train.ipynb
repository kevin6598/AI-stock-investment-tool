{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# AI Stock Investment Tool - Colab Training\n\nTrain multiple model configurations with walk-forward validation on GPU.\n\n**Before starting:**\n1. Go to **Runtime > Change runtime type > T4 GPU**\n2. Run cells **in order** from top to bottom\n3. If repo is private, you'll need a [GitHub Personal Access Token](https://github.com/settings/tokens) with `repo` scope",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install -q yfinance lightgbm torch optuna pyarrow scikit-learn scipy pandas numpy matplotlib",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:35:45.185035800Z",
     "start_time": "2026-02-09T12:35:23.067676700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "import os\nos.chdir(\"/content\")\n\n# Clean previous clone if any\n!rm -rf AI-stock-investment-tool\n\n# Try public clone first, fall back to token auth\nREPO = \"https://github.com/kevin6598/AI-stock-investment-tool.git\"\nret = os.system(f\"git clone {REPO} 2>/dev/null\")\n\nif ret != 0:\n    from getpass import getpass\n    print(\"Public clone failed -- repo is private.\")\n    print(\"Create a token at: https://github.com/settings/tokens (repo scope)\")\n    token = getpass(\"Paste your GitHub token: \")\n    !git clone https://{token}@github.com/kevin6598/AI-stock-investment-tool.git\n    del token\n\nos.chdir(\"/content/AI-stock-investment-tool\")\nprint(f\"Working dir: {os.getcwd()}\")\n!git log --oneline -3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:35:45.593941800Z",
     "start_time": "2026-02-09T12:35:45.188027900Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Clean previous clone if any\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -rf AI-stock-investment-tool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다: '/content'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "import torch, sys\nprint(f\"Python: {sys.version}\")\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"WARNING: No GPU detected. Go to Runtime > Change runtime type > T4 GPU\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Mount Google Drive & Load Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Configure paths\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/ai_stock_tool\"\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "\n",
    "DATA_PATH = os.path.join(DRIVE_DIR, \"dataset.parquet\")\n",
    "OUTPUT_DIR = os.path.join(DRIVE_DIR, \"models_registry\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Drive dir: {DRIVE_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Fetch Data & Build Features\n",
    "\n",
    "If you already exported `dataset.parquet` locally and uploaded it to Drive, skip this cell and go to **Load existing dataset**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# === Option A: Build dataset from scratch ===\n",
    "\n",
    "TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"JPM\", \"V\", \"JNJ\"]\n",
    "PERIOD = \"5y\"\n",
    "FORWARD_HORIZONS = [21, 63, 126]  # 1M, 3M, 6M\n",
    "\n",
    "from data.stock_api import get_historical_data, get_stock_info\n",
    "from training.feature_engineering import build_panel_dataset, cross_sectional_normalize\n",
    "\n",
    "print(\"Fetching stock data...\")\n",
    "stock_dfs = {}\n",
    "stock_infos = {}\n",
    "for ticker in TICKERS:\n",
    "    df = get_historical_data(ticker, period=PERIOD)\n",
    "    if not df.empty:\n",
    "        stock_dfs[ticker] = df\n",
    "        stock_infos[ticker] = get_stock_info(ticker) or {}\n",
    "        print(f\"  {ticker}: {len(df)} rows\")\n",
    "\n",
    "market_df = get_historical_data(\"SPY\", period=PERIOD)\n",
    "print(f\"  SPY (market): {len(market_df)} rows\")\n",
    "\n",
    "print(\"\\nBuilding features...\")\n",
    "panel = build_panel_dataset(stock_dfs, stock_infos, market_df, FORWARD_HORIZONS)\n",
    "panel = cross_sectional_normalize(panel)\n",
    "print(f\"Panel shape: {panel.shape}\")\n",
    "\n",
    "# Save to Drive\n",
    "panel.to_parquet(DATA_PATH)\n",
    "print(f\"\\nSaved to {DATA_PATH}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# === Option B: Load existing dataset from Drive ===\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "panel = pd.read_parquet(DATA_PATH)\n",
    "print(f\"Loaded panel: {panel.shape}\")\n",
    "print(f\"Tickers: {panel.index.get_level_values(1).unique().tolist()}\")\n",
    "print(f\"Date range: {panel.index.get_level_values(0).min()} to {panel.index.get_level_values(0).max()}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Configure Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from training.model_config import ModelConfig, ConfigGrid\n",
    "\n",
    "# Option 1: Manual configs\n",
    "configs = [\n",
    "    ModelConfig(model_type=\"elastic_net\", learning_rate=0.1, epochs=1),\n",
    "    ModelConfig(model_type=\"lightgbm\", learning_rate=0.05, epochs=500,\n",
    "                extra_params={\"num_leaves\": 31, \"max_depth\": 6}),\n",
    "    ModelConfig(model_type=\"lightgbm\", learning_rate=0.01, epochs=500,\n",
    "                extra_params={\"num_leaves\": 63, \"max_depth\": 8}),\n",
    "    ModelConfig(model_type=\"lstm_attention\", learning_rate=1e-3, epochs=100,\n",
    "                dropout=0.2, sequence_length=60),\n",
    "    ModelConfig(model_type=\"transformer\", learning_rate=3e-4, epochs=100,\n",
    "                dropout=0.2, sequence_length=60),\n",
    "]\n",
    "\n",
    "# Option 2: Grid search (uncomment to use)\n",
    "# configs = ConfigGrid.from_grid({\n",
    "#     \"model_type\": [\"lightgbm\"],\n",
    "#     \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "#     \"extra_params\": [{\"num_leaves\": 31}, {\"num_leaves\": 63}],\n",
    "# })\n",
    "\n",
    "# Option 3: Random search (uncomment to use)\n",
    "# configs = ConfigGrid.from_random({\n",
    "#     \"model_type\": [\"lightgbm\", \"lstm_attention\"],\n",
    "#     \"learning_rate\": [0.001, 0.005, 0.01, 0.05],\n",
    "#     \"dropout\": [0.1, 0.2, 0.3],\n",
    "# }, n_samples=8)\n",
    "\n",
    "print(f\"Total configs to train: {len(configs)}\")\n",
    "for i, c in enumerate(configs):\n",
    "    print(f\"  [{i}] {c.model_type} | lr={c.learning_rate} | dropout={c.dropout} | epochs={c.epochs}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Train with Walk-Forward Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from training.model_config import MultiConfigRunner\n",
    "from training.model_selection import WalkForwardConfig\n",
    "\n",
    "# Define walk-forward settings\n",
    "HORIZON = \"1M\"  # Change to \"3M\" or \"6M\" as needed\n",
    "TARGET_COL = \"fwd_return_21d\"  # Must match horizon: 21d=1M, 63d=3M, 126d=6M\n",
    "\n",
    "wf_config = WalkForwardConfig(\n",
    "    train_start=\"2015-01-01\",\n",
    "    test_end=\"2025-01-01\",\n",
    "    train_min_months=36,\n",
    "    val_months=6,\n",
    "    test_months=6,\n",
    "    step_months=6,\n",
    "    embargo_days=21,\n",
    "    expanding=True,\n",
    ")\n",
    "\n",
    "# Feature columns (exclude targets and _close)\n",
    "feature_cols = [\n",
    "    c for c in panel.columns\n",
    "    if not c.startswith(\"fwd_return_\") and c != \"_close\"\n",
    "]\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"Horizon: {HORIZON}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Optional: Prune low-importance features to speed up training\n",
    "from training.feature_engineering import prune_features\n",
    "\n",
    "sample = panel.head(5000)  # Use a sample for feature selection\n",
    "_, selected_cols = prune_features(\n",
    "    sample[feature_cols],\n",
    "    sample[TARGET_COL],\n",
    "    importance_threshold=0.005,\n",
    ")\n",
    "print(f\"Pruned: {len(feature_cols)} -> {len(selected_cols)} features\")\n",
    "\n",
    "# Uncomment to use pruned features:\n",
    "# feature_cols = selected_cols"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "runner = MultiConfigRunner(save_to_registry=False)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "t0 = time.time()\n",
    "\n",
    "results = runner.run(\n",
    "    configs=configs,\n",
    "    panel=panel,\n",
    "    target_col=TARGET_COL,\n",
    "    feature_cols=feature_cols,\n",
    "    wf_config=wf_config,\n",
    "    horizon=HORIZON,\n",
    ")\n",
    "\n",
    "total_time = time.time() - t0\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training complete in {total_time:.1f}s\")\n",
    "print(f\"Configs evaluated: {len(results)}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Compare Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build results table\n",
    "rows = []\n",
    "for r in results:\n",
    "    ev = r.evaluation\n",
    "    rows.append({\n",
    "        \"Model\": r.config.model_type,\n",
    "        \"LR\": r.config.learning_rate,\n",
    "        \"Dropout\": r.config.dropout,\n",
    "        \"IC\": round(ev.mean_ic, 4),\n",
    "        \"ICIR\": round(ev.icir, 2),\n",
    "        \"Sharpe\": round(ev.mean_sharpe, 2),\n",
    "        \"Max DD\": round(ev.mean_mdd, 4),\n",
    "        \"Calmar\": round(ev.mean_calmar, 2),\n",
    "        \"Hit Ratio\": round(ev.mean_hit_ratio, 4),\n",
    "        \"Folds\": len(ev.fold_results),\n",
    "        \"Time (s)\": round(r.training_time, 1),\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "df_results = df_results.sort_values(\"IC\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\nModel Comparison (sorted by IC):\")\n",
    "print(\"=\" * 80)\n",
    "display(df_results)"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Statistical comparison\n",
    "from training.model_comparison import ModelComparisonEngine\n",
    "\n",
    "evaluations = [r.evaluation for r in results]\n",
    "engine = ModelComparisonEngine()\n",
    "report = engine.compare(evaluations)\n",
    "\n",
    "print(\"Rankings by IC:\")\n",
    "for name, val in report.rankings.get(\"ic\", []):\n",
    "    print(f\"  {name}: {val:.4f}\")\n",
    "\n",
    "print(f\"\\nStability scores:\")\n",
    "for name, score in report.stability_scores.items():\n",
    "    print(f\"  {name}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nBest per horizon: {report.best_per_horizon}\")\n",
    "\n",
    "if report.significance_tests:\n",
    "    print(f\"\\nSignificance tests:\")\n",
    "    for key, test in report.significance_tests.items():\n",
    "        sig = \"YES\" if test[\"ttest_significant_5pct\"] else \"no\"\n",
    "        print(f\"  {key}: p={test['ttest_p_value']:.4f} (significant: {sig})\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# IC by model\n",
    "axes[0].barh(df_results[\"Model\"] + \" (lr=\" + df_results[\"LR\"].astype(str) + \")\", df_results[\"IC\"])\n",
    "axes[0].set_xlabel(\"Mean IC\")\n",
    "axes[0].set_title(\"Information Coefficient\")\n",
    "\n",
    "# Sharpe by model\n",
    "axes[1].barh(df_results[\"Model\"] + \" (lr=\" + df_results[\"LR\"].astype(str) + \")\", df_results[\"Sharpe\"])\n",
    "axes[1].set_xlabel(\"Mean Sharpe\")\n",
    "axes[1].set_title(\"Sharpe Ratio\")\n",
    "\n",
    "# Training time\n",
    "axes[2].barh(df_results[\"Model\"] + \" (lr=\" + df_results[\"LR\"].astype(str) + \")\", df_results[\"Time (s)\"])\n",
    "axes[2].set_xlabel(\"Seconds\")\n",
    "axes[2].set_title(\"Training Time\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"comparison.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Save Best Models to Drive"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Save all results\n",
    "results_data = []\n",
    "for i, r in enumerate(results):\n",
    "    model_dir = os.path.join(OUTPUT_DIR, f\"{r.config.model_type}_v{i}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    # Save config\n",
    "    with open(os.path.join(model_dir, \"config.json\"), \"w\") as f:\n",
    "        json.dump(r.config.to_json(), f, indent=2)\n",
    "\n",
    "    # Save metrics\n",
    "    metrics = {\n",
    "        \"mean_ic\": r.evaluation.mean_ic,\n",
    "        \"icir\": r.evaluation.icir,\n",
    "        \"mean_sharpe\": r.evaluation.mean_sharpe,\n",
    "        \"mean_mdd\": r.evaluation.mean_mdd,\n",
    "        \"mean_calmar\": r.evaluation.mean_calmar,\n",
    "        \"mean_hit_ratio\": r.evaluation.mean_hit_ratio,\n",
    "        \"n_folds\": len(r.evaluation.fold_results),\n",
    "    }\n",
    "    with open(os.path.join(model_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    results_data.append({\n",
    "        \"config\": r.config.to_json(),\n",
    "        \"training_time\": r.training_time,\n",
    "        \"best_params\": r.best_params,\n",
    "        \"metrics\": metrics,\n",
    "    })\n",
    "\n",
    "    print(f\"Saved: {model_dir}\")\n",
    "\n",
    "# Save combined results JSON (for local import)\n",
    "results_path = os.path.join(OUTPUT_DIR, \"results.json\")\n",
    "with open(results_path, \"w\") as f:\n",
    "    json.dump(results_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nAll results saved to {OUTPUT_DIR}\")\n",
    "print(f\"Import locally with: DataExporter.import_results('{results_path}')\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. (Optional) Hyperparameter Search with Optuna"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Run Optuna HP search for the best model type\n",
    "from training.hyperparameter_search import run_optuna_search\n",
    "\n",
    "best_model_type = results[0].config.model_type\n",
    "print(f\"Running Optuna HP search for: {best_model_type}\")\n",
    "\n",
    "best_params, best_ic = run_optuna_search(\n",
    "    model_type=best_model_type,\n",
    "    panel=panel,\n",
    "    target_col=TARGET_COL,\n",
    "    feature_cols=feature_cols,\n",
    "    n_trials=20,\n",
    ")\n",
    "\n",
    "print(f\"\\nBest IC: {best_ic:.4f}\")\n",
    "print(f\"Best params: {best_params}\")"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Hybrid Multi-Modal Model Training (50-Ticker Universe)\n\nTrain the hybrid multi-modal model on the full 50-ticker universe with ticker embeddings and export production artifacts.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 50-ticker universe for hybrid model\nTICKERS_50 = [\n    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"NVDA\", \"TSLA\", \"BRK-B\", \"JPM\", \"JNJ\",\n    \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\", \"NFLX\", \"ADBE\",\n    \"CRM\", \"CMCSA\", \"XOM\", \"VZ\", \"KO\", \"INTC\", \"PEP\", \"ABT\", \"CSCO\", \"TMO\",\n    \"COST\", \"MRK\", \"WMT\", \"AVGO\", \"ACN\", \"CVX\", \"NKE\", \"LLY\", \"MCD\", \"TXN\",\n    \"QCOM\", \"DHR\", \"UPS\", \"BMY\", \"PM\", \"LIN\", \"NEE\", \"ORCL\", \"RTX\", \"HON\",\n]\n\nfrom data.stock_api import get_historical_data, get_stock_info\nfrom training.feature_engineering import (\n    build_panel_dataset, cross_sectional_normalize, add_ticker_embedding_column\n)\n\nprint(f\"Fetching data for {len(TICKERS_50)} tickers...\")\nstock_dfs_50 = {}\nstock_infos_50 = {}\nfor ticker in TICKERS_50:\n    try:\n        df = get_historical_data(ticker, period=\"5y\")\n        if not df.empty and len(df) > 300:\n            stock_dfs_50[ticker] = df\n            stock_infos_50[ticker] = get_stock_info(ticker) or {}\n    except Exception as e:\n        print(f\"  WARN: {ticker} failed: {e}\")\n\nmarket_df_50 = get_historical_data(\"SPY\", period=\"5y\")\nvalid_tickers = sorted(stock_dfs_50.keys())\nprint(f\"Valid tickers: {len(valid_tickers)}\")\n\nprint(\"Building panel...\")\npanel_50 = build_panel_dataset(stock_dfs_50, stock_infos_50, market_df_50, [21, 63, 126])\npanel_50 = cross_sectional_normalize(panel_50)\npanel_50, ticker_to_id = add_ticker_embedding_column(panel_50, valid_tickers)\nprint(f\"Panel shape: {panel_50.shape}\")\nprint(f\"Ticker IDs: {ticker_to_id}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import time\nimport numpy as np\nfrom training.models import create_model\n\nTARGET_COL_50 = \"fwd_return_21d\"\nfeature_cols_50 = [c for c in panel_50.columns\n                   if not c.startswith(\"fwd_return_\") and c not in (\"_close\", \"ticker_id\")]\n\nX_50 = panel_50[feature_cols_50].values.astype(np.float32)\ny_50 = panel_50[TARGET_COL_50].values.astype(np.float32)\nnp.nan_to_num(X_50, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\nnp.nan_to_num(y_50, copy=False, nan=0.0, posinf=0.0, neginf=0.0)\n\nsplit = int(len(X_50) * 0.8)\nval_split = int(len(X_50) * 0.9)\n\nprint(f\"Features: {X_50.shape[1]}\")\nprint(f\"Samples: train={split}, val={val_split-split}, test={len(X_50)-val_split}\")\n\nprint(\"\\nTraining hybrid multi-modal model...\")\nt0 = time.time()\n\nhybrid = create_model(\"hybrid_multimodal\", {\n    \"epochs\": 50,\n    \"patience\": 10,\n    \"n_tickers\": len(valid_tickers),\n    \"hidden_dim\": 128,\n    \"fusion_dim\": 128,\n    \"vae_latent_dim\": 16,\n    \"sequence_length\": 60,\n    \"learning_rate\": 1e-3,\n    \"batch_size\": 64,\n})\n\nhybrid.fit(\n    X_50[:split], y_50[:split],\n    X_50[split:val_split], y_50[split:val_split],\n    feature_names=feature_cols_50,\n)\n\ntrain_time = time.time() - t0\nprint(f\"Training complete in {train_time:.1f}s\")\n\n# Quick evaluation\ntest_preds = hybrid.predict(X_50[val_split:])\nvalid_mask = ~np.isnan(test_preds)\nfrom training.model_selection import compute_prediction_metrics\ntest_metrics = compute_prediction_metrics(y_50[val_split:][valid_mask], test_preds[valid_mask])\nprint(f\"Test IC: {test_metrics.ic:.4f}, Hit ratio: {test_metrics.hit_ratio:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Export Production Artifacts\n\nExport model, scaler, config, feature columns, and ticker list for the FastAPI backend.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\nimport pickle\nfrom datetime import datetime\n\nARTIFACT_DIR = os.path.join(DRIVE_DIR, \"artifacts\")\nos.makedirs(ARTIFACT_DIR, exist_ok=True)\n\n# 1. Save model\nmodel_path = os.path.join(ARTIFACT_DIR, \"model.pkl\")\nwith open(model_path, \"wb\") as f:\n    pickle.dump(hybrid, f)\nprint(f\"Model saved: {model_path}\")\n\n# 2. Save feature scaler\nif hasattr(hybrid, 'scaler'):\n    scaler_path = os.path.join(ARTIFACT_DIR, \"feature_scaler.pkl\")\n    with open(scaler_path, \"wb\") as f:\n        pickle.dump(hybrid.scaler, f)\n    print(f\"Scaler saved: {scaler_path}\")\n\n# 3. Save config\nconfig = {\n    \"model_type\": \"hybrid_multimodal\",\n    \"horizons\": [\"1M\", \"3M\", \"6M\"],\n    \"horizon_days\": [21, 63, 126],\n    \"n_features\": len(feature_cols_50),\n    \"n_tickers\": len(valid_tickers),\n    \"hidden_dim\": 128,\n    \"fusion_dim\": 128,\n    \"vae_latent_dim\": 16,\n    \"sequence_length\": 60,\n}\nwith open(os.path.join(ARTIFACT_DIR, \"config.json\"), \"w\") as f:\n    json.dump(config, f, indent=2)\nprint(\"Config saved\")\n\n# 4. Save feature columns (preserves training order)\nwith open(os.path.join(ARTIFACT_DIR, \"feature_columns.json\"), \"w\") as f:\n    json.dump(feature_cols_50, f)\nprint(f\"Feature columns saved ({len(feature_cols_50)} cols)\")\n\n# 5. Save ticker list\nwith open(os.path.join(ARTIFACT_DIR, \"ticker_list.json\"), \"w\") as f:\n    json.dump(valid_tickers, f)\nprint(f\"Ticker list saved ({len(valid_tickers)} tickers)\")\n\n# 6. Save training metadata\nmetadata = {\n    \"version\": f\"hybrid_v{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n    \"trained_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n    \"n_tickers\": len(valid_tickers),\n    \"n_features\": len(feature_cols_50),\n    \"n_samples\": len(X_50),\n    \"train_size\": split,\n    \"test_ic\": float(test_metrics.ic),\n    \"test_hit_ratio\": float(test_metrics.hit_ratio),\n    \"training_time_seconds\": round(train_time, 1),\n    \"tickers\": valid_tickers,\n}\nwith open(os.path.join(ARTIFACT_DIR, \"training_metadata.json\"), \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(f\"\\nAll artifacts exported to: {ARTIFACT_DIR}\")\nprint(f\"Version: {metadata['version']}\")\nprint(f\"\\nTo deploy: copy artifacts/ to your server and restart the FastAPI backend.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}