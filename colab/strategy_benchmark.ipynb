{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {"provenance": [], "gpuType": "T4"},
  "kernelspec": {"name": "python3", "display_name": "Python 3"},
  "language_info": {"name": "python"},
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Multi-Strategy Benchmark (Extended)\n", "\n", "Compare **15 alpha extraction strategies** under identical walk-forward conditions.\n", "\n", "| ID | Strategy | Architecture |\n", "|----|----------|-------------|\n", "| A | LSTM Baseline | Price-only temporal LSTM |\n", "| B | NLP Only | Sentiment MLP |\n", "| C | Late Ensemble | A + B with ridge meta |\n", "| D | Residual Sentiment | Market-residualized NLP |\n", "| E | Gated Hybrid | Gated price-NLP fusion |\n", "| E1 | Attention Hybrid | Cross-attention price/NLP |\n", "| E2 | Additive Residual | T + alpha*S fusion |\n", "| F | CS-Attention LSTM | Temporal + stock attention |\n", "| F1 | Temporal Fusion | Simplified TFT |\n", "| G | Transformer | Encoder-only transformer |\n", "| G1 | Efficient Transformer | Linear attention O(n*d) |\n", "| H | Random Forest | sklearn RF (no torch) |\n", "| I | LightGBM | Gradient boosted trees (no torch) |\n", "| J | Short Horizon NLP | NLP MLP 5D only |\n", "| K | Short Horizon Hybrid | Gated hybrid 5D only |\n", "\n", "**Evaluation:** IC, Sharpe, R2, per-stock R2, directional accuracy, calibration, market-level prediction, backtest PnL, DM statistical tests.\n", "\n", "**Goal:** Determine which structure produces real, production-surviving alpha."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["!pip install -q yfinance lightgbm torch optuna pyarrow scikit-learn scipy pandas numpy matplotlib"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import os\n", "os.chdir(\"/content\")\n", "!rm -rf AI-stock-investment-tool\n", "\n", "REPO = \"https://github.com/kevin6598/AI-stock-investment-tool.git\"\n", "ret = os.system(\"git clone %s 2>/dev/null\" % REPO)\n", "if ret != 0:\n", "    from getpass import getpass\n", "    token = getpass(\"GitHub token (repo scope): \")\n", "    os.system(\"git clone https://%s@github.com/kevin6598/AI-stock-investment-tool.git\" % token)\n", "    del token\n", "\n", "os.chdir(\"/content/AI-stock-investment-tool\")\n", "!git log --oneline -3"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import torch, sys\n", "print(\"Python: %s\" % sys.version)\n", "print(\"PyTorch: %s\" % torch.__version__)\n", "print(\"CUDA: %s\" % torch.cuda.is_available())\n", "if torch.cuda.is_available():\n", "    print(\"GPU: %s\" % torch.cuda.get_device_name(0))"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Global Configuration\n", "\n", "Single config block. All strategies respect these constraints.\n", "No model-specific unfair tuning."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["CONFIG = {\n", "    \"horizons\": [5, 21],\n", "    \"walk_forward\": {\n", "        \"train_years\": 2,\n", "        \"test_months\": 4,\n", "        \"step_months\": 4,\n", "        \"val_months\": 2,\n", "        \"embargo_days\": 5,\n", "    },\n", "    \"max_epochs\": 15,\n", "    \"early_stop_patience\": 3,\n", "    \"ranking_weight\": 0.5,\n", "    \"max_params\": 1_500_000,\n", "}\n", "\n", "print(\"Horizons: %s\" % CONFIG[\"horizons\"])\n", "print(\"Walk-forward: %s\" % CONFIG[\"walk_forward\"])\n", "print(\"Max epochs: %d\" % CONFIG[\"max_epochs\"])\n", "print(\"Max params: %d\" % CONFIG[\"max_params\"])"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Standardized Data Pipeline\n", "\n", "All strategies use the SAME processed dataset."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n", "\n", "DRIVE_DIR = \"/content/drive/MyDrive/ai_stock_tool\"\n", "DATA_PATH = os.path.join(DRIVE_DIR, \"dataset.parquet\")\n", "ARTIFACT_DIR = os.path.join(DRIVE_DIR, \"artifacts\")\n", "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n", "print(\"Data: %s\" % DATA_PATH)"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "panel = pd.read_parquet(DATA_PATH)\n", "valid_tickers = panel.index.get_level_values(1).unique().tolist()\n", "print(\"Panel: %s\" % str(panel.shape))\n", "print(\"Tickers: %d\" % len(valid_tickers))\n", "\n", "date_min = panel.index.get_level_values(0).min()\n", "date_max = panel.index.get_level_values(0).max()\n", "data_span_months = (date_max - date_min).days / 30.44\n", "print(\"Date range: %s to %s (%.0f months)\" % (\n", "    date_min.date(), date_max.date(), data_span_months))\n", "\n", "# Estimate fold count\n", "wf = CONFIG[\"walk_forward\"]\n", "train_months = wf[\"train_years\"] * 12\n", "val_months = wf.get(\"val_months\", 3)\n", "test_months = wf[\"test_months\"]\n", "step_months = wf[\"step_months\"]\n", "min_needed = train_months + val_months + test_months + 1\n", "available_after_first = data_span_months - min_needed\n", "est_folds = max(0, 1 + int(available_after_first / step_months))\n", "print(\"\\nFold estimate: train=%dmo + val=%dmo + test=%dmo = %dmo min\" % (\n", "    train_months, val_months, test_months, min_needed))\n", "print(\"Expected folds: ~%d (with step=%dmo)\" % (est_folds, step_months))\n", "if est_folds == 0:\n", "    print(\"WARNING: No folds possible! Reduce train_years or test_months.\")\n", "\n", "# Feature columns (same for ALL strategies)\n", "feature_cols = [\n", "    c for c in panel.columns\n", "    if not c.startswith(\"fwd_return_\")\n", "    and not c.startswith(\"residual_return_\")\n", "    and not c.startswith(\"ranked_target_\")\n", "    and c not in (\"_close\", \"ticker_id\")\n", "]\n", "\n", "price_cols = [c for c in feature_cols if not c.startswith(\"nlp_\")]\n", "nlp_cols = [c for c in feature_cols if c.startswith(\"nlp_\")]\n", "print(\"\\nFeatures: %d total (%d price, %d NLP)\" % (\n", "    len(feature_cols), len(price_cols), len(nlp_cols)))\n", "\n", "# Check required targets\n", "for h in CONFIG[\"horizons\"]:\n", "    tc = \"fwd_return_%dd\" % h\n", "    if tc in panel.columns:\n", "        non_null = panel[tc].notna().sum()\n", "        print(\"  %s: %d non-null\" % (tc, non_null))\n", "    else:\n", "        print(\"  WARNING: %s not found!\" % tc)"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Precompute derived features for all strategies\n", "\n", "# Sentiment residual (for Strategy D)\n", "market_feat = None\n", "for cand in [\"market_return\", \"market_return_21d\", \"spy_return_21d\"]:\n", "    if cand in panel.columns:\n", "        market_feat = cand\n", "        break\n", "\n", "if market_feat:\n", "    print(\"Market return feature: %s\" % market_feat)\n", "else:\n", "    print(\"WARNING: No market return feature found for residualization\")\n", "\n", "# Volatility proxy\n", "vol_feat = None\n", "for cand in [\"volatility_21d\", \"realized_vol_21d\", \"atr_pct\"]:\n", "    if cand in panel.columns:\n", "        vol_feat = cand\n", "        break\n", "\n", "if vol_feat:\n", "    print(\"Volatility feature: %s\" % vol_feat)\n", "else:\n", "    print(\"WARNING: No volatility feature found\")\n", "\n", "# Data quality check\n", "nan_pct = panel[feature_cols].isna().mean().mean() * 100\n", "print(\"\\nNaN rate: %.2f%%\" % nan_pct)\n", "print(\"Data pipeline ready.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Strategy Definitions\n", "\n", "All 15 strategies with identical interface: `train()`, `predict()`, `num_parameters()`.\n", "\n", "- **A-F**: Neural temporal/NLP models (require PyTorch)\n", "- **E1, E2**: Novel fusion architectures (cross-attention, additive residual)\n", "- **F1**: Simplified Temporal Fusion Transformer\n", "- **G, G1**: Transformer variants (standard + linear attention)\n", "- **H, I**: Tree-based models (no torch required)\n", "- **J, K**: Short-horizon specialists (5D only)"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["from training.strategy_benchmark import (\n", "    BenchmarkConfig, BenchmarkEvaluator, STRATEGY_REGISTRY,\n", "    save_benchmark_results, run_integrity_checks,\n", "    ExtendedMetrics, DMTestResult,\n", ")\n", "\n", "config = BenchmarkConfig.from_dict(CONFIG)\n", "\n", "# List all 15 strategies\n", "print(\"Strategies to benchmark (%d total):\" % len(STRATEGY_REGISTRY))\n", "print(\"-\" * 50)\n", "for key, cls in sorted(STRATEGY_REGISTRY.items()):\n", "    sh = getattr(cls, 'supported_horizons', None)\n", "    h_info = \"all horizons\" if sh is None else \"%s only\" % sh\n", "    print(\"  %-3s: %-28s (%s)\" % (key, cls.name, h_info))\n", "\n", "# Verify param counts (dry-run instantiation)\n", "print(\"\\nParam count check (instantiation only):\")\n", "for key, cls in sorted(STRATEGY_REGISTRY.items()):\n", "    s = cls()\n", "    print(\"  %s: OK\" % cls.name)\n", "\n", "print(\"\\nTotal: %d strategies\" % len(STRATEGY_REGISTRY))"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Run Benchmark\n", "\n", "Walk-forward evaluation for every strategy at every horizon.\n", "\n", "Expected runtime: ~45-60 min on T4 GPU (15 strategies x 2 horizons)."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import logging\n", "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=\"%H:%M:%S\")\n", "\n", "evaluator = BenchmarkEvaluator(panel, feature_cols, config)\n", "\n", "strategy_classes = list(STRATEGY_REGISTRY.values())\n", "print(\"Running %d strategies x %d horizons...\" % (\n", "    len(strategy_classes), len(config.horizons)))\n", "print(\"=\" * 60)\n", "\n", "import time\n", "t0 = time.time()\n", "results = evaluator.run_all(strategy_classes)\n", "total_time = time.time() - t0\n", "\n", "print(\"\\n\" + \"=\" * 60)\n", "print(\"Benchmark complete in %.1f min\" % (total_time / 60))\n", "print(\"Total evaluations: %d\" % len(results))\n", "print(\"Strategies with extended metrics: %d\" % sum(1 for r in results if r.extended))"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Strategy Comparison Table"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import math\n", "\n", "# Build comparison table\n", "rows = []\n", "for r in results:\n", "    rows.append({\n", "        \"Strategy\": r.name,\n", "        \"Horizon\": r.horizon,\n", "        \"IC\": round(r.ic_mean, 4),\n", "        \"ICIR\": round(r.icir, 2),\n", "        \"Sharpe\": round(r.sharpe, 2),\n", "        \"IC_std\": round(r.ic_std, 4),\n", "        \"Prod IC\": round(r.prod_ic, 4),\n", "        \"Overfit\": round(r.overfit_score, 3),\n", "        \"Composite\": round(r.composite, 4),\n", "        \"Params\": r.param_count,\n", "        \"Time(s)\": round(r.train_time, 1),\n", "        \"Status\": r.status,\n", "    })\n", "\n", "df_results = pd.DataFrame(rows)\n", "print(\"\\nStrategy Benchmark Results (sorted by Composite):\")\n", "print(\"=\" * 100)\n", "display(df_results)\n", "\n", "# Summary by status\n", "print(\"\\nStatus Summary:\")\n", "for status in [\"PASS\", \"WARN\", \"FAIL\"]:\n", "    count = sum(1 for r in results if r.status == status)\n", "    names = [r.name + \"/\" + r.horizon for r in results if r.status == status]\n", "    print(\"  %s (%d): %s\" % (status, count, \", \".join(names) if names else \"none\"))"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5a. Extended Metrics Table\n", "\n", "Regression accuracy, directional metrics, calibration, and market-level predictions."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Extended Metrics: Regression, Directional, Calibration, Market-level\n", "ext_rows = []\n", "for r in results:\n", "    if r.extended is None:\n", "        continue\n", "    e = r.extended\n", "    ext_rows.append({\n", "        \"Strategy\": r.name,\n", "        \"Horizon\": r.horizon,\n", "        \"RMSE\": round(e.rmse, 6),\n", "        \"R2\": round(e.r_squared, 4),\n", "        \"Hit%\": round(e.hit_ratio * 100, 1),\n", "        \"Prec\": round(e.precision, 3),\n", "        \"Recall\": round(e.recall, 3),\n", "        \"F1\": round(e.f1, 3),\n", "        \"Cal.Slope\": round(e.calib_slope, 3),\n", "        \"Mkt.R2\": round(e.market_r2, 4),\n", "        \"Mkt.Dir%\": round(e.market_direction_accuracy * 100, 1),\n", "    })\n", "\n", "if ext_rows:\n", "    df_ext = pd.DataFrame(ext_rows)\n", "    print(\"Extended Metrics:\")\n", "    print(\"=\" * 120)\n", "    display(df_ext)\n", "else:\n", "    print(\"No extended metrics available.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Per-Stock R2 Summary\n", "r2_rows = []\n", "for r in results:\n", "    if r.extended is None:\n", "        continue\n", "    e = r.extended\n", "    r2_rows.append({\n", "        \"Strategy\": r.name,\n", "        \"Horizon\": r.horizon,\n", "        \"Mean R2\": round(e.mean_stock_r2, 4),\n", "        \"Median R2\": round(e.median_stock_r2, 4),\n", "        \"% Positive\": round(e.pct_r2_positive, 1),\n", "        \"% > 0.05\": round(e.pct_r2_above_005, 1),\n", "        \"N Stocks\": len(e.stock_r2_values),\n", "    })\n", "\n", "if r2_rows:\n", "    df_r2 = pd.DataFrame(r2_rows)\n", "    print(\"Per-Stock R2 Summary:\")\n", "    print(\"=\" * 90)\n", "    display(df_r2)\n", "else:\n", "    print(\"No per-stock R2 data available.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Backtest Results: Long-Only and Long-Short\n", "bt_rows = []\n", "for r in results:\n", "    if r.extended is None:\n", "        continue\n", "    e = r.extended\n", "    bt_rows.append({\n", "        \"Strategy\": r.name,\n", "        \"Horizon\": r.horizon,\n", "        \"L/O CAGR\": \"%.2f%%\" % (e.lo_cagr * 100),\n", "        \"L/O Sharpe\": round(e.lo_sharpe, 2),\n", "        \"L/O MaxDD\": \"%.2f%%\" % (e.lo_max_dd * 100),\n", "        \"L/S CAGR\": \"%.2f%%\" % (e.ls_cagr * 100),\n", "        \"L/S Sharpe\": round(e.ls_sharpe, 2),\n", "        \"L/S MaxDD\": \"%.2f%%\" % (e.ls_max_dd * 100),\n", "    })\n", "\n", "if bt_rows:\n", "    df_bt = pd.DataFrame(bt_rows)\n", "    print(\"Backtest Results (Long-Only and Long-Short 20/20):\")\n", "    print(\"=\" * 100)\n", "    display(df_bt)\n", "else:\n", "    print(\"No backtest data available.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Diebold-Mariano Test Matrix\n", "dm_results = BenchmarkEvaluator.compute_dm_tests(results)\n", "\n", "if dm_results:\n", "    # Display as table\n", "    dm_rows = []\n", "    for dm in dm_results:\n", "        dm_rows.append({\n", "            \"A\": dm.strategy_a.split(\"_\")[0],\n", "            \"B\": dm.strategy_b.split(\"_\")[0],\n", "            \"Horizon\": dm.horizon,\n", "            \"DM Stat\": round(dm.dm_stat, 2),\n", "            \"p-value\": round(dm.p_value, 4),\n", "            \"Better\": dm.better.split(\"_\")[0],\n", "            \"Sig?\": \"*\" if dm.p_value < 0.05 else (\".\" if dm.p_value < 0.10 else \"\"),\n", "        })\n", "    df_dm = pd.DataFrame(dm_rows)\n", "    print(\"Diebold-Mariano Tests (* = p<0.05, . = p<0.10):\")\n", "    print(\"=\" * 80)\n", "    display(df_dm)\n", "\n", "    # Heatmap per horizon\n", "    import matplotlib.pyplot as plt\n", "    horizons = sorted(set(dm.horizon for dm in dm_results))\n", "    fig_dm, axes_dm = plt.subplots(1, len(horizons), figsize=(8 * len(horizons), 6))\n", "    if len(horizons) == 1:\n", "        axes_dm = [axes_dm]\n", "\n", "    for ax, h in zip(axes_dm, horizons):\n", "        h_dm = [dm for dm in dm_results if dm.horizon == h]\n", "        names = sorted(set(\n", "            [dm.strategy_a.split(\"_\")[0] for dm in h_dm] +\n", "            [dm.strategy_b.split(\"_\")[0] for dm in h_dm]\n", "        ))\n", "        n = len(names)\n", "        pval_matrix = np.ones((n, n))\n", "        name_to_idx = {nm: i for i, nm in enumerate(names)}\n", "\n", "        for dm in h_dm:\n", "            ia = name_to_idx.get(dm.strategy_a.split(\"_\")[0])\n", "            ib = name_to_idx.get(dm.strategy_b.split(\"_\")[0])\n", "            if ia is not None and ib is not None:\n", "                pval_matrix[ia, ib] = dm.p_value\n", "                pval_matrix[ib, ia] = dm.p_value\n", "\n", "        im = ax.imshow(pval_matrix, cmap=\"RdYlGn\", vmin=0, vmax=0.2)\n", "        ax.set_xticks(range(n))\n", "        ax.set_xticklabels(names, rotation=45, fontsize=7, ha=\"right\")\n", "        ax.set_yticks(range(n))\n", "        ax.set_yticklabels(names, fontsize=7)\n", "        ax.set_title(\"DM p-values: %s\" % h, fontweight=\"bold\")\n", "\n", "        for i in range(n):\n", "            for j in range(n):\n", "                if i != j:\n", "                    ax.text(j, i, \"%.2f\" % pval_matrix[i, j],\n", "                            ha=\"center\", va=\"center\", fontsize=6,\n", "                            color=\"white\" if pval_matrix[i, j] < 0.05 else \"black\")\n", "\n", "    plt.colorbar(im, ax=axes_dm[-1], shrink=0.7, label=\"p-value\")\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"dm_test_heatmap.png\"), dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"DM test heatmap saved.\")\n", "else:\n", "    print(\"No DM test results (need fold predictions from multiple strategies).\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Visualization Dashboard"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["import matplotlib.pyplot as plt\n", "import matplotlib.gridspec as gridspec\n", "\n", "fig = plt.figure(figsize=(20, 16))\n", "gs_layout = gridspec.GridSpec(2, 3, hspace=0.35, wspace=0.3)\n", "\n", "# --- Panel 1: IC Comparison Bar Chart ---\n", "ax1 = fig.add_subplot(gs_layout[0, 0])\n", "labels = [\"%s\\n%s\" % (r.name.split(\"_\", 1)[-1][:12], r.horizon) for r in results]\n", "ics = [r.ic_mean for r in results]\n", "colors = [\"#4CAF50\" if r.status == \"PASS\" else \"#FFC107\" if r.status == \"WARN\" else \"#F44336\"\n", "          for r in results]\n", "ax1.barh(range(len(results)), ics, color=colors, edgecolor=\"white\")\n", "ax1.set_yticks(range(len(results)))\n", "ax1.set_yticklabels(labels, fontsize=7)\n", "ax1.set_xlabel(\"Cross-Sectional IC\")\n", "ax1.set_title(\"IC Comparison\", fontweight=\"bold\")\n", "ax1.axvline(x=0, color=\"gray\", linewidth=0.5)\n", "ax1.invert_yaxis()\n", "\n", "# --- Panel 2: IC Stability (fold ICs per strategy) ---\n", "ax2 = fig.add_subplot(gs_layout[0, 1])\n", "cmap = plt.colormaps[\"tab20\"]\n", "for i, r in enumerate(results):\n", "    if r.fold_metrics:\n", "        fold_ics = [f.ic for f in r.fold_metrics]\n", "        x_positions = [i] * len(fold_ics)\n", "        ax2.scatter(x_positions, fold_ics, color=cmap(i % 20), s=30, zorder=3, alpha=0.7)\n", "        ax2.plot([i, i], [min(fold_ics), max(fold_ics)],\n", "                 color=cmap(i % 20), linewidth=2, alpha=0.5)\n", "ax2.set_xticks(range(len(results)))\n", "ax2.set_xticklabels([r.name.split(\"_\")[0] + \"/\" + r.horizon for r in results],\n", "                     rotation=90, fontsize=6, ha=\"center\")\n", "ax2.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "ax2.set_ylabel(\"IC per fold\")\n", "ax2.set_title(\"IC Stability (per fold)\", fontweight=\"bold\")\n", "ax2.grid(axis=\"y\", alpha=0.3)\n", "\n", "# --- Panel 3: Composite Score Bar ---\n", "ax3 = fig.add_subplot(gs_layout[0, 2])\n", "composites = [r.composite if not math.isinf(r.composite) else 0 for r in results]\n", "ax3.barh(range(len(results)), composites, color=colors, edgecolor=\"white\")\n", "ax3.set_yticks(range(len(results)))\n", "ax3.set_yticklabels(labels, fontsize=7)\n", "ax3.set_xlabel(\"Composite Score\")\n", "ax3.set_title(\"Composite Score\", fontweight=\"bold\")\n", "ax3.axvline(x=0, color=\"gray\", linewidth=0.5)\n", "ax3.invert_yaxis()\n", "\n", "# --- Panel 4: Gate Activation ---\n", "ax4 = fig.add_subplot(gs_layout[1, 0])\n", "gate_data = [(r.name, r.horizon, r.gate_stats) for r in results if r.gate_stats]\n", "if gate_data:\n", "    g_labels = [\"%s/%s\" % (n, h) for n, h, _ in gate_data]\n", "    g_means = []\n", "    g_stds = []\n", "    for _, _, gstat in gate_data:\n", "        if isinstance(gstat, dict):\n", "            g_means.append(gstat.get(\"gate_mean\", 0))\n", "            g_stds.append(gstat.get(\"gate_std\", 0))\n", "        else:\n", "            g_means.append(0.5)\n", "            g_stds.append(0)\n", "    ax4.barh(g_labels, g_means, xerr=g_stds, color=\"#2196F3\", capsize=5)\n", "    ax4.set_xlabel(\"Gate Activation\")\n", "    ax4.set_title(\"Gate Distribution (Hybrid)\", fontweight=\"bold\")\n", "    ax4.set_xlim(0, 1)\n", "else:\n", "    ax4.text(0.5, 0.5, \"No gate stats\\navailable\",\n", "             transform=ax4.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n", "    ax4.set_title(\"Gate Distribution\", fontweight=\"bold\")\n", "\n", "# --- Panel 5: Ensemble Weights ---\n", "ax5 = fig.add_subplot(gs_layout[1, 1])\n", "ens_data = [(r.name, r.horizon, r.ensemble_weights) for r in results if r.ensemble_weights]\n", "if ens_data:\n", "    for i, (name, horizon, w) in enumerate(ens_data):\n", "        x = [0, 1]\n", "        vals = [w.get(\"lstm\", 0), w.get(\"nlp\", 0)]\n", "        ax5.bar([v + i * 0.3 for v in x], vals, width=0.25,\n", "                label=\"%s/%s\" % (name.split(\"_\")[0], horizon))\n", "    ax5.set_xticks([0, 1])\n", "    ax5.set_xticklabels([\"LSTM weight\", \"NLP weight\"])\n", "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n", "    ax5.legend(fontsize=8)\n", "    ax5.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "else:\n", "    ax5.text(0.5, 0.5, \"No ensemble weights\\navailable\",\n", "             transform=ax5.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n", "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n", "\n", "# --- Panel 6: Horizon Sensitivity ---\n", "ax6 = fig.add_subplot(gs_layout[1, 2])\n", "strategy_names = sorted(set(r.name for r in results))\n", "horizon_labels = sorted(set(r.horizon for r in results))\n", "x_pos = np.arange(len(strategy_names))\n", "width = 0.35\n", "\n", "for j, h in enumerate(horizon_labels):\n", "    h_ics = []\n", "    for sn in strategy_names:\n", "        match = [r for r in results if r.name == sn and r.horizon == h]\n", "        h_ics.append(match[0].ic_mean if match else 0)\n", "    offset = (j - len(horizon_labels) / 2 + 0.5) * width\n", "    ax6.bar(x_pos + offset, h_ics, width, label=h)\n", "\n", "ax6.set_xticks(x_pos)\n", "ax6.set_xticklabels([n.split(\"_\")[0] for n in strategy_names],\n", "                     rotation=45, fontsize=7, ha=\"right\")\n", "ax6.set_ylabel(\"IC\")\n", "ax6.set_title(\"Horizon Sensitivity (5D vs 21D)\", fontweight=\"bold\")\n", "ax6.legend(fontsize=9)\n", "ax6.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "ax6.grid(axis=\"y\", alpha=0.3)\n", "\n", "fig.suptitle(\"Multi-Strategy Benchmark Dashboard (15 Models)\", fontsize=16, fontweight=\"bold\", y=1.01)\n", "plt.savefig(os.path.join(ARTIFACT_DIR, \"strategy_benchmark.png\"), dpi=150, bbox_inches=\"tight\")\n", "plt.show()\n", "print(\"Dashboard saved.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6a. Extended Visualizations\n", "\n", "Five additional panels: Per-Stock R2 Histogram, Pred vs Actual Scatter, Calibration Slope, Rolling R2, Cumulative PnL."]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# --- Visualization 1: Per-Stock R2 Histogram ---\n", "ext_results = [r for r in results if r.extended and r.extended.stock_r2_values]\n", "n_ext = len(ext_results)\n", "\n", "if n_ext > 0:\n", "    ncols = min(5, n_ext)\n", "    nrows = (n_ext + ncols - 1) // ncols\n", "    fig_r2h, axes_r2h = plt.subplots(nrows, ncols, figsize=(4 * ncols, 3 * nrows))\n", "    if n_ext == 1:\n", "        axes_flat = [axes_r2h]\n", "    else:\n", "        axes_flat = axes_r2h.flatten() if hasattr(axes_r2h, 'flatten') else [axes_r2h]\n", "\n", "    for idx, r in enumerate(ext_results):\n", "        if idx >= len(axes_flat):\n", "            break\n", "        ax = axes_flat[idx]\n", "        vals = list(r.extended.stock_r2_values.values())\n", "        ax.hist(vals, bins=20, color=\"#2196F3\", edgecolor=\"white\", alpha=0.8)\n", "        ax.axvline(x=0, color=\"red\", linewidth=1, linestyle=\"--\")\n", "        ax.axvline(x=np.median(vals), color=\"green\", linewidth=1, linestyle=\"-\",\n", "                   label=\"median=%.3f\" % np.median(vals))\n", "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n", "        ax.set_xlabel(\"R2\", fontsize=8)\n", "        ax.legend(fontsize=6)\n", "\n", "    for idx in range(n_ext, len(axes_flat)):\n", "        axes_flat[idx].set_visible(False)\n", "\n", "    fig_r2h.suptitle(\"Per-Stock R2 Distribution\", fontsize=14, fontweight=\"bold\")\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"per_stock_r2_histogram.png\"),\n", "                dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"Per-stock R2 histogram saved.\")\n", "else:\n", "    print(\"No per-stock R2 data for visualization.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# --- Visualization 2: Pred vs Actual Scatter ---\n", "scatter_results = [r for r in results if r.fold_predictions]\n", "\n", "if scatter_results:\n", "    n_sc = len(scatter_results)\n", "    ncols = min(5, n_sc)\n", "    nrows = (n_sc + ncols - 1) // ncols\n", "    fig_sc, axes_sc = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n", "    if n_sc == 1:\n", "        axes_flat = [axes_sc]\n", "    else:\n", "        axes_flat = axes_sc.flatten() if hasattr(axes_sc, 'flatten') else [axes_sc]\n", "\n", "    for idx, r in enumerate(scatter_results):\n", "        if idx >= len(axes_flat):\n", "            break\n", "        ax = axes_flat[idx]\n", "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n", "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n", "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n", "        p, a = all_p[valid], all_a[valid]\n", "\n", "        if len(p) > 5000:\n", "            idx_sub = np.random.choice(len(p), 5000, replace=False)\n", "            p_plot, a_plot = p[idx_sub], a[idx_sub]\n", "        else:\n", "            p_plot, a_plot = p, a\n", "\n", "        ax.scatter(p_plot, a_plot, alpha=0.1, s=3, color=\"#2196F3\")\n", "\n", "        if len(p) > 10:\n", "            coef = np.polyfit(p, a, 1)\n", "            x_line = np.linspace(p.min(), p.max(), 50)\n", "            ax.plot(x_line, coef[0] * x_line + coef[1], \"r-\", linewidth=1.5,\n", "                    label=\"slope=%.2f\" % coef[0])\n", "\n", "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n", "        ax.set_xlabel(\"Predicted\", fontsize=8)\n", "        ax.set_ylabel(\"Actual\", fontsize=8)\n", "        ax.legend(fontsize=7)\n", "\n", "    for idx in range(n_sc, len(axes_flat)):\n", "        axes_flat[idx].set_visible(False)\n", "\n", "    fig_sc.suptitle(\"Prediction vs Actual\", fontsize=14, fontweight=\"bold\")\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"pred_vs_actual_scatter.png\"),\n", "                dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"Pred vs actual scatter saved.\")\n", "else:\n", "    print(\"No fold predictions for scatter plot.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# --- Visualization 3: Calibration Slope Bar Chart ---\n", "cal_results = [r for r in results if r.extended is not None]\n", "\n", "if cal_results:\n", "    fig_cal, ax_cal = plt.subplots(figsize=(10, max(4, len(cal_results) * 0.4)))\n", "    labels_cal = [\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon) for r in cal_results]\n", "    slopes = [r.extended.calib_slope for r in cal_results]\n", "    colors_cal = [\"#4CAF50\" if abs(s - 1.0) < 0.3 else \"#FFC107\" if abs(s - 1.0) < 0.6\n", "                  else \"#F44336\" for s in slopes]\n", "\n", "    y_pos = range(len(cal_results))\n", "    ax_cal.barh(y_pos, slopes, color=colors_cal, edgecolor=\"white\")\n", "    ax_cal.set_yticks(y_pos)\n", "    ax_cal.set_yticklabels(labels_cal, fontsize=8)\n", "    ax_cal.axvline(x=1.0, color=\"blue\", linewidth=2, linestyle=\"--\", label=\"Ideal (slope=1.0)\")\n", "    ax_cal.set_xlabel(\"Calibration Slope\")\n", "    ax_cal.set_title(\"Calibration: Pred vs Actual Regression Slope\", fontweight=\"bold\")\n", "    ax_cal.legend(fontsize=9)\n", "    ax_cal.invert_yaxis()\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"calibration_slope.png\"), dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"Calibration slope chart saved.\")\n", "else:\n", "    print(\"No calibration data for visualization.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# --- Visualization 4: Rolling R2 (126-sample window) ---\n", "rolling_results = [r for r in results if r.fold_predictions]\n", "\n", "if rolling_results:\n", "    fig_roll, ax_roll = plt.subplots(figsize=(14, 6))\n", "    window = 126\n", "\n", "    for r in rolling_results:\n", "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n", "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n", "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n", "        p, a = all_p[valid], all_a[valid]\n", "\n", "        if len(p) < window + 10:\n", "            continue\n", "\n", "        rolling_r2 = []\n", "        for i in range(window, len(p)):\n", "            p_w = p[i - window:i]\n", "            a_w = a[i - window:i]\n", "            ss_res = np.sum((p_w - a_w) ** 2)\n", "            ss_tot = np.sum((a_w - np.mean(a_w)) ** 2)\n", "            r2 = 1.0 - ss_res / ss_tot if ss_tot > 1e-10 else 0.0\n", "            rolling_r2.append(r2)\n", "\n", "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n", "        ax_roll.plot(rolling_r2, label=label, alpha=0.7, linewidth=1)\n", "\n", "    ax_roll.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "    ax_roll.set_xlabel(\"Sample Index\")\n", "    ax_roll.set_ylabel(\"Rolling R2 (window=%d)\" % window)\n", "    ax_roll.set_title(\"Rolling R2 Across Walk-Forward Test Periods\", fontweight=\"bold\")\n", "    ax_roll.legend(fontsize=7, ncol=3, loc=\"upper right\")\n", "    ax_roll.grid(alpha=0.3)\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"rolling_r2.png\"), dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"Rolling R2 chart saved.\")\n", "else:\n", "    print(\"No fold predictions for rolling R2.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# --- Visualization 5: Cumulative PnL Curves ---\n", "pnl_results = [r for r in results\n", "               if r.extended is not None\n", "               and r.extended.lo_equity is not None\n", "               and len(r.extended.lo_equity) > 1]\n", "\n", "if pnl_results:\n", "    fig_pnl, (ax_lo, ax_ls) = plt.subplots(1, 2, figsize=(16, 6))\n", "\n", "    for r in pnl_results:\n", "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n", "        ax_lo.plot(r.extended.lo_equity, label=label, alpha=0.7, linewidth=1)\n", "        if r.extended.ls_equity is not None and len(r.extended.ls_equity) > 1:\n", "            ax_ls.plot(r.extended.ls_equity, label=label, alpha=0.7, linewidth=1)\n", "\n", "    ax_lo.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "    ax_lo.set_xlabel(\"Trading Day\")\n", "    ax_lo.set_ylabel(\"Equity\")\n", "    ax_lo.set_title(\"Long-Only Cumulative PnL\", fontweight=\"bold\")\n", "    ax_lo.legend(fontsize=6, ncol=2)\n", "    ax_lo.grid(alpha=0.3)\n", "\n", "    ax_ls.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n", "    ax_ls.set_xlabel(\"Trading Day\")\n", "    ax_ls.set_ylabel(\"Equity\")\n", "    ax_ls.set_title(\"Long-Short (20/20) Cumulative PnL\", fontweight=\"bold\")\n", "    ax_ls.legend(fontsize=6, ncol=2)\n", "    ax_ls.grid(alpha=0.3)\n", "\n", "    plt.tight_layout()\n", "    plt.savefig(os.path.join(ARTIFACT_DIR, \"cumulative_pnl.png\"), dpi=150, bbox_inches=\"tight\")\n", "    plt.show()\n", "    print(\"Cumulative PnL curves saved.\")\n", "else:\n", "    print(\"No equity curve data for PnL visualization.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7. Diagnostic Output"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Save full benchmark results to JSON\n", "save_path = save_benchmark_results(\n", "    results,\n", "    path=os.path.join(ARTIFACT_DIR, \"strategy_benchmark_results.json\"),\n", ")\n", "print(\"Results saved to: %s\" % save_path)\n", "\n", "# Print per-strategy detail\n", "print(\"\\n\" + \"=\" * 70)\n", "print(\"DETAILED RESULTS\")\n", "print(\"=\" * 70)\n", "for r in results:\n", "    print(\"\\n--- %s / %s [%s] ---\" % (r.name, r.horizon, r.status))\n", "    print(\"  IC: %.4f +/- %.4f  ICIR: %.2f\" % (r.ic_mean, r.ic_std, r.icir))\n", "    print(\"  Sharpe: %.2f  MaxDD: %.4f\" % (r.sharpe, r.max_drawdown))\n", "    print(\"  Overfit: %.3f  Composite: %.4f\" % (r.overfit_score, r.composite))\n", "    print(\"  Prod IC: %.4f  Params: %d  Time: %.1fs\" % (\n", "        r.prod_ic, r.param_count, r.train_time))\n", "    if r.fold_metrics:\n", "        fold_ics = [f.ic for f in r.fold_metrics]\n", "        print(\"  Fold ICs: %s\" % [round(x, 4) for x in fold_ics])\n", "    if r.extended:\n", "        e = r.extended\n", "        print(\"  R2: %.4f  Hit%%: %.1f%%  Cal.Slope: %.3f\" % (\n", "            e.r_squared, e.hit_ratio * 100, e.calib_slope))\n", "        print(\"  L/O Sharpe: %.2f  L/S Sharpe: %.2f\" % (e.lo_sharpe, e.ls_sharpe))\n", "    if r.gate_stats:\n", "        print(\"  Gate: mean=%.3f std=%.3f\" % (\n", "            r.gate_stats.get(\"gate_mean\", 0), r.gate_stats.get(\"gate_std\", 0)))\n", "    if r.ensemble_weights:\n", "        w = r.ensemble_weights\n", "        print(\"  Ensemble: lstm=%.3f nlp=%.3f intercept=%.4f\" % (\n", "            w.get(\"lstm\", 0), w.get(\"nlp\", 0), w.get(\"intercept\", 0)))"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 8. Experimental Integrity Checks"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["warnings = run_integrity_checks(results)\n", "\n", "if warnings:\n", "    print(\"INTEGRITY WARNINGS (%d):\" % len(warnings))\n", "    for w in warnings:\n", "        print(\"  [!] %s\" % w)\n", "else:\n", "    print(\"All integrity checks passed.\")\n", "\n", "# Additional checks\n", "print(\"\\nConsistency Checks:\")\n", "\n", "for h in sorted(set(r.horizon for r in results)):\n", "    fold_counts = [len(r.fold_metrics) for r in results if r.horizon == h]\n", "    if len(set(fold_counts)) > 1:\n", "        print(\"  [!] Inconsistent fold counts at %s: %s\" % (h, fold_counts))\n", "    else:\n", "        print(\"  [OK] %s: %d folds for all strategies\" % (h, fold_counts[0] if fold_counts else 0))\n", "\n", "for r in results:\n", "    if r.param_count > CONFIG[\"max_params\"]:\n", "        print(\"  [!] %s: %d params > %d limit\" % (r.name, r.param_count, CONFIG[\"max_params\"]))\n", "\n", "print(\"\\nIntegrity check complete.\")"],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Summary & Decision\n", "\n", "This benchmark answers:\n", "\n", "1. **Does sentiment add incremental alpha?** Compare A vs C/E\n", "2. **Is hybrid destructive or additive?** Compare A vs E/E1/E2\n", "3. **Is ensemble safer than fusion?** Compare C vs E\n", "4. **Cross-attention vs additive fusion?** Compare E1 vs E2\n", "5. **Transformer vs LSTM?** Compare G vs A\n", "6. **Trees vs neural networks?** Compare H/I vs A\n", "7. **Which structure survives production retrain?** Check Prod IC column\n", "8. **Statistical significance?** DM test p-values"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": ["# Extended decision summary\n", "print(\"=\" * 60)\n", "print(\"PRICE PREDICTION SUMMARY\")\n", "print(\"=\" * 60)\n", "\n", "# Best by extended metrics\n", "ext_results_all = [r for r in results if r.extended is not None]\n", "if ext_results_all:\n", "    best_r2 = max(ext_results_all, key=lambda r: r.extended.mean_stock_r2)\n", "    print(\"\\nBest by Mean Stock R2: %s/%s (%.4f)\" % (\n", "        best_r2.name, best_r2.horizon, best_r2.extended.mean_stock_r2))\n", "\n", "    best_hit = max(ext_results_all, key=lambda r: r.extended.hit_ratio)\n", "    print(\"Best by Directional Accuracy: %s/%s (%.1f%%)\" % (\n", "        best_hit.name, best_hit.horizon, best_hit.extended.hit_ratio * 100))\n", "\n", "    best_cal = min(ext_results_all, key=lambda r: abs(r.extended.calib_slope - 1.0))\n", "    print(\"Best Calibration (slope closest to 1): %s/%s (%.3f)\" % (\n", "        best_cal.name, best_cal.horizon, best_cal.extended.calib_slope))\n", "\n", "    best_lo = max(ext_results_all, key=lambda r: r.extended.lo_sharpe)\n", "    print(\"Highest Sharpe (L/O): %s/%s (%.2f)\" % (\n", "        best_lo.name, best_lo.horizon, best_lo.extended.lo_sharpe))\n", "\n", "    best_ls = max(ext_results_all, key=lambda r: r.extended.ls_sharpe)\n", "    print(\"Highest Sharpe (L/S): %s/%s (%.2f)\" % (\n", "        best_ls.name, best_ls.horizon, best_ls.extended.ls_sharpe))\n", "\n", "# DM significance vs baseline\n", "if dm_results:\n", "    baseline_name = \"A_LSTM_Baseline\"\n", "    sig_improvements = [dm for dm in dm_results\n", "                        if dm.p_value < 0.05\n", "                        and (dm.strategy_a == baseline_name or dm.strategy_b == baseline_name)\n", "                        and dm.better != baseline_name]\n", "    if sig_improvements:\n", "        print(\"\\nDM test: significant improvements over baseline:\")\n", "        for dm in sig_improvements:\n", "            print(\"  %s beats %s at %s (p=%.4f)\" % (\n", "                dm.better, baseline_name, dm.horizon, dm.p_value))\n", "    else:\n", "        print(\"\\nDM test: no strategy significantly beats baseline (p<0.05)\")\n", "\n", "# Key comparisons\n", "print(\"\\n--- Key Comparisons ---\")\n", "\n", "# Sentiment alpha\n", "a_21 = [r for r in results if r.name.startswith(\"A_\") and r.horizon == \"21D\"]\n", "c_21 = [r for r in results if r.name.startswith(\"C_\") and r.horizon == \"21D\"]\n", "e_21 = [r for r in results if r.name.startswith(\"E_\") and r.horizon == \"21D\"]\n", "if a_21 and c_21:\n", "    delta = c_21[0].ic_mean - a_21[0].ic_mean\n", "    verdict = \"YES (+%.4f IC)\" % delta if delta > 0.005 else \"NO (delta=%.4f)\" % delta\n", "    print(\"1. Sentiment adds alpha? %s\" % verdict)\n", "\n", "# Hybrid vs baseline\n", "if a_21 and e_21:\n", "    delta = e_21[0].ic_mean - a_21[0].ic_mean\n", "    verdict = \"ADDITIVE (+%.4f)\" % delta if delta > 0 else \"DESTRUCTIVE (%.4f)\" % delta\n", "    print(\"2. Hybrid vs LSTM? %s\" % verdict)\n", "\n", "# Cross-attention vs additive\n", "e1_21 = [r for r in results if r.name.startswith(\"E1\") and r.horizon == \"21D\"]\n", "e2_21 = [r for r in results if r.name.startswith(\"E2\") and r.horizon == \"21D\"]\n", "if e1_21 and e2_21:\n", "    if e1_21[0].ic_mean > e2_21[0].ic_mean:\n", "        print(\"3. Cross-attn vs Additive? CROSS-ATTN (IC %.4f vs %.4f)\" % (\n", "            e1_21[0].ic_mean, e2_21[0].ic_mean))\n", "    else:\n", "        print(\"3. Cross-attn vs Additive? ADDITIVE (IC %.4f vs %.4f)\" % (\n", "            e2_21[0].ic_mean, e1_21[0].ic_mean))\n", "\n", "# Transformer vs LSTM\n", "g_21 = [r for r in results if r.name.startswith(\"G_\") and r.horizon == \"21D\"]\n", "if a_21 and g_21:\n", "    delta = g_21[0].ic_mean - a_21[0].ic_mean\n", "    verdict = \"TRANSFORMER (+%.4f)\" % delta if delta > 0 else \"LSTM (%.4f)\" % delta\n", "    print(\"4. Transformer vs LSTM? %s\" % verdict)\n", "\n", "# Trees vs neural\n", "h_21 = [r for r in results if r.name.startswith(\"H_\") and r.horizon == \"21D\"]\n", "i_21 = [r for r in results if r.name.startswith(\"I_\") and r.horizon == \"21D\"]\n", "if a_21 and h_21 and i_21:\n", "    best_tree = max([h_21[0], i_21[0]], key=lambda r: r.ic_mean)\n", "    delta = best_tree.ic_mean - a_21[0].ic_mean\n", "    verdict = \"TREES (+%.4f)\" % delta if delta > 0 else \"NEURAL (%.4f)\" % delta\n", "    print(\"5. Trees vs Neural? %s (best tree: %s)\" % (verdict, best_tree.name))\n", "\n", "# Production survival\n", "print(\"\\n--- Production Survival ---\")\n", "for r in results:\n", "    if r.ic_mean > 0 and r.prod_ic > 0:\n", "        ratio = r.prod_ic / r.ic_mean if r.ic_mean > 1e-8 else 0\n", "        survived = \"SURVIVED\" if ratio >= 0.9 else \"DEGRADED\"\n", "        print(\"  %s/%s: WF IC=%.4f -> Prod IC=%.4f (%.0f%%) [%s]\" % (\n", "            r.name, r.horizon, r.ic_mean, r.prod_ic, ratio * 100, survived))\n", "\n", "# Final recommendation\n", "print(\"\\n\" + \"=\" * 60)\n", "passing = [r for r in results if r.status == \"PASS\"]\n", "if passing:\n", "    best = passing[0]\n", "    print(\"RECOMMENDATION: Deploy %s\" % best.name)\n", "    print(\"  Composite: %.4f  IC: %.4f  Prod IC: %.4f\" % (\n", "        best.composite, best.ic_mean, best.prod_ic))\n", "    if best.extended:\n", "        print(\"  R2: %.4f  Hit%%: %.1f%%  L/S Sharpe: %.2f\" % (\n", "            best.extended.r_squared, best.extended.hit_ratio * 100,\n", "            best.extended.ls_sharpe))\n", "else:\n", "    warning_results = [r for r in results if r.status == \"WARN\"]\n", "    if warning_results:\n", "        print(\"RECOMMENDATION: Cautiously deploy %s (WARN status)\" % warning_results[0].name)\n", "    else:\n", "        print(\"RECOMMENDATION: No viable strategy. Review data/features.\")\n", "print(\"=\" * 60)"],
   "execution_count": null,
   "outputs": []
  }
 ]
}