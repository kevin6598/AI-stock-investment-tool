{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f# Multi-Strategy Benchmark (Extended)\n",
    "\n",
    "Compare **15 alpha extraction strategies** under identical walk-forward conditions.\n",
    "\n",
    "| ID | Strategy | Architecture |\n",
    "|----|----------|-------------|\n",
    "| A | LSTM Baseline | Price-only temporal LSTM |\n",
    "| B | NLP Only | Sentiment MLP |\n",
    "| C | Late Ensemble | A + B with ridge meta |\n",
    "| D | Residual Sentiment | Market-residualized NLP |\n",
    "| E | Gated Hybrid | Gated price-NLP fusion |\n",
    "| E1 | Attention Hybrid | Cross-attention price/NLP |\n",
    "| E2 | Additive Residual | T + alpha*S fusion |\n",
    "| F | CS-Attention LSTM | Temporal + stock attention |\n",
    "| F1 | Temporal Fusion | Simplified TFT |\n",
    "| G | Transformer | Encoder-only transformer |\n",
    "| G1 | Efficient Transformer | Linear attention O(n*d) |\n",
    "| H | Random Forest | sklearn RF (no torch) |\n",
    "| I | LightGBM | Gradient boosted trees (no torch) |\n",
    "| J | Short Horizon NLP | NLP MLP 5D only |\n",
    "| K | Short Horizon Hybrid | Gated hybrid 5D only |\n",
    "\n",
    "**Evaluation:** IC, Sharpe, R2, per-stock R2, directional accuracy, calibration, market-level prediction, backtest PnL, DM statistical tests.\n",
    "\n",
    "**Goal:** Determine which structure produces real, production-surviving alpha."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install -q yfinance lightgbm torch optuna pyarrow scikit-learn scipy pandas numpy matplotlib"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.chdir(\"/content\")\n",
    "!rm -rf AI-stock-investment-tool\n",
    "\n",
    "REPO = \"https://github.com/kevin6598/AI-stock-investment-tool.git\"\n",
    "ret = os.system(\"git clone %s 2>/dev/null\" % REPO)\n",
    "if ret != 0:\n",
    "    from getpass import getpass\n",
    "    token = getpass(\"GitHub token (repo scope): \")\n",
    "    os.system(\"git clone https://%s@github.com/kevin6598/AI-stock-investment-tool.git\" % token)\n",
    "    del token\n",
    "\n",
    "os.chdir(\"/content/AI-stock-investment-tool\")\n",
    "!git log --oneline -3"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch, sys\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"PyTorch: %s\" % torch.__version__)\n",
    "print(\"CUDA: %s\" % torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU: %s\" % torch.cuda.get_device_name(0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Dataset & Benchmark Configuration\n\n**Dataset presets** -- choose universe size, market, and data period.\nWalk-forward parameters auto-adjust based on data period length.\n\n| Preset | Universe | Tickers | Best for |\n|--------|----------|---------|----------|\n| default | S&P subset + KOSPI/KOSDAQ | ~100 | Quick test (~30 min) |\n| extended | Larger S&P + Korean | ~160 | Thorough benchmark (~60 min) |\n| custom | User-defined | variable | Focused analysis |\n\n| Period | Train Years | Horizons | Est. Folds |\n|--------|-------------|----------|------------|\n| 5y | 2 | 5D, 21D | ~4 |\n| 10y | 3 | 5D, 21D, 63D | ~10 |\n| 15y | 4 | 5D, 21D, 63D | ~16 |"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ==============================================\n# DATASET CONFIGURATION -- CHANGE THESE VALUES\n# ==============================================\n\n# Universe: \"default\" (~100 tickers), \"extended\" (~160), \"custom\"\nUNIVERSE = \"extended\"\n\n# Market filter: \"ALL\" (KOSPI+KOSDAQ+NASDAQ), \"US\" (NASDAQ/NYSE only), \"KR\" (KOSPI+KOSDAQ only)\nMARKET = \"ALL\"\n\n# Data period: \"5y\", \"10y\", \"15y\"\nPERIOD = \"10y\"\n\n# Custom tickers (only used when UNIVERSE=\"custom\")\nCUSTOM_TICKERS = [\n    # US Tech\n    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\",\n    # US Finance\n    \"JPM\", \"GS\", \"V\", \"MA\",\n    # US Healthcare\n    \"JNJ\", \"UNH\", \"LLY\", \"PFE\",\n    # KOSPI\n    \"005930.KS\", \"000660.KS\", \"035420.KS\", \"005380.KS\", \"051910.KS\",\n    # KOSDAQ\n    \"293490.KQ\", \"247540.KQ\", \"086520.KQ\",\n]\n\n# ==============================================\n# RUN MODE -- controls speed vs thoroughness\n# ==============================================\n# \"quick\"    : 8 key strategies, 2 horizons, fewer folds (~20-30 min)\n# \"standard\" : all 15 strategies, auto horizons (~60-90 min)\n# \"full\"     : all 15 strategies, all horizons, more folds (~120-180 min)\nRUN_MODE = \"standard\"\n\n# Strategy subset (None = use RUN_MODE default, or list specific keys)\n# e.g. [\"A\", \"C\", \"E\", \"E1\", \"G\", \"H\", \"I\"] for a focused comparison\nSTRATEGY_KEYS = None\n\n# Email notification when benchmark completes\nNOTIFY_EMAIL = \"seo.kevin6598@gmail.com\"  # set to None to disable\n\n# ==============================================\n# BENCHMARK CONFIGURATION (auto-adjusted)\n# ==============================================\n_period_years = {\"5y\": 5, \"10y\": 10, \"15y\": 15}.get(PERIOD, 5)\n\n# Run mode presets\nif RUN_MODE == \"quick\":\n    _max_epochs = 8\n    _early_stop = 3\n    if _period_years >= 10:\n        _train_years = 3\n        _test_months = 6\n        _step_months = 12   # larger steps = fewer folds\n        _val_months = 3\n        _horizons = [5, 21]  # skip 63D for speed\n    else:\n        _train_years = 2\n        _test_months = 4\n        _step_months = 6\n        _val_months = 2\n        _horizons = [5, 21]\n    _default_strategies = [\"A\", \"B\", \"C\", \"E\", \"E1\", \"G\", \"H\", \"I\"]\nelif RUN_MODE == \"full\":\n    _max_epochs = 15\n    _early_stop = 4\n    if _period_years >= 15:\n        _train_years = 4\n        _test_months = 6\n        _step_months = 4     # smaller steps = more folds\n        _val_months = 3\n        _horizons = [5, 21, 63]\n    elif _period_years >= 10:\n        _train_years = 3\n        _test_months = 6\n        _step_months = 4\n        _val_months = 3\n        _horizons = [5, 21, 63]\n    else:\n        _train_years = 2\n        _test_months = 4\n        _step_months = 3\n        _val_months = 2\n        _horizons = [5, 21]\n    _default_strategies = None  # all\nelse:  # standard\n    _max_epochs = 10\n    _early_stop = 3\n    if _period_years >= 10:\n        _train_years = 3\n        _test_months = 6\n        _step_months = 6\n        _val_months = 3\n        _horizons = [5, 21, 63]\n    else:\n        _train_years = 2\n        _test_months = 4\n        _step_months = 4\n        _val_months = 2\n        _horizons = [5, 21]\n    _default_strategies = None  # all\n\n# User override for strategy subset\nSTRATEGY_KEYS = STRATEGY_KEYS if STRATEGY_KEYS is not None else _default_strategies\n\nCONFIG = {\n    \"horizons\": _horizons,\n    \"walk_forward\": {\n        \"train_years\": _train_years,\n        \"test_months\": _test_months,\n        \"step_months\": _step_months,\n        \"val_months\": _val_months,\n        \"embargo_days\": 5,\n    },\n    \"max_epochs\": _max_epochs,\n    \"early_stop_patience\": _early_stop,\n    \"ranking_weight\": 0.5,\n    \"max_params\": 1_500_000,\n}\n\nprint(\"=== Dataset Configuration ===\")\nprint(\"Universe: %s  |  Market: %s  |  Period: %s (%dy)\" % (\n    UNIVERSE, MARKET, PERIOD, _period_years))\nprint(\"\\n=== Run Mode: %s ===\" % RUN_MODE.upper())\nif STRATEGY_KEYS:\n    print(\"Strategies: %d selected %s\" % (len(STRATEGY_KEYS), STRATEGY_KEYS))\nelse:\n    print(\"Strategies: ALL 15\")\nprint(\"Horizons: %s\" % _horizons)\nprint(\"Walk-forward: train=%dy, test=%dmo, step=%dmo, val=%dmo\" % (\n    _train_years, _test_months, _step_months, _val_months))\nprint(\"Epochs: max=%d, early_stop=%d\" % (_max_epochs, _early_stop))\nif NOTIFY_EMAIL:\n    print(\"\\nEmail notification: %s\" % NOTIFY_EMAIL)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Standardized Data Pipeline\n\nDownloads OHLCV data via yfinance, builds features (technical, sentiment, macro, fundamental, risk),\nand caches the result to Google Drive for fast re-runs.\n\nFirst run may take **15-30 min** depending on universe size. Subsequent runs load from cache instantly."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\n\n# Try mounting Google Drive (optional - falls back to local storage)\nDRIVE_MOUNTED = False\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive', timeout_ms=60000)\n    DRIVE_MOUNTED = True\n    DRIVE_DIR = \"/content/drive/MyDrive/ai_stock_tool\"\n    print(\"Google Drive mounted.\")\nexcept Exception as _drive_err:\n    print(\"Drive mount failed: %s\" % str(_drive_err)[:80])\n    print(\"Using local storage instead (data will NOT persist across sessions).\")\n    DRIVE_DIR = \"/content/ai_stock_tool\"\n\nARTIFACT_DIR = os.path.join(DRIVE_DIR, \"artifacts\")\nos.makedirs(ARTIFACT_DIR, exist_ok=True)\n\n# Cache path based on universe, market, period\n_cache_name = \"benchmark_%s_%s_%s.parquet\" % (UNIVERSE, MARKET, PERIOD)\nDATA_PATH = os.path.join(DRIVE_DIR, _cache_name)\nprint(\"Data path: %s\" % DATA_PATH)\nprint(\"Artifacts: %s\" % ARTIFACT_DIR)\n\nif os.path.exists(DATA_PATH):\n    print(\"\\nFound cached dataset, loading...\")\n    panel = pd.read_parquet(DATA_PATH)\n    print(\"Loaded from cache: %s\" % str(panel.shape))\nelse:\n    print(\"\\nNo cached dataset found. Building from scratch...\")\n    print(\"This may take 15-30 min depending on universe size.\\n\")\n\n    from data.stock_api import get_historical_data, get_stock_info\n    from data.universe_manager import UniverseManager\n    from training.feature_engineering import build_panel_dataset, cross_sectional_normalize\n\n    # --- Resolve ticker list ---\n    um = UniverseManager()\n    if UNIVERSE == \"extended\":\n        um._members = UniverseManager.load_extended_universe()\n\n    if UNIVERSE == \"custom\":\n        tickers = CUSTOM_TICKERS\n    else:\n        tickers = um.get_universe_by_market(MARKET)\n\n    print(\"Target: %d tickers (universe=%s, market=%s, period=%s)\" % (\n        len(tickers), UNIVERSE, MARKET, PERIOD))\n\n    # --- Download OHLCV + company info ---\n    import time as _time\n    stock_dfs = {}\n    stock_infos = {}\n    failed = []\n    t0 = _time.time()\n\n    for i, ticker in enumerate(tickers):\n        if (i + 1) % 10 == 0 or i == 0:\n            elapsed = _time.time() - t0\n            print(\"  [%d/%d] %s (%.0fs elapsed)\" % (i + 1, len(tickers), ticker, elapsed))\n        try:\n            df = get_historical_data(ticker, period=PERIOD)\n            if df.empty:\n                failed.append(ticker)\n                continue\n            stock_dfs[ticker] = df\n            info = get_stock_info(ticker) or {}\n            stock_infos[ticker] = info\n        except Exception as ex:\n            failed.append(ticker)\n            print(\"    FAILED: %s -- %s\" % (ticker, str(ex)[:80]))\n\n    dl_time = _time.time() - t0\n    print(\"\\nDownloaded: %d/%d tickers in %.0f sec\" % (\n        len(stock_dfs), len(tickers), dl_time))\n    if failed:\n        print(\"Failed (%d): %s%s\" % (\n            len(failed), \", \".join(failed[:20]),\n            \" ...\" if len(failed) > 20 else \"\"))\n\n    # --- Market index ---\n    market_ticker = um.get_market_ticker(list(stock_dfs.keys()))\n    print(\"\\nMarket index: %s\" % market_ticker)\n    market_df = get_historical_data(market_ticker, period=PERIOD)\n    if market_df.empty:\n        print(\"WARNING: Market index download failed\")\n        market_df = None\n\n    # --- Build feature panel ---\n    horizons_days = CONFIG[\"horizons\"]\n    print(\"\\nBuilding features (horizons=%s)...\" % horizons_days)\n    t1 = _time.time()\n    panel = build_panel_dataset(stock_dfs, stock_infos, market_df, horizons_days)\n    print(\"Raw panel: %s (%.0f sec)\" % (str(panel.shape), _time.time() - t1))\n\n    # Cross-sectional normalization\n    panel = cross_sectional_normalize(panel)\n    print(\"Normalized: %s\" % str(panel.shape))\n\n    # Save for future runs\n    try:\n        panel.to_parquet(DATA_PATH)\n        _size_mb = os.path.getsize(DATA_PATH) / 1e6\n        print(\"\\nCached to: %s (%.1f MB)\" % (DATA_PATH, _size_mb))\n        if not DRIVE_MOUNTED:\n            print(\"NOTE: Local cache only -- will be lost when runtime disconnects.\")\n    except Exception as _save_err:\n        print(\"Cache save failed: %s\" % str(_save_err)[:80])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "valid_tickers = panel.index.get_level_values(1).unique().tolist()\nprint(\"Panel: %s\" % str(panel.shape))\nprint(\"Tickers: %d\" % len(valid_tickers))\n\ndate_min = panel.index.get_level_values(0).min()\ndate_max = panel.index.get_level_values(0).max()\ndata_span_months = (date_max - date_min).days / 30.44\nprint(\"Date range: %s to %s (%.0f months)\" % (\n    date_min.date(), date_max.date(), data_span_months))\n\n# --- Market Composition ---\nkr_kospi = sorted([t for t in valid_tickers if t.upper().endswith(\".KS\")])\nkr_kosdaq = sorted([t for t in valid_tickers if t.upper().endswith(\".KQ\")])\nus_tickers = sorted([t for t in valid_tickers\n                     if not t.upper().endswith((\".KS\", \".KQ\"))])\n\nprint(\"\\n=== Market Composition ===\")\nprint(\"NYSE/NASDAQ: %d tickers\" % len(us_tickers))\nprint(\"KOSPI (.KS): %d tickers\" % len(kr_kospi))\nprint(\"KOSDAQ (.KQ): %d tickers\" % len(kr_kosdaq))\n\nif kr_kospi:\n    print(\"\\nKOSPI: %s\" % \", \".join(kr_kospi))\nif kr_kosdaq:\n    print(\"KOSDAQ: %s\" % \", \".join(kr_kosdaq))\nif us_tickers and len(us_tickers) <= 30:\n    print(\"US: %s\" % \", \".join(us_tickers))\nelif us_tickers:\n    print(\"US (first 30): %s ...\" % \", \".join(us_tickers[:30]))\n\n# --- Per-ticker data coverage ---\nticker_counts = panel.groupby(level=1).size()\nprint(\"\\n=== Data Coverage ===\")\nprint(\"Avg samples/ticker: %.0f\" % ticker_counts.mean())\nprint(\"Min: %d (%s)  Max: %d (%s)\" % (\n    ticker_counts.min(), ticker_counts.idxmin(),\n    ticker_counts.max(), ticker_counts.idxmax()))\n\nthin = ticker_counts[ticker_counts < 500]\nif len(thin) > 0:\n    print(\"Tickers with < 500 samples (%d): %s\" % (\n        len(thin), \", \".join(thin.index.tolist()[:15])))\n\n# --- Fold estimate ---\nwf = CONFIG[\"walk_forward\"]\ntrain_months = wf[\"train_years\"] * 12\nval_months = wf.get(\"val_months\", 3)\ntest_months = wf[\"test_months\"]\nstep_months = wf[\"step_months\"]\nmin_needed = train_months + val_months + test_months + 1\navailable_after_first = data_span_months - min_needed\nest_folds = max(0, 1 + int(available_after_first / step_months))\nprint(\"\\n=== Walk-Forward Folds ===\")\nprint(\"train=%dmo + val=%dmo + test=%dmo = %dmo minimum\" % (\n    train_months, val_months, test_months, min_needed))\nprint(\"Expected folds: ~%d (step=%dmo over %.0f months)\" % (\n    est_folds, step_months, data_span_months))\nif est_folds == 0:\n    print(\"WARNING: No folds possible! Reduce train_years or increase data period.\")\n\n# --- Feature columns ---\nfeature_cols = [\n    c for c in panel.columns\n    if not c.startswith(\"fwd_return_\")\n    and not c.startswith(\"residual_return_\")\n    and not c.startswith(\"ranked_target_\")\n    and c not in (\"_close\", \"ticker_id\")\n]\n\nprice_cols = [c for c in feature_cols if not c.startswith(\"nlp_\")]\nnlp_cols = [c for c in feature_cols if c.startswith(\"nlp_\")]\nprint(\"\\n=== Features ===\")\nprint(\"Total: %d  (Price: %d, NLP: %d)\" % (\n    len(feature_cols), len(price_cols), len(nlp_cols)))\n\n# Check required targets\nfor h in CONFIG[\"horizons\"]:\n    tc = \"fwd_return_%dd\" % h\n    if tc in panel.columns:\n        non_null = panel[tc].notna().sum()\n        print(\"  %s: %d non-null (%.1f%%)\" % (\n            tc, non_null, non_null / len(panel) * 100))\n    else:\n        print(\"  WARNING: %s not found!\" % tc)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Precompute derived features for all strategies\n",
    "\n",
    "# Sentiment residual (for Strategy D)\n",
    "market_feat = None\n",
    "for cand in [\"market_return\", \"market_return_21d\", \"spy_return_21d\"]:\n",
    "    if cand in panel.columns:\n",
    "        market_feat = cand\n",
    "        break\n",
    "\n",
    "if market_feat:\n",
    "    print(\"Market return feature: %s\" % market_feat)\n",
    "else:\n",
    "    print(\"WARNING: No market return feature found for residualization\")\n",
    "\n",
    "# Volatility proxy\n",
    "vol_feat = None\n",
    "for cand in [\"volatility_21d\", \"realized_vol_21d\", \"atr_pct\"]:\n",
    "    if cand in panel.columns:\n",
    "        vol_feat = cand\n",
    "        break\n",
    "\n",
    "if vol_feat:\n",
    "    print(\"Volatility feature: %s\" % vol_feat)\n",
    "else:\n",
    "    print(\"WARNING: No volatility feature found\")\n",
    "\n",
    "# Data quality check\n",
    "nan_pct = panel[feature_cols].isna().mean().mean() * 100\n",
    "print(\"\\nNaN rate: %.2f%%\" % nan_pct)\n",
    "print(\"Data pipeline ready.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Strategy Definitions\n",
    "\n",
    "All 15 strategies with identical interface: `train()`, `predict()`, `num_parameters()`.\n",
    "\n",
    "- **A-F**: Neural temporal/NLP models (require PyTorch)\n",
    "- **E1, E2**: Novel fusion architectures (cross-attention, additive residual)\n",
    "- **F1**: Simplified Temporal Fusion Transformer\n",
    "- **G, G1**: Transformer variants (standard + linear attention)\n",
    "- **H, I**: Tree-based models (no torch required)\n",
    "- **J, K**: Short-horizon specialists (5D only)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from training.strategy_benchmark import (\n    BenchmarkConfig, BenchmarkEvaluator, STRATEGY_REGISTRY,\n    save_benchmark_results, run_integrity_checks,\n    ExtendedMetrics, DMTestResult,\n)\n\nconfig = BenchmarkConfig.from_dict(CONFIG)\n\n# Filter strategies based on STRATEGY_KEYS\nif STRATEGY_KEYS is not None:\n    selected_registry = {k: v for k, v in STRATEGY_REGISTRY.items() if k in STRATEGY_KEYS}\n    missing = set(STRATEGY_KEYS) - set(selected_registry.keys())\n    if missing:\n        print(\"WARNING: Unknown strategy keys: %s\" % missing)\nelse:\n    selected_registry = STRATEGY_REGISTRY\n\nprint(\"Strategies to benchmark (%d / %d):\" % (len(selected_registry), len(STRATEGY_REGISTRY)))\nprint(\"-\" * 55)\nfor key, cls in sorted(selected_registry.items()):\n    sh = getattr(cls, 'supported_horizons', None)\n    h_info = \"all horizons\" if sh is None else \"%s only\" % sh\n    print(\"  %-3s: %-28s (%s)\" % (key, cls.name, h_info))\n\n# Estimate total evaluations\nn_strats = len(selected_registry)\nn_horizons = len(config.horizons)\n# Short-horizon strategies only run at 5D\nshort_only = sum(1 for cls in selected_registry.values()\n                 if getattr(cls, 'supported_horizons', None) == [5])\nn_evals = n_strats * n_horizons - short_only * (n_horizons - 1)\nprint(\"\\nEstimated evaluations: %d (strategies x horizons)\" % n_evals)\nprint(\"Estimated folds per eval: ~%d\" % est_folds)\nprint(\"Total training runs: ~%d\" % (n_evals * est_folds))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Run Benchmark\n\nWalk-forward evaluation for selected strategies at configured horizons.\n\n**Checkpoint/Resume:** Results are saved per-strategy to `ARTIFACT_DIR/checkpoints/`.\nIf the runtime times out, simply re-run this cell -- completed strategies will be\nloaded from checkpoint and only remaining strategies will be computed.\nSet `CLEAR_CHECKPOINTS = True` to discard previous results and start fresh.\n\n**Estimated runtime (T4 GPU):**\n\n| Run Mode | Strategies | Horizons | Folds (10y) | Est. Time |\n|----------|-----------|----------|-------------|-----------|\n| `quick` | 8 key | 5D, 21D | ~5 | **20-30 min** |\n| `standard` | all 15 | 5D, 21D, 63D | ~10 | **60-90 min** |\n| `full` | all 15 | 5D, 21D, 63D | ~14 | **120-180 min** |\n\nEmail notification is sent to `NOTIFY_EMAIL` when the benchmark completes."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import logging\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=\"%H:%M:%S\")\n\nevaluator = BenchmarkEvaluator(panel, feature_cols, config)\n\n# Checkpoint directory -- saves each strategy result to disk after completion.\n# On runtime timeout, re-run this cell to resume from the last checkpoint.\nCHECKPOINT_DIR = os.path.join(ARTIFACT_DIR, \"checkpoints\")\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n# To force a full re-run (discard previous checkpoints), set CLEAR_CHECKPOINTS = True\nCLEAR_CHECKPOINTS = False\nif CLEAR_CHECKPOINTS:\n    import glob as _glob\n    for _f in _glob.glob(os.path.join(CHECKPOINT_DIR, \"*.pkl\")):\n        os.remove(_f)\n    print(\"Cleared all checkpoints.\")\n\n# Delete specific broken checkpoints to force re-evaluation\n_DELETE_CHECKPOINTS = [\"I_LightGBM_5D.pkl\"]\nfor _ckpt_name in _DELETE_CHECKPOINTS:\n    _ckpt_path = os.path.join(CHECKPOINT_DIR, _ckpt_name)\n    if os.path.exists(_ckpt_path):\n        os.remove(_ckpt_path)\n        print(\"Deleted checkpoint: %s (will re-evaluate)\" % _ckpt_name)\n\n# Show existing checkpoints\n_existing = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith(\".pkl\")]\nif _existing:\n    print(\"Found %d checkpoint(s) from previous run -- will resume:\" % len(_existing))\n    for _f in sorted(_existing):\n        print(\"  %s\" % _f)\nelse:\n    print(\"No checkpoints found -- starting fresh run.\")\n\nstrategy_classes = list(selected_registry.values())\nn_horizons_eff = len(config.horizons)\nprint(\"\\nRunning %d strategies x %d horizons (mode=%s)...\" % (\n    len(strategy_classes), n_horizons_eff, RUN_MODE))\nprint(\"=\" * 60)\n\nimport time\nt0 = time.time()\nresults = evaluator.run_all(strategy_classes, checkpoint_dir=CHECKPOINT_DIR)\ntotal_time = time.time() - t0\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Benchmark complete in %.1f min\" % (total_time / 60))\nprint(\"Total evaluations: %d\" % len(results))\nprint(\"Strategies with extended metrics: %d\" % sum(1 for r in results if r.extended))\n\n# --- Email notification ---\nif NOTIFY_EMAIL:\n    _benchmark_summary = (\n        \"Benchmark complete in %.1f min\\n\"\n        \"Mode: %s | Universe: %s | Market: %s | Period: %s\\n\"\n        \"Strategies: %d | Evaluations: %d\\n\\n\"\n        % (total_time / 60, RUN_MODE, UNIVERSE, MARKET, PERIOD,\n           len(strategy_classes), len(results))\n    )\n    # Top 5 results\n    _top = sorted(results, key=lambda r: r.composite, reverse=True)[:5]\n    _benchmark_summary += \"=== Top 5 by Composite ===\\n\"\n    for _r in _top:\n        _benchmark_summary += \"  %s/%s: IC=%.4f Sharpe=%.2f Composite=%.4f [%s]\\n\" % (\n            _r.name, _r.horizon, _r.ic_mean, _r.sharpe, _r.composite, _r.status)\n\n    try:\n        import smtplib\n        from email.mime.text import MIMEText\n        from google.colab import auth\n        import google.auth\n        import google.auth.transport.requests\n        from googleapiclient.discovery import build\n        import base64\n\n        auth.authenticate_user()\n        creds, _ = google.auth.default()\n        creds.refresh(google.auth.transport.requests.Request())\n        service = build('gmail', 'v1', credentials=creds)\n\n        msg = MIMEText(_benchmark_summary)\n        msg['to'] = NOTIFY_EMAIL\n        msg['subject'] = '[Benchmark] %s/%s/%s done - %.0fmin' % (\n            UNIVERSE, MARKET, PERIOD, total_time / 60)\n        raw = base64.urlsafe_b64encode(msg.as_bytes()).decode()\n        service.users().messages().send(\n            userId='me', body={'raw': raw}).execute()\n        print(\"Email sent to %s\" % NOTIFY_EMAIL)\n    except Exception as mail_err:\n        print(\"Email notification failed: %s\" % str(mail_err)[:100])\n        print(\"(Summary printed above instead)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strategy Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "# Build comparison table\n",
    "rows = []\n",
    "for r in results:\n",
    "    rows.append({\n",
    "        \"Strategy\": r.name,\n",
    "        \"Horizon\": r.horizon,\n",
    "        \"IC\": round(r.ic_mean, 4),\n",
    "        \"ICIR\": round(r.icir, 2),\n",
    "        \"Sharpe\": round(r.sharpe, 2),\n",
    "        \"IC_std\": round(r.ic_std, 4),\n",
    "        \"Prod IC\": round(r.prod_ic, 4),\n",
    "        \"Overfit\": round(r.overfit_score, 3),\n",
    "        \"Composite\": round(r.composite, 4),\n",
    "        \"Params\": r.param_count,\n",
    "        \"Time(s)\": round(r.train_time, 1),\n",
    "        \"Status\": r.status,\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "print(\"\\nStrategy Benchmark Results (sorted by Composite):\")\n",
    "print(\"=\" * 100)\n",
    "display(df_results)\n",
    "\n",
    "# Summary by status\n",
    "print(\"\\nStatus Summary:\")\n",
    "for status in [\"PASS\", \"WARN\", \"FAIL\"]:\n",
    "    count = sum(1 for r in results if r.status == status)\n",
    "    names = [r.name + \"/\" + r.horizon for r in results if r.status == status]\n",
    "    print(\"  %s (%d): %s\" % (status, count, \", \".join(names) if names else \"none\"))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a. Extended Metrics Table\n",
    "\n",
    "Regression accuracy, directional metrics, calibration, and market-level predictions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extended Metrics: Regression, Directional, Calibration, Market-level\n",
    "ext_rows = []\n",
    "for r in results:\n",
    "    if r.extended is None:\n",
    "        continue\n",
    "    e = r.extended\n",
    "    ext_rows.append({\n",
    "        \"Strategy\": r.name,\n",
    "        \"Horizon\": r.horizon,\n",
    "        \"RMSE\": round(e.rmse, 6),\n",
    "        \"R2\": round(e.r_squared, 4),\n",
    "        \"Hit%\": round(e.hit_ratio * 100, 1),\n",
    "        \"Prec\": round(e.precision, 3),\n",
    "        \"Recall\": round(e.recall, 3),\n",
    "        \"F1\": round(e.f1, 3),\n",
    "        \"Cal.Slope\": round(e.calib_slope, 3),\n",
    "        \"Mkt.R2\": round(e.market_r2, 4),\n",
    "        \"Mkt.Dir%\": round(e.market_direction_accuracy * 100, 1),\n",
    "    })\n",
    "\n",
    "if ext_rows:\n",
    "    df_ext = pd.DataFrame(ext_rows)\n",
    "    print(\"Extended Metrics:\")\n",
    "    print(\"=\" * 120)\n",
    "    display(df_ext)\n",
    "else:\n",
    "    print(\"No extended metrics available.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Per-Stock R2 Summary\n",
    "r2_rows = []\n",
    "for r in results:\n",
    "    if r.extended is None:\n",
    "        continue\n",
    "    e = r.extended\n",
    "    r2_rows.append({\n",
    "        \"Strategy\": r.name,\n",
    "        \"Horizon\": r.horizon,\n",
    "        \"Mean R2\": round(e.mean_stock_r2, 4),\n",
    "        \"Median R2\": round(e.median_stock_r2, 4),\n",
    "        \"% Positive\": round(e.pct_r2_positive, 1),\n",
    "        \"% > 0.05\": round(e.pct_r2_above_005, 1),\n",
    "        \"N Stocks\": len(e.stock_r2_values),\n",
    "    })\n",
    "\n",
    "if r2_rows:\n",
    "    df_r2 = pd.DataFrame(r2_rows)\n",
    "    print(\"Per-Stock R2 Summary:\")\n",
    "    print(\"=\" * 90)\n",
    "    display(df_r2)\n",
    "else:\n",
    "    print(\"No per-stock R2 data available.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Backtest Results: Long-Only and Long-Short\n",
    "bt_rows = []\n",
    "for r in results:\n",
    "    if r.extended is None:\n",
    "        continue\n",
    "    e = r.extended\n",
    "    bt_rows.append({\n",
    "        \"Strategy\": r.name,\n",
    "        \"Horizon\": r.horizon,\n",
    "        \"L/O CAGR\": \"%.2f%%\" % (e.lo_cagr * 100),\n",
    "        \"L/O Sharpe\": round(e.lo_sharpe, 2),\n",
    "        \"L/O MaxDD\": \"%.2f%%\" % (e.lo_max_dd * 100),\n",
    "        \"L/S CAGR\": \"%.2f%%\" % (e.ls_cagr * 100),\n",
    "        \"L/S Sharpe\": round(e.ls_sharpe, 2),\n",
    "        \"L/S MaxDD\": \"%.2f%%\" % (e.ls_max_dd * 100),\n",
    "    })\n",
    "\n",
    "if bt_rows:\n",
    "    df_bt = pd.DataFrame(bt_rows)\n",
    "    print(\"Backtest Results (Long-Only and Long-Short 20/20):\")\n",
    "    print(\"=\" * 100)\n",
    "    display(df_bt)\n",
    "else:\n",
    "    print(\"No backtest data available.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Diebold-Mariano Test Matrix\n",
    "dm_results = BenchmarkEvaluator.compute_dm_tests(results)\n",
    "\n",
    "if dm_results:\n",
    "    # Display as table\n",
    "    dm_rows = []\n",
    "    for dm in dm_results:\n",
    "        dm_rows.append({\n",
    "            \"A\": dm.strategy_a.split(\"_\")[0],\n",
    "            \"B\": dm.strategy_b.split(\"_\")[0],\n",
    "            \"Horizon\": dm.horizon,\n",
    "            \"DM Stat\": round(dm.dm_stat, 2),\n",
    "            \"p-value\": round(dm.p_value, 4),\n",
    "            \"Better\": dm.better.split(\"_\")[0],\n",
    "            \"Sig?\": \"*\" if dm.p_value < 0.05 else (\".\" if dm.p_value < 0.10 else \"\"),\n",
    "        })\n",
    "    df_dm = pd.DataFrame(dm_rows)\n",
    "    print(\"Diebold-Mariano Tests (* = p<0.05, . = p<0.10):\")\n",
    "    print(\"=\" * 80)\n",
    "    display(df_dm)\n",
    "\n",
    "    # Heatmap per horizon\n",
    "    import matplotlib.pyplot as plt\n",
    "    horizons = sorted(set(dm.horizon for dm in dm_results))\n",
    "    fig_dm, axes_dm = plt.subplots(1, len(horizons), figsize=(8 * len(horizons), 6))\n",
    "    if len(horizons) == 1:\n",
    "        axes_dm = [axes_dm]\n",
    "\n",
    "    for ax, h in zip(axes_dm, horizons):\n",
    "        h_dm = [dm for dm in dm_results if dm.horizon == h]\n",
    "        names = sorted(set(\n",
    "            [dm.strategy_a.split(\"_\")[0] for dm in h_dm] +\n",
    "            [dm.strategy_b.split(\"_\")[0] for dm in h_dm]\n",
    "        ))\n",
    "        n = len(names)\n",
    "        pval_matrix = np.ones((n, n))\n",
    "        name_to_idx = {nm: i for i, nm in enumerate(names)}\n",
    "\n",
    "        for dm in h_dm:\n",
    "            ia = name_to_idx.get(dm.strategy_a.split(\"_\")[0])\n",
    "            ib = name_to_idx.get(dm.strategy_b.split(\"_\")[0])\n",
    "            if ia is not None and ib is not None:\n",
    "                pval_matrix[ia, ib] = dm.p_value\n",
    "                pval_matrix[ib, ia] = dm.p_value\n",
    "\n",
    "        im = ax.imshow(pval_matrix, cmap=\"RdYlGn\", vmin=0, vmax=0.2)\n",
    "        ax.set_xticks(range(n))\n",
    "        ax.set_xticklabels(names, rotation=45, fontsize=7, ha=\"right\")\n",
    "        ax.set_yticks(range(n))\n",
    "        ax.set_yticklabels(names, fontsize=7)\n",
    "        ax.set_title(\"DM p-values: %s\" % h, fontweight=\"bold\")\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    ax.text(j, i, \"%.2f\" % pval_matrix[i, j],\n",
    "                            ha=\"center\", va=\"center\", fontsize=6,\n",
    "                            color=\"white\" if pval_matrix[i, j] < 0.05 else \"black\")\n",
    "\n",
    "    plt.colorbar(im, ax=axes_dm[-1], shrink=0.7, label=\"p-value\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"dm_test_heatmap.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"DM test heatmap saved.\")\n",
    "else:\n",
    "    print(\"No DM test results (need fold predictions from multiple strategies).\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n\nfig = plt.figure(figsize=(20, 16))\ngs_layout = gridspec.GridSpec(2, 3, hspace=0.35, wspace=0.3)\n\n# --- Panel 1: IC Comparison Bar Chart ---\nax1 = fig.add_subplot(gs_layout[0, 0])\nlabels = [\"%s\\n%s\" % (r.name.split(\"_\", 1)[-1][:12], r.horizon) for r in results]\nics = [r.ic_mean for r in results]\ncolors = [\"#4CAF50\" if r.status == \"PASS\" else \"#FFC107\" if r.status == \"WARN\" else \"#F44336\"\n          for r in results]\nax1.barh(range(len(results)), ics, color=colors, edgecolor=\"white\")\nax1.set_yticks(range(len(results)))\nax1.set_yticklabels(labels, fontsize=7)\nax1.set_xlabel(\"Cross-Sectional IC\")\nax1.set_title(\"IC Comparison\", fontweight=\"bold\")\nax1.axvline(x=0, color=\"gray\", linewidth=0.5)\nax1.invert_yaxis()\n\n# --- Panel 2: IC Stability (fold ICs per strategy) ---\nax2 = fig.add_subplot(gs_layout[0, 1])\ncmap = plt.colormaps[\"tab20\"]\nfor i, r in enumerate(results):\n    if r.fold_metrics:\n        fold_ics = [f.ic for f in r.fold_metrics]\n        x_positions = [i] * len(fold_ics)\n        ax2.scatter(x_positions, fold_ics, color=cmap(i % 20), s=30, zorder=3, alpha=0.7)\n        ax2.plot([i, i], [min(fold_ics), max(fold_ics)],\n                 color=cmap(i % 20), linewidth=2, alpha=0.5)\nax2.set_xticks(range(len(results)))\nax2.set_xticklabels([r.name.split(\"_\")[0] + \"/\" + r.horizon for r in results],\n                     rotation=90, fontsize=6, ha=\"center\")\nax2.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\nax2.set_ylabel(\"IC per fold\")\nax2.set_title(\"IC Stability (per fold)\", fontweight=\"bold\")\nax2.grid(axis=\"y\", alpha=0.3)\n\n# --- Panel 3: Composite Score Bar ---\nax3 = fig.add_subplot(gs_layout[0, 2])\ncomposites = [r.composite if not math.isinf(r.composite) else 0 for r in results]\nax3.barh(range(len(results)), composites, color=colors, edgecolor=\"white\")\nax3.set_yticks(range(len(results)))\nax3.set_yticklabels(labels, fontsize=7)\nax3.set_xlabel(\"Composite Score\")\nax3.set_title(\"Composite Score\", fontweight=\"bold\")\nax3.axvline(x=0, color=\"gray\", linewidth=0.5)\nax3.invert_yaxis()\n\n# --- Panel 4: Gate Activation ---\nax4 = fig.add_subplot(gs_layout[1, 0])\ngate_data = [(r.name, r.horizon, r.gate_stats) for r in results if r.gate_stats]\nif gate_data:\n    g_labels = [\"%s/%s\" % (n, h) for n, h, _ in gate_data]\n    g_means = []\n    g_stds = []\n    for _, _, gstat in gate_data:\n        if isinstance(gstat, dict):\n            g_means.append(gstat.get(\"gate_mean\", 0))\n            g_stds.append(gstat.get(\"gate_std\", 0))\n        else:\n            g_means.append(0.5)\n            g_stds.append(0)\n    ax4.barh(g_labels, g_means, xerr=g_stds, color=\"#2196F3\", capsize=5)\n    ax4.set_xlabel(\"Gate Activation\")\n    ax4.set_title(\"Gate Distribution (Hybrid)\", fontweight=\"bold\")\n    ax4.set_xlim(0, 1)\nelse:\n    ax4.text(0.5, 0.5, \"No gate stats\\navailable\",\n             transform=ax4.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n    ax4.set_title(\"Gate Distribution\", fontweight=\"bold\")\n\n# --- Panel 5: Ensemble Weights ---\nax5 = fig.add_subplot(gs_layout[1, 1])\nens_data = [(r.name, r.horizon, r.ensemble_weights) for r in results if r.ensemble_weights]\nif ens_data:\n    for i, (name, horizon, w) in enumerate(ens_data):\n        x = [0, 1]\n        vals = [w.get(\"lstm\", 0), w.get(\"nlp\", 0)]\n        ax5.bar([v + i * 0.3 for v in x], vals, width=0.25,\n                label=\"%s/%s\" % (name.split(\"_\")[0], horizon))\n    ax5.set_xticks([0, 1])\n    ax5.set_xticklabels([\"LSTM weight\", \"NLP weight\"])\n    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n    ax5.legend(fontsize=8)\n    ax5.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\nelse:\n    ax5.text(0.5, 0.5, \"No ensemble weights\\navailable\",\n             transform=ax5.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n\n# --- Panel 6: Horizon Sensitivity ---\nax6 = fig.add_subplot(gs_layout[1, 2])\nstrategy_names = sorted(set(r.name for r in results))\nhorizon_labels = sorted(set(r.horizon for r in results))\nx_pos = np.arange(len(strategy_names))\nwidth = 0.8 / max(len(horizon_labels), 1)\n\nfor j, h in enumerate(horizon_labels):\n    h_ics = []\n    for sn in strategy_names:\n        match = [r for r in results if r.name == sn and r.horizon == h]\n        h_ics.append(match[0].ic_mean if match else 0)\n    offset = (j - len(horizon_labels) / 2 + 0.5) * width\n    ax6.bar(x_pos + offset, h_ics, width, label=h)\n\nax6.set_xticks(x_pos)\nax6.set_xticklabels([n.split(\"_\")[0] for n in strategy_names],\n                     rotation=45, fontsize=7, ha=\"right\")\nax6.set_ylabel(\"IC\")\nh_str = \" vs \".join(horizon_labels)\nax6.set_title(\"Horizon Sensitivity (%s)\" % h_str, fontweight=\"bold\")\nax6.legend(fontsize=8)\nax6.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\nax6.grid(axis=\"y\", alpha=0.3)\n\nfig.suptitle(\"Multi-Strategy Benchmark Dashboard (15 Models)\", fontsize=16, fontweight=\"bold\", y=1.01)\nplt.savefig(os.path.join(ARTIFACT_DIR, \"strategy_benchmark.png\"), dpi=150, bbox_inches=\"tight\")\nplt.show()\nprint(\"Dashboard saved.\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a. Extended Visualizations\n",
    "\n",
    "Five additional panels: Per-Stock R2 Histogram, Pred vs Actual Scatter, Calibration Slope, Rolling R2, Cumulative PnL."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Visualization 1: Per-Stock R2 Histogram ---\n",
    "ext_results = [r for r in results if r.extended and r.extended.stock_r2_values]\n",
    "n_ext = len(ext_results)\n",
    "\n",
    "if n_ext > 0:\n",
    "    ncols = min(5, n_ext)\n",
    "    nrows = (n_ext + ncols - 1) // ncols\n",
    "    fig_r2h, axes_r2h = plt.subplots(nrows, ncols, figsize=(4 * ncols, 3 * nrows))\n",
    "    if n_ext == 1:\n",
    "        axes_flat = [axes_r2h]\n",
    "    else:\n",
    "        axes_flat = axes_r2h.flatten() if hasattr(axes_r2h, 'flatten') else [axes_r2h]\n",
    "\n",
    "    for idx, r in enumerate(ext_results):\n",
    "        if idx >= len(axes_flat):\n",
    "            break\n",
    "        ax = axes_flat[idx]\n",
    "        vals = list(r.extended.stock_r2_values.values())\n",
    "        ax.hist(vals, bins=20, color=\"#2196F3\", edgecolor=\"white\", alpha=0.8)\n",
    "        ax.axvline(x=0, color=\"red\", linewidth=1, linestyle=\"--\")\n",
    "        ax.axvline(x=np.median(vals), color=\"green\", linewidth=1, linestyle=\"-\",\n",
    "                   label=\"median=%.3f\" % np.median(vals))\n",
    "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n",
    "        ax.set_xlabel(\"R2\", fontsize=8)\n",
    "        ax.legend(fontsize=6)\n",
    "\n",
    "    for idx in range(n_ext, len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "\n",
    "    fig_r2h.suptitle(\"Per-Stock R2 Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"per_stock_r2_histogram.png\"),\n",
    "                dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Per-stock R2 histogram saved.\")\n",
    "else:\n",
    "    print(\"No per-stock R2 data for visualization.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Visualization 2: Pred vs Actual Scatter ---\n",
    "scatter_results = [r for r in results if r.fold_predictions]\n",
    "\n",
    "if scatter_results:\n",
    "    n_sc = len(scatter_results)\n",
    "    ncols = min(5, n_sc)\n",
    "    nrows = (n_sc + ncols - 1) // ncols\n",
    "    fig_sc, axes_sc = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n",
    "    if n_sc == 1:\n",
    "        axes_flat = [axes_sc]\n",
    "    else:\n",
    "        axes_flat = axes_sc.flatten() if hasattr(axes_sc, 'flatten') else [axes_sc]\n",
    "\n",
    "    for idx, r in enumerate(scatter_results):\n",
    "        if idx >= len(axes_flat):\n",
    "            break\n",
    "        ax = axes_flat[idx]\n",
    "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n",
    "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n",
    "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n",
    "        p, a = all_p[valid], all_a[valid]\n",
    "\n",
    "        if len(p) > 5000:\n",
    "            idx_sub = np.random.choice(len(p), 5000, replace=False)\n",
    "            p_plot, a_plot = p[idx_sub], a[idx_sub]\n",
    "        else:\n",
    "            p_plot, a_plot = p, a\n",
    "\n",
    "        ax.scatter(p_plot, a_plot, alpha=0.1, s=3, color=\"#2196F3\")\n",
    "\n",
    "        if len(p) > 10:\n",
    "            coef = np.polyfit(p, a, 1)\n",
    "            x_line = np.linspace(p.min(), p.max(), 50)\n",
    "            ax.plot(x_line, coef[0] * x_line + coef[1], \"r-\", linewidth=1.5,\n",
    "                    label=\"slope=%.2f\" % coef[0])\n",
    "\n",
    "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n",
    "        ax.set_xlabel(\"Predicted\", fontsize=8)\n",
    "        ax.set_ylabel(\"Actual\", fontsize=8)\n",
    "        ax.legend(fontsize=7)\n",
    "\n",
    "    for idx in range(n_sc, len(axes_flat)):\n",
    "        axes_flat[idx].set_visible(False)\n",
    "\n",
    "    fig_sc.suptitle(\"Prediction vs Actual\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"pred_vs_actual_scatter.png\"),\n",
    "                dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Pred vs actual scatter saved.\")\n",
    "else:\n",
    "    print(\"No fold predictions for scatter plot.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Visualization 3: Calibration Slope Bar Chart ---\n",
    "cal_results = [r for r in results if r.extended is not None]\n",
    "\n",
    "if cal_results:\n",
    "    fig_cal, ax_cal = plt.subplots(figsize=(10, max(4, len(cal_results) * 0.4)))\n",
    "    labels_cal = [\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon) for r in cal_results]\n",
    "    slopes = [r.extended.calib_slope for r in cal_results]\n",
    "    colors_cal = [\"#4CAF50\" if abs(s - 1.0) < 0.3 else \"#FFC107\" if abs(s - 1.0) < 0.6\n",
    "                  else \"#F44336\" for s in slopes]\n",
    "\n",
    "    y_pos = range(len(cal_results))\n",
    "    ax_cal.barh(y_pos, slopes, color=colors_cal, edgecolor=\"white\")\n",
    "    ax_cal.set_yticks(y_pos)\n",
    "    ax_cal.set_yticklabels(labels_cal, fontsize=8)\n",
    "    ax_cal.axvline(x=1.0, color=\"blue\", linewidth=2, linestyle=\"--\", label=\"Ideal (slope=1.0)\")\n",
    "    ax_cal.set_xlabel(\"Calibration Slope\")\n",
    "    ax_cal.set_title(\"Calibration: Pred vs Actual Regression Slope\", fontweight=\"bold\")\n",
    "    ax_cal.legend(fontsize=9)\n",
    "    ax_cal.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"calibration_slope.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Calibration slope chart saved.\")\n",
    "else:\n",
    "    print(\"No calibration data for visualization.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Visualization 4: Rolling R2 (126-sample window) ---\n",
    "rolling_results = [r for r in results if r.fold_predictions]\n",
    "\n",
    "if rolling_results:\n",
    "    fig_roll, ax_roll = plt.subplots(figsize=(14, 6))\n",
    "    window = 126\n",
    "\n",
    "    for r in rolling_results:\n",
    "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n",
    "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n",
    "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n",
    "        p, a = all_p[valid], all_a[valid]\n",
    "\n",
    "        if len(p) < window + 10:\n",
    "            continue\n",
    "\n",
    "        rolling_r2 = []\n",
    "        for i in range(window, len(p)):\n",
    "            p_w = p[i - window:i]\n",
    "            a_w = a[i - window:i]\n",
    "            ss_res = np.sum((p_w - a_w) ** 2)\n",
    "            ss_tot = np.sum((a_w - np.mean(a_w)) ** 2)\n",
    "            r2 = 1.0 - ss_res / ss_tot if ss_tot > 1e-10 else 0.0\n",
    "            rolling_r2.append(r2)\n",
    "\n",
    "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n",
    "        ax_roll.plot(rolling_r2, label=label, alpha=0.7, linewidth=1)\n",
    "\n",
    "    ax_roll.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "    ax_roll.set_xlabel(\"Sample Index\")\n",
    "    ax_roll.set_ylabel(\"Rolling R2 (window=%d)\" % window)\n",
    "    ax_roll.set_title(\"Rolling R2 Across Walk-Forward Test Periods\", fontweight=\"bold\")\n",
    "    ax_roll.legend(fontsize=7, ncol=3, loc=\"upper right\")\n",
    "    ax_roll.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"rolling_r2.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Rolling R2 chart saved.\")\n",
    "else:\n",
    "    print(\"No fold predictions for rolling R2.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Visualization 5: Cumulative PnL Curves ---\n",
    "pnl_results = [r for r in results\n",
    "               if r.extended is not None\n",
    "               and r.extended.lo_equity is not None\n",
    "               and len(r.extended.lo_equity) > 1]\n",
    "\n",
    "if pnl_results:\n",
    "    fig_pnl, (ax_lo, ax_ls) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    for r in pnl_results:\n",
    "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n",
    "        ax_lo.plot(r.extended.lo_equity, label=label, alpha=0.7, linewidth=1)\n",
    "        if r.extended.ls_equity is not None and len(r.extended.ls_equity) > 1:\n",
    "            ax_ls.plot(r.extended.ls_equity, label=label, alpha=0.7, linewidth=1)\n",
    "\n",
    "    ax_lo.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "    ax_lo.set_xlabel(\"Trading Day\")\n",
    "    ax_lo.set_ylabel(\"Equity\")\n",
    "    ax_lo.set_title(\"Long-Only Cumulative PnL\", fontweight=\"bold\")\n",
    "    ax_lo.legend(fontsize=6, ncol=2)\n",
    "    ax_lo.grid(alpha=0.3)\n",
    "\n",
    "    ax_ls.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "    ax_ls.set_xlabel(\"Trading Day\")\n",
    "    ax_ls.set_ylabel(\"Equity\")\n",
    "    ax_ls.set_title(\"Long-Short (20/20) Cumulative PnL\", fontweight=\"bold\")\n",
    "    ax_ls.legend(fontsize=6, ncol=2)\n",
    "    ax_ls.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"cumulative_pnl.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Cumulative PnL curves saved.\")\n",
    "else:\n",
    "    print(\"No equity curve data for PnL visualization.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diagnostic Output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Save full benchmark results to JSON\n",
    "save_path = save_benchmark_results(\n",
    "    results,\n",
    "    path=os.path.join(ARTIFACT_DIR, \"strategy_benchmark_results.json\"),\n",
    ")\n",
    "print(\"Results saved to: %s\" % save_path)\n",
    "\n",
    "# Print per-strategy detail\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "for r in results:\n",
    "    print(\"\\n--- %s / %s [%s] ---\" % (r.name, r.horizon, r.status))\n",
    "    print(\"  IC: %.4f +/- %.4f  ICIR: %.2f\" % (r.ic_mean, r.ic_std, r.icir))\n",
    "    print(\"  Sharpe: %.2f  MaxDD: %.4f\" % (r.sharpe, r.max_drawdown))\n",
    "    print(\"  Overfit: %.3f  Composite: %.4f\" % (r.overfit_score, r.composite))\n",
    "    print(\"  Prod IC: %.4f  Params: %d  Time: %.1fs\" % (\n",
    "        r.prod_ic, r.param_count, r.train_time))\n",
    "    if r.fold_metrics:\n",
    "        fold_ics = [f.ic for f in r.fold_metrics]\n",
    "        print(\"  Fold ICs: %s\" % [round(x, 4) for x in fold_ics])\n",
    "    if r.extended:\n",
    "        e = r.extended\n",
    "        print(\"  R2: %.4f  Hit%%: %.1f%%  Cal.Slope: %.3f\" % (\n",
    "            e.r_squared, e.hit_ratio * 100, e.calib_slope))\n",
    "        print(\"  L/O Sharpe: %.2f  L/S Sharpe: %.2f\" % (e.lo_sharpe, e.ls_sharpe))\n",
    "    if r.gate_stats:\n",
    "        print(\"  Gate: mean=%.3f std=%.3f\" % (\n",
    "            r.gate_stats.get(\"gate_mean\", 0), r.gate_stats.get(\"gate_std\", 0)))\n",
    "    if r.ensemble_weights:\n",
    "        w = r.ensemble_weights\n",
    "        print(\"  Ensemble: lstm=%.3f nlp=%.3f intercept=%.4f\" % (\n",
    "            w.get(\"lstm\", 0), w.get(\"nlp\", 0), w.get(\"intercept\", 0)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experimental Integrity Checks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "warnings = run_integrity_checks(results)\n",
    "\n",
    "if warnings:\n",
    "    print(\"INTEGRITY WARNINGS (%d):\" % len(warnings))\n",
    "    for w in warnings:\n",
    "        print(\"  [!] %s\" % w)\n",
    "else:\n",
    "    print(\"All integrity checks passed.\")\n",
    "\n",
    "# Additional checks\n",
    "print(\"\\nConsistency Checks:\")\n",
    "\n",
    "for h in sorted(set(r.horizon for r in results)):\n",
    "    fold_counts = [len(r.fold_metrics) for r in results if r.horizon == h]\n",
    "    if len(set(fold_counts)) > 1:\n",
    "        print(\"  [!] Inconsistent fold counts at %s: %s\" % (h, fold_counts))\n",
    "    else:\n",
    "        print(\"  [OK] %s: %d folds for all strategies\" % (h, fold_counts[0] if fold_counts else 0))\n",
    "\n",
    "for r in results:\n",
    "    if r.param_count > CONFIG[\"max_params\"]:\n",
    "        print(\"  [!] %s: %d params > %d limit\" % (r.name, r.param_count, CONFIG[\"max_params\"]))\n",
    "\n",
    "print(\"\\nIntegrity check complete.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Decision\n",
    "\n",
    "This benchmark answers:\n",
    "\n",
    "1. **Does sentiment add incremental alpha?** Compare A vs C/E\n",
    "2. **Is hybrid destructive or additive?** Compare A vs E/E1/E2\n",
    "3. **Is ensemble safer than fusion?** Compare C vs E\n",
    "4. **Cross-attention vs additive fusion?** Compare E1 vs E2\n",
    "5. **Transformer vs LSTM?** Compare G vs A\n",
    "6. **Trees vs neural networks?** Compare H/I vs A\n",
    "7. **Which structure survives production retrain?** Check Prod IC column\n",
    "8. **Statistical significance?** DM test p-values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extended decision summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PRICE PREDICTION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Best by extended metrics\n",
    "ext_results_all = [r for r in results if r.extended is not None]\n",
    "if ext_results_all:\n",
    "    best_r2 = max(ext_results_all, key=lambda r: r.extended.mean_stock_r2)\n",
    "    print(\"\\nBest by Mean Stock R2: %s/%s (%.4f)\" % (\n",
    "        best_r2.name, best_r2.horizon, best_r2.extended.mean_stock_r2))\n",
    "\n",
    "    best_hit = max(ext_results_all, key=lambda r: r.extended.hit_ratio)\n",
    "    print(\"Best by Directional Accuracy: %s/%s (%.1f%%)\" % (\n",
    "        best_hit.name, best_hit.horizon, best_hit.extended.hit_ratio * 100))\n",
    "\n",
    "    best_cal = min(ext_results_all, key=lambda r: abs(r.extended.calib_slope - 1.0))\n",
    "    print(\"Best Calibration (slope closest to 1): %s/%s (%.3f)\" % (\n",
    "        best_cal.name, best_cal.horizon, best_cal.extended.calib_slope))\n",
    "\n",
    "    best_lo = max(ext_results_all, key=lambda r: r.extended.lo_sharpe)\n",
    "    print(\"Highest Sharpe (L/O): %s/%s (%.2f)\" % (\n",
    "        best_lo.name, best_lo.horizon, best_lo.extended.lo_sharpe))\n",
    "\n",
    "    best_ls = max(ext_results_all, key=lambda r: r.extended.ls_sharpe)\n",
    "    print(\"Highest Sharpe (L/S): %s/%s (%.2f)\" % (\n",
    "        best_ls.name, best_ls.horizon, best_ls.extended.ls_sharpe))\n",
    "\n",
    "# DM significance vs baseline\n",
    "if dm_results:\n",
    "    baseline_name = \"A_LSTM_Baseline\"\n",
    "    sig_improvements = [dm for dm in dm_results\n",
    "                        if dm.p_value < 0.05\n",
    "                        and (dm.strategy_a == baseline_name or dm.strategy_b == baseline_name)\n",
    "                        and dm.better != baseline_name]\n",
    "    if sig_improvements:\n",
    "        print(\"\\nDM test: significant improvements over baseline:\")\n",
    "        for dm in sig_improvements:\n",
    "            print(\"  %s beats %s at %s (p=%.4f)\" % (\n",
    "                dm.better, baseline_name, dm.horizon, dm.p_value))\n",
    "    else:\n",
    "        print(\"\\nDM test: no strategy significantly beats baseline (p<0.05)\")\n",
    "\n",
    "# Key comparisons\n",
    "print(\"\\n--- Key Comparisons ---\")\n",
    "\n",
    "# Sentiment alpha\n",
    "a_21 = [r for r in results if r.name.startswith(\"A_\") and r.horizon == \"21D\"]\n",
    "c_21 = [r for r in results if r.name.startswith(\"C_\") and r.horizon == \"21D\"]\n",
    "e_21 = [r for r in results if r.name.startswith(\"E_\") and r.horizon == \"21D\"]\n",
    "if a_21 and c_21:\n",
    "    delta = c_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"YES (+%.4f IC)\" % delta if delta > 0.005 else \"NO (delta=%.4f)\" % delta\n",
    "    print(\"1. Sentiment adds alpha? %s\" % verdict)\n",
    "\n",
    "# Hybrid vs baseline\n",
    "if a_21 and e_21:\n",
    "    delta = e_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"ADDITIVE (+%.4f)\" % delta if delta > 0 else \"DESTRUCTIVE (%.4f)\" % delta\n",
    "    print(\"2. Hybrid vs LSTM? %s\" % verdict)\n",
    "\n",
    "# Cross-attention vs additive\n",
    "e1_21 = [r for r in results if r.name.startswith(\"E1\") and r.horizon == \"21D\"]\n",
    "e2_21 = [r for r in results if r.name.startswith(\"E2\") and r.horizon == \"21D\"]\n",
    "if e1_21 and e2_21:\n",
    "    if e1_21[0].ic_mean > e2_21[0].ic_mean:\n",
    "        print(\"3. Cross-attn vs Additive? CROSS-ATTN (IC %.4f vs %.4f)\" % (\n",
    "            e1_21[0].ic_mean, e2_21[0].ic_mean))\n",
    "    else:\n",
    "        print(\"3. Cross-attn vs Additive? ADDITIVE (IC %.4f vs %.4f)\" % (\n",
    "            e2_21[0].ic_mean, e1_21[0].ic_mean))\n",
    "\n",
    "# Transformer vs LSTM\n",
    "g_21 = [r for r in results if r.name.startswith(\"G_\") and r.horizon == \"21D\"]\n",
    "if a_21 and g_21:\n",
    "    delta = g_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"TRANSFORMER (+%.4f)\" % delta if delta > 0 else \"LSTM (%.4f)\" % delta\n",
    "    print(\"4. Transformer vs LSTM? %s\" % verdict)\n",
    "\n",
    "# Trees vs neural\n",
    "h_21 = [r for r in results if r.name.startswith(\"H_\") and r.horizon == \"21D\"]\n",
    "i_21 = [r for r in results if r.name.startswith(\"I_\") and r.horizon == \"21D\"]\n",
    "if a_21 and h_21 and i_21:\n",
    "    best_tree = max([h_21[0], i_21[0]], key=lambda r: r.ic_mean)\n",
    "    delta = best_tree.ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"TREES (+%.4f)\" % delta if delta > 0 else \"NEURAL (%.4f)\" % delta\n",
    "    print(\"5. Trees vs Neural? %s (best tree: %s)\" % (verdict, best_tree.name))\n",
    "\n",
    "# Production survival\n",
    "print(\"\\n--- Production Survival ---\")\n",
    "for r in results:\n",
    "    if r.ic_mean > 0 and r.prod_ic > 0:\n",
    "        ratio = r.prod_ic / r.ic_mean if r.ic_mean > 1e-8 else 0\n",
    "        survived = \"SURVIVED\" if ratio >= 0.9 else \"DEGRADED\"\n",
    "        print(\"  %s/%s: WF IC=%.4f -> Prod IC=%.4f (%.0f%%) [%s]\" % (\n",
    "            r.name, r.horizon, r.ic_mean, r.prod_ic, ratio * 100, survived))\n",
    "\n",
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "passing = [r for r in results if r.status == \"PASS\"]\n",
    "if passing:\n",
    "    best = passing[0]\n",
    "    print(\"RECOMMENDATION: Deploy %s\" % best.name)\n",
    "    print(\"  Composite: %.4f  IC: %.4f  Prod IC: %.4f\" % (\n",
    "        best.composite, best.ic_mean, best.prod_ic))\n",
    "    if best.extended:\n",
    "        print(\"  R2: %.4f  Hit%%: %.1f%%  L/S Sharpe: %.2f\" % (\n",
    "            best.extended.r_squared, best.extended.hit_ratio * 100,\n",
    "            best.extended.ls_sharpe))\n",
    "else:\n",
    "    warning_results = [r for r in results if r.status == \"WARN\"]\n",
    "    if warning_results:\n",
    "        print(\"RECOMMENDATION: Cautiously deploy %s (WARN status)\" % warning_results[0].name)\n",
    "    else:\n",
    "        print(\"RECOMMENDATION: No viable strategy. Review data/features.\")\n",
    "print(\"=\" * 60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Per-Market Performance Analysis\n\nBreak down strategy performance by market (US vs KOSPI vs KOSDAQ) to identify\nmarket-specific alpha and cross-market generalization.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Per-market R2 breakdown using fold predictions\ndef _classify_market(ticker):\n    t = ticker.upper()\n    if t.endswith(\".KS\"):\n        return \"KOSPI\"\n    elif t.endswith(\".KQ\"):\n        return \"KOSDAQ\"\n    return \"US\"\n\nmarket_perf_rows = []\nfor r in results:\n    if r.extended is None or not r.extended.stock_r2_values:\n        continue\n    # Group stock R2 by market\n    market_r2s = {}\n    for ticker, r2_val in r.extended.stock_r2_values.items():\n        mkt = _classify_market(ticker)\n        if mkt not in market_r2s:\n            market_r2s[mkt] = []\n        market_r2s[mkt].append(r2_val)\n\n    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n        vals = market_r2s.get(mkt, [])\n        if not vals:\n            continue\n        market_perf_rows.append({\n            \"Strategy\": r.name.split(\"_\")[0],\n            \"Horizon\": r.horizon,\n            \"Market\": mkt,\n            \"N Stocks\": len(vals),\n            \"Mean R2\": round(np.mean(vals), 4),\n            \"Median R2\": round(np.median(vals), 4),\n            \"% Positive\": round(sum(1 for v in vals if v > 0) / len(vals) * 100, 1),\n        })\n\nif market_perf_rows:\n    df_mkt = pd.DataFrame(market_perf_rows)\n    print(\"=== Per-Market R2 Breakdown ===\")\n    print(\"=\" * 100)\n\n    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n        sub = df_mkt[df_mkt[\"Market\"] == mkt]\n        if sub.empty:\n            continue\n        print(\"\\n--- %s ---\" % mkt)\n        display(sub.drop(columns=[\"Market\"]).reset_index(drop=True))\n\n    # Best strategy per market\n    print(\"\\n=== Best Strategy per Market (by Mean R2) ===\")\n    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n        sub = df_mkt[df_mkt[\"Market\"] == mkt]\n        if sub.empty:\n            print(\"  %s: No data\" % mkt)\n            continue\n        best_idx = sub[\"Mean R2\"].idxmax()\n        best = sub.loc[best_idx]\n        print(\"  %s: %s/%s (Mean R2=%.4f, %d stocks)\" % (\n            mkt, best[\"Strategy\"], best[\"Horizon\"],\n            best[\"Mean R2\"], best[\"N Stocks\"]))\nelse:\n    print(\"No per-market data (need extended metrics with stock R2 values).\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Per-market R2 comparison visualization\nif market_perf_rows:\n    df_mkt = pd.DataFrame(market_perf_rows)\n    markets_present = [m for m in [\"US\", \"KOSPI\", \"KOSDAQ\"] if m in df_mkt[\"Market\"].values]\n    n_markets = len(markets_present)\n\n    if n_markets > 0:\n        fig_mkt, axes_mkt = plt.subplots(1, n_markets, figsize=(7 * n_markets, 6))\n        if n_markets == 1:\n            axes_mkt = [axes_mkt]\n\n        for ax, mkt in zip(axes_mkt, markets_present):\n            sub = df_mkt[df_mkt[\"Market\"] == mkt].copy()\n            sub[\"Label\"] = sub[\"Strategy\"] + \"/\" + sub[\"Horizon\"]\n            sub = sub.sort_values(\"Mean R2\", ascending=True)\n\n            colors_mkt = [\"#4CAF50\" if v > 0 else \"#F44336\" for v in sub[\"Mean R2\"]]\n            ax.barh(sub[\"Label\"], sub[\"Mean R2\"], color=colors_mkt, edgecolor=\"white\")\n            ax.axvline(x=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n            ax.set_xlabel(\"Mean Stock R2\")\n            ax.set_title(\"%s (%d stocks)\" % (mkt, sub[\"N Stocks\"].iloc[0]), fontweight=\"bold\")\n            ax.tick_params(axis=\"y\", labelsize=7)\n\n        plt.suptitle(\"Per-Market Strategy Performance\", fontsize=14, fontweight=\"bold\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(ARTIFACT_DIR, \"per_market_performance.png\"),\n                    dpi=150, bbox_inches=\"tight\")\n        plt.show()\n        print(\"Per-market performance chart saved.\")\n\n    # Cross-market generalization heatmap\n    pivot = df_mkt.pivot_table(\n        values=\"Mean R2\", index=[\"Strategy\", \"Horizon\"],\n        columns=\"Market\", aggfunc=\"first\")\n    if pivot.shape[1] >= 2:\n        fig_gen, ax_gen = plt.subplots(figsize=(8, max(4, len(pivot) * 0.35)))\n        im = ax_gen.imshow(pivot.values, cmap=\"RdYlGn\", aspect=\"auto\",\n                           vmin=-0.05, vmax=0.1)\n        ax_gen.set_xticks(range(pivot.shape[1]))\n        ax_gen.set_xticklabels(pivot.columns, fontsize=10)\n        ax_gen.set_yticks(range(pivot.shape[0]))\n        ylabels = [\"%s/%s\" % (s, h) for s, h in pivot.index]\n        ax_gen.set_yticklabels(ylabels, fontsize=7)\n        ax_gen.set_title(\"Cross-Market Generalization (Mean Stock R2)\", fontweight=\"bold\")\n\n        for i in range(pivot.shape[0]):\n            for j in range(pivot.shape[1]):\n                val = pivot.values[i, j]\n                if not np.isnan(val):\n                    ax_gen.text(j, i, \"%.3f\" % val, ha=\"center\", va=\"center\",\n                                fontsize=7, color=\"white\" if val > 0.05 else \"black\")\n\n        plt.colorbar(im, ax=ax_gen, shrink=0.7, label=\"Mean R2\")\n        plt.tight_layout()\n        plt.savefig(os.path.join(ARTIFACT_DIR, \"cross_market_heatmap.png\"),\n                    dpi=150, bbox_inches=\"tight\")\n        plt.show()\n        print(\"Cross-market heatmap saved.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}