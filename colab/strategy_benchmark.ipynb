{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Strategy Benchmark\n",
    "\n",
    "Compare **7 alpha extraction strategies** under identical walk-forward conditions.\n",
    "\n",
    "| Strategy | Description |\n",
    "|----------|-------------|\n",
    "| A | LSTM Baseline (price-only temporal) |\n",
    "| B | NLP Only (sentiment MLP) |\n",
    "| C | Late Ensemble (A + B with ridge) |\n",
    "| D | Residual Sentiment (market-residualized NLP) |\n",
    "| E | Gated Hybrid (gated price-NLP fusion) |\n",
    "| F | Cross-Sectional Attention LSTM |\n",
    "| G | Short Horizon NLP (5D only) |\n",
    "\n",
    "**Goal:** Determine which structure produces real, production-surviving alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q yfinance lightgbm torch optuna pyarrow scikit-learn scipy pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content\")\n",
    "!rm -rf AI-stock-investment-tool\n",
    "\n",
    "REPO = \"https://github.com/kevin6598/AI-stock-investment-tool.git\"\n",
    "ret = os.system(\"git clone %s 2>/dev/null\" % REPO)\n",
    "if ret != 0:\n",
    "    from getpass import getpass\n",
    "    token = getpass(\"GitHub token (repo scope): \")\n",
    "    os.system(\"git clone https://%s@github.com/kevin6598/AI-stock-investment-tool.git\" % token)\n",
    "    del token\n",
    "\n",
    "os.chdir(\"/content/AI-stock-investment-tool\")\n",
    "!git log --oneline -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\n",
    "print(\"Python: %s\" % sys.version)\n",
    "print(\"PyTorch: %s\" % torch.__version__)\n",
    "print(\"CUDA: %s\" % torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU: %s\" % torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global Configuration\n",
    "\n",
    "Single config block. All strategies respect these constraints.\n",
    "No model-specific unfair tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "CONFIG = {\n    \"horizons\": [5, 21],\n    \"walk_forward\": {\n        \"train_years\": 2,\n        \"test_months\": 4,\n        \"step_months\": 4,\n        \"val_months\": 2,\n        \"embargo_days\": 5,\n    },\n    \"max_epochs\": 15,\n    \"early_stop_patience\": 3,\n    \"ranking_weight\": 0.5,\n    \"max_params\": 1_500_000,\n}\n\nprint(\"Horizons: %s\" % CONFIG[\"horizons\"])\nprint(\"Walk-forward: %s\" % CONFIG[\"walk_forward\"])\nprint(\"Max epochs: %d\" % CONFIG[\"max_epochs\"])\nprint(\"Max params: %d\" % CONFIG[\"max_params\"])\n\n# Data span check (will be computed after loading data)\n# With train=24mo + val=2mo + test=4mo + embargo ~= 30mo minimum\n# Dataset ~42 months -> expect ~3-4 folds with step=4mo"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardized Data Pipeline\n",
    "\n",
    "All strategies use the SAME processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_DIR = \"/content/drive/MyDrive/ai_stock_tool\"\n",
    "DATA_PATH = os.path.join(DRIVE_DIR, \"dataset.parquet\")\n",
    "ARTIFACT_DIR = os.path.join(DRIVE_DIR, \"artifacts\")\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "print(\"Data: %s\" % DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\npanel = pd.read_parquet(DATA_PATH)\nvalid_tickers = panel.index.get_level_values(1).unique().tolist()\nprint(\"Panel: %s\" % str(panel.shape))\nprint(\"Tickers: %d\" % len(valid_tickers))\n\ndate_min = panel.index.get_level_values(0).min()\ndate_max = panel.index.get_level_values(0).max()\ndata_span_months = (date_max - date_min).days / 30.44\nprint(\"Date range: %s to %s (%.0f months)\" % (\n    date_min.date(), date_max.date(), data_span_months))\n\n# Estimate fold count\nwf = CONFIG[\"walk_forward\"]\ntrain_months = wf[\"train_years\"] * 12\nval_months = wf.get(\"val_months\", 3)\ntest_months = wf[\"test_months\"]\nstep_months = wf[\"step_months\"]\nmin_needed = train_months + val_months + test_months + 1\navailable_after_first = data_span_months - min_needed\nest_folds = max(0, 1 + int(available_after_first / step_months))\nprint(\"\\nFold estimate: train=%dmo + val=%dmo + test=%dmo = %dmo min\" % (\n    train_months, val_months, test_months, min_needed))\nprint(\"Expected folds: ~%d (with step=%dmo)\" % (est_folds, step_months))\nif est_folds == 0:\n    print(\"WARNING: No folds possible! Reduce train_years or test_months.\")\n\n# Feature columns (same for ALL strategies)\nfeature_cols = [\n    c for c in panel.columns\n    if not c.startswith(\"fwd_return_\")\n    and not c.startswith(\"residual_return_\")\n    and not c.startswith(\"ranked_target_\")\n    and c not in (\"_close\", \"ticker_id\")\n]\n\nprice_cols = [c for c in feature_cols if not c.startswith(\"nlp_\")]\nnlp_cols = [c for c in feature_cols if c.startswith(\"nlp_\")]\nprint(\"\\nFeatures: %d total (%d price, %d NLP)\" % (\n    len(feature_cols), len(price_cols), len(nlp_cols)))\n\n# Check required targets\nfor h in CONFIG[\"horizons\"]:\n    tc = \"fwd_return_%dd\" % h\n    if tc in panel.columns:\n        non_null = panel[tc].notna().sum()\n        print(\"  %s: %d non-null\" % (tc, non_null))\n    else:\n        print(\"  WARNING: %s not found!\" % tc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute derived features for all strategies\n",
    "\n",
    "# Sentiment residual (for Strategy D)\n",
    "market_feat = None\n",
    "for cand in [\"market_return\", \"market_return_21d\", \"spy_return_21d\"]:\n",
    "    if cand in panel.columns:\n",
    "        market_feat = cand\n",
    "        break\n",
    "\n",
    "if market_feat:\n",
    "    print(\"Market return feature: %s\" % market_feat)\n",
    "else:\n",
    "    print(\"WARNING: No market return feature found for residualization\")\n",
    "\n",
    "# Volatility proxy\n",
    "vol_feat = None\n",
    "for cand in [\"volatility_21d\", \"realized_vol_21d\", \"atr_pct\"]:\n",
    "    if cand in panel.columns:\n",
    "        vol_feat = cand\n",
    "        break\n",
    "\n",
    "if vol_feat:\n",
    "    print(\"Volatility feature: %s\" % vol_feat)\n",
    "else:\n",
    "    print(\"WARNING: No volatility feature found\")\n",
    "\n",
    "# Data quality check\n",
    "nan_pct = panel[feature_cols].isna().mean().mean() * 100\n",
    "print(\"\\nNaN rate: %.2f%%\" % nan_pct)\n",
    "print(\"Data pipeline ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Strategy Definitions\n",
    "\n",
    "All 7 strategies with identical interface: `train()`, `predict()`, `num_parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.strategy_benchmark import (\n",
    "    BenchmarkConfig, BenchmarkEvaluator, STRATEGY_REGISTRY,\n",
    "    save_benchmark_results, run_integrity_checks,\n",
    ")\n",
    "\n",
    "config = BenchmarkConfig.from_dict(CONFIG)\n",
    "\n",
    "# List all strategies\n",
    "print(\"Strategies to benchmark:\")\n",
    "print(\"-\" * 40)\n",
    "for key, cls in sorted(STRATEGY_REGISTRY.items()):\n",
    "    sh = getattr(cls, 'supported_horizons', None)\n",
    "    h_info = \"all horizons\" if sh is None else \"%s only\" % sh\n",
    "    print(\"  %s: %s (%s)\" % (key, cls.name, h_info))\n",
    "\n",
    "# Verify param counts (dry-run instantiation)\n",
    "print(\"\\nParam count check (instantiation only):\")\n",
    "for key, cls in sorted(STRATEGY_REGISTRY.items()):\n",
    "    s = cls()\n",
    "    print(\"  %s: OK\" % cls.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Benchmark\n",
    "\n",
    "Walk-forward evaluation for every strategy at every horizon.\n",
    "\n",
    "Expected runtime: ~15-30 min on T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "\n",
    "evaluator = BenchmarkEvaluator(panel, feature_cols, config)\n",
    "\n",
    "strategy_classes = list(STRATEGY_REGISTRY.values())\n",
    "print(\"Running %d strategies x %d horizons...\" % (\n",
    "    len(strategy_classes), len(config.horizons)))\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "results = evaluator.run_all(strategy_classes)\n",
    "total_time = time.time() - t0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Benchmark complete in %.1f min\" % (total_time / 60))\n",
    "print(\"Total evaluations: %d\" % len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strategy Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Build comparison table\n",
    "rows = []\n",
    "for r in results:\n",
    "    rows.append({\n",
    "        \"Strategy\": r.name,\n",
    "        \"Horizon\": r.horizon,\n",
    "        \"IC\": round(r.ic_mean, 4),\n",
    "        \"ICIR\": round(r.icir, 2),\n",
    "        \"Sharpe\": round(r.sharpe, 2),\n",
    "        \"IC_std\": round(r.ic_std, 4),\n",
    "        \"Prod IC\": round(r.prod_ic, 4),\n",
    "        \"Overfit\": round(r.overfit_score, 3),\n",
    "        \"Composite\": round(r.composite, 4),\n",
    "        \"Params\": r.param_count,\n",
    "        \"Time(s)\": round(r.train_time, 1),\n",
    "        \"Status\": r.status,\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "print(\"\\nStrategy Benchmark Results (sorted by Composite):\")\n",
    "print(\"=\" * 100)\n",
    "display(df_results)\n",
    "\n",
    "# Summary by status\n",
    "print(\"\\nStatus Summary:\")\n",
    "for status in [\"PASS\", \"WARN\", \"FAIL\"]:\n",
    "    count = sum(1 for r in results if r.status == status)\n",
    "    names = [r.name + \"/\" + r.horizon for r in results if r.status == status]\n",
    "    print(\"  %s (%d): %s\" % (status, count, \", \".join(names) if names else \"none\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = gridspec.GridSpec(2, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# --- Panel 1: IC Comparison Bar Chart ---\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "labels = [\"%s\\n%s\" % (r.name.split(\"_\", 1)[-1][:12], r.horizon) for r in results]\n",
    "ics = [r.ic_mean for r in results]\n",
    "colors = [\"#4CAF50\" if r.status == \"PASS\" else \"#FFC107\" if r.status == \"WARN\" else \"#F44336\"\n",
    "          for r in results]\n",
    "ax1.barh(range(len(results)), ics, color=colors, edgecolor=\"white\")\n",
    "ax1.set_yticks(range(len(results)))\n",
    "ax1.set_yticklabels(labels, fontsize=8)\n",
    "ax1.set_xlabel(\"Cross-Sectional IC\")\n",
    "ax1.set_title(\"IC Comparison\", fontweight=\"bold\")\n",
    "ax1.axvline(x=0, color=\"gray\", linewidth=0.5)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# --- Panel 2: IC Stability (fold ICs per strategy) ---\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "cmap = plt.cm.get_cmap(\"tab10\")\n",
    "for i, r in enumerate(results):\n",
    "    if r.fold_metrics:\n",
    "        fold_ics = [f.ic for f in r.fold_metrics]\n",
    "        x_positions = [i] * len(fold_ics)\n",
    "        ax2.scatter(x_positions, fold_ics, color=cmap(i % 10), s=40, zorder=3, alpha=0.7)\n",
    "        ax2.plot([i, i], [min(fold_ics), max(fold_ics)],\n",
    "                 color=cmap(i % 10), linewidth=2, alpha=0.5)\n",
    "ax2.set_xticks(range(len(results)))\n",
    "ax2.set_xticklabels([r.name.split(\"_\")[0] + \"/\" + r.horizon for r in results],\n",
    "                     rotation=45, fontsize=7, ha=\"right\")\n",
    "ax2.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "ax2.set_ylabel(\"IC per fold\")\n",
    "ax2.set_title(\"IC Stability (per fold)\", fontweight=\"bold\")\n",
    "ax2.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "# --- Panel 3: Composite Score Bar ---\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "composites = [r.composite if not math.isinf(r.composite) else 0 for r in results]\n",
    "ax3.barh(range(len(results)), composites, color=colors, edgecolor=\"white\")\n",
    "ax3.set_yticks(range(len(results)))\n",
    "ax3.set_yticklabels(labels, fontsize=8)\n",
    "ax3.set_xlabel(\"Composite Score\")\n",
    "ax3.set_title(\"Composite Score\", fontweight=\"bold\")\n",
    "ax3.axvline(x=0, color=\"gray\", linewidth=0.5)\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# --- Panel 4: Gate Activation (Strategy E only) ---\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "gate_data = [(r.name, r.horizon, r.gate_stats) for r in results if r.gate_stats]\n",
    "if gate_data:\n",
    "    g_labels = [\"%s/%s\" % (n, h) for n, h, _ in gate_data]\n",
    "    g_means = [gs.get(\"gate_mean\", 0) for _, _, gs in gate_data]\n",
    "    g_stds = [gs.get(\"gate_std\", 0) for _, _, gs in gate_data]\n",
    "    ax4.barh(g_labels, g_means, xerr=g_stds, color=\"#2196F3\", capsize=5)\n",
    "    ax4.set_xlabel(\"Gate Activation\")\n",
    "    ax4.set_title(\"Gate Distribution (Hybrid)\", fontweight=\"bold\")\n",
    "    ax4.set_xlim(0, 1)\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, \"No gate stats\\navailable\",\n",
    "             transform=ax4.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n",
    "    ax4.set_title(\"Gate Distribution\", fontweight=\"bold\")\n",
    "\n",
    "# --- Panel 5: Ensemble Weights (Strategy C only) ---\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "ens_data = [(r.name, r.horizon, r.ensemble_weights) for r in results if r.ensemble_weights]\n",
    "if ens_data:\n",
    "    for i, (name, horizon, w) in enumerate(ens_data):\n",
    "        x = [0, 1]\n",
    "        vals = [w.get(\"lstm\", 0), w.get(\"nlp\", 0)]\n",
    "        ax5.bar([v + i * 0.3 for v in x], vals, width=0.25,\n",
    "                label=\"%s/%s\" % (name.split(\"_\")[0], horizon))\n",
    "    ax5.set_xticks([0, 1])\n",
    "    ax5.set_xticklabels([\"LSTM weight\", \"NLP weight\"])\n",
    "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n",
    "    ax5.legend(fontsize=8)\n",
    "    ax5.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "else:\n",
    "    ax5.text(0.5, 0.5, \"No ensemble weights\\navailable\",\n",
    "             transform=ax5.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n",
    "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n",
    "\n",
    "# --- Panel 6: Horizon Sensitivity ---\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "strategy_names = sorted(set(r.name for r in results))\n",
    "horizon_labels = sorted(set(r.horizon for r in results))\n",
    "x_pos = np.arange(len(strategy_names))\n",
    "width = 0.35\n",
    "\n",
    "for j, h in enumerate(horizon_labels):\n",
    "    h_ics = []\n",
    "    for sn in strategy_names:\n",
    "        match = [r for r in results if r.name == sn and r.horizon == h]\n",
    "        h_ics.append(match[0].ic_mean if match else 0)\n",
    "    offset = (j - len(horizon_labels) / 2 + 0.5) * width\n",
    "    ax6.bar(x_pos + offset, h_ics, width, label=h)\n",
    "\n",
    "ax6.set_xticks(x_pos)\n",
    "ax6.set_xticklabels([n.split(\"_\")[0] for n in strategy_names],\n",
    "                     rotation=45, fontsize=8, ha=\"right\")\n",
    "ax6.set_ylabel(\"IC\")\n",
    "ax6.set_title(\"Horizon Sensitivity (5D vs 21D)\", fontweight=\"bold\")\n",
    "ax6.legend(fontsize=9)\n",
    "ax6.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "ax6.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "fig.suptitle(\"Multi-Strategy Benchmark Dashboard\", fontsize=16, fontweight=\"bold\", y=1.01)\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"strategy_benchmark.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Dashboard saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Diagnostic Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full benchmark results to JSON\n",
    "save_path = save_benchmark_results(\n",
    "    results,\n",
    "    path=os.path.join(ARTIFACT_DIR, \"strategy_benchmark_results.json\"),\n",
    ")\n",
    "print(\"Results saved to: %s\" % save_path)\n",
    "\n",
    "# Print per-strategy detail\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "for r in results:\n",
    "    print(\"\\n--- %s / %s [%s] ---\" % (r.name, r.horizon, r.status))\n",
    "    print(\"  IC: %.4f +/- %.4f  ICIR: %.2f\" % (r.ic_mean, r.ic_std, r.icir))\n",
    "    print(\"  Sharpe: %.2f  MaxDD: %.4f\" % (r.sharpe, r.max_drawdown))\n",
    "    print(\"  Overfit: %.3f  Composite: %.4f\" % (r.overfit_score, r.composite))\n",
    "    print(\"  Prod IC: %.4f  Params: %d  Time: %.1fs\" % (\n",
    "        r.prod_ic, r.param_count, r.train_time))\n",
    "    if r.fold_metrics:\n",
    "        fold_ics = [f.ic for f in r.fold_metrics]\n",
    "        print(\"  Fold ICs: %s\" % [round(x, 4) for x in fold_ics])\n",
    "    if r.gate_stats:\n",
    "        print(\"  Gate: mean=%.3f std=%.3f\" % (\n",
    "            r.gate_stats.get(\"gate_mean\", 0), r.gate_stats.get(\"gate_std\", 0)))\n",
    "    if r.ensemble_weights:\n",
    "        w = r.ensemble_weights\n",
    "        print(\"  Ensemble: lstm=%.3f nlp=%.3f intercept=%.4f\" % (\n",
    "            w.get(\"lstm\", 0), w.get(\"nlp\", 0), w.get(\"intercept\", 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Experimental Integrity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings = run_integrity_checks(results)\n",
    "\n",
    "if warnings:\n",
    "    print(\"INTEGRITY WARNINGS (%d):\" % len(warnings))\n",
    "    for w in warnings:\n",
    "        print(\"  [!] %s\" % w)\n",
    "else:\n",
    "    print(\"All integrity checks passed.\")\n",
    "\n",
    "# Additional checks\n",
    "print(\"\\nConsistency Checks:\")\n",
    "\n",
    "# Same number of folds across strategies at same horizon\n",
    "for h in sorted(set(r.horizon for r in results)):\n",
    "    fold_counts = [len(r.fold_metrics) for r in results if r.horizon == h]\n",
    "    if len(set(fold_counts)) > 1:\n",
    "        print(\"  [!] Inconsistent fold counts at %s: %s\" % (h, fold_counts))\n",
    "    else:\n",
    "        print(\"  [OK] %s: %d folds for all strategies\" % (h, fold_counts[0] if fold_counts else 0))\n",
    "\n",
    "# Param limit check\n",
    "for r in results:\n",
    "    if r.param_count > CONFIG[\"max_params\"]:\n",
    "        print(\"  [!] %s: %d params > %d limit\" % (r.name, r.param_count, CONFIG[\"max_params\"]))\n",
    "\n",
    "print(\"\\nIntegrity check complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Decision\n",
    "\n",
    "This benchmark answers:\n",
    "\n",
    "1. **Does sentiment add incremental alpha?** Compare A vs C/E\n",
    "2. **Is hybrid destructive or additive?** Compare A vs E\n",
    "3. **Is ensemble safer than fusion?** Compare C vs E\n",
    "4. **Is NLP short-horizon only?** Compare G/5D vs B/21D\n",
    "5. **Is cross-sectional modeling necessary?** Compare A vs F\n",
    "6. **Which structure survives production retrain?** Check Prod IC column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated decision summary\n",
    "print(\"=\" * 60)\n",
    "print(\"DECISION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Best overall\n",
    "passing = [r for r in results if r.status == \"PASS\"]\n",
    "if passing:\n",
    "    best = passing[0]  # already sorted by composite\n",
    "    print(\"\\nBest PASS strategy: %s/%s\" % (best.name, best.horizon))\n",
    "    print(\"  Composite: %.4f  IC: %.4f  Prod IC: %.4f\" % (\n",
    "        best.composite, best.ic_mean, best.prod_ic))\n",
    "else:\n",
    "    print(\"\\nNo strategy achieved PASS status.\")\n",
    "    warning_results = [r for r in results if r.status == \"WARN\"]\n",
    "    if warning_results:\n",
    "        best = warning_results[0]\n",
    "        print(\"Best WARN strategy: %s/%s\" % (best.name, best.horizon))\n",
    "        print(\"  Composite: %.4f  IC: %.4f\" % (best.composite, best.ic_mean))\n",
    "\n",
    "# Key questions\n",
    "print(\"\\n--- Key Questions ---\")\n",
    "\n",
    "# 1. Sentiment alpha\n",
    "a_21 = [r for r in results if r.name.startswith(\"A_\") and r.horizon == \"21D\"]\n",
    "c_21 = [r for r in results if r.name.startswith(\"C_\") and r.horizon == \"21D\"]\n",
    "if a_21 and c_21:\n",
    "    delta = c_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"YES (+%.4f IC)\" % delta if delta > 0.005 else \"NO (delta=%.4f)\" % delta\n",
    "    print(\"1. Sentiment adds alpha? %s\" % verdict)\n",
    "\n",
    "# 2. Hybrid vs baseline\n",
    "e_21 = [r for r in results if r.name.startswith(\"E_\") and r.horizon == \"21D\"]\n",
    "if a_21 and e_21:\n",
    "    delta = e_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"ADDITIVE (+%.4f)\" % delta if delta > 0 else \"DESTRUCTIVE (%.4f)\" % delta\n",
    "    print(\"2. Hybrid vs LSTM? %s\" % verdict)\n",
    "\n",
    "# 3. Ensemble vs fusion\n",
    "if c_21 and e_21:\n",
    "    if c_21[0].ic_mean > e_21[0].ic_mean:\n",
    "        print(\"3. Ensemble vs Fusion? ENSEMBLE safer (IC %.4f vs %.4f)\" % (\n",
    "            c_21[0].ic_mean, e_21[0].ic_mean))\n",
    "    else:\n",
    "        print(\"3. Ensemble vs Fusion? FUSION better (IC %.4f vs %.4f)\" % (\n",
    "            e_21[0].ic_mean, c_21[0].ic_mean))\n",
    "\n",
    "# 4. Short horizon NLP\n",
    "b_5 = [r for r in results if r.name.startswith(\"B_\") and r.horizon == \"5D\"]\n",
    "b_21 = [r for r in results if r.name.startswith(\"B_\") and r.horizon == \"21D\"]\n",
    "g_5 = [r for r in results if r.name.startswith(\"G_\") and r.horizon == \"5D\"]\n",
    "if b_5 and b_21:\n",
    "    if b_5[0].ic_mean > b_21[0].ic_mean + 0.005:\n",
    "        print(\"4. NLP short-horizon only? YES (5D IC=%.4f > 21D IC=%.4f)\" % (\n",
    "            b_5[0].ic_mean, b_21[0].ic_mean))\n",
    "    else:\n",
    "        print(\"4. NLP short-horizon only? NO (5D IC=%.4f, 21D IC=%.4f)\" % (\n",
    "            b_5[0].ic_mean, b_21[0].ic_mean))\n",
    "\n",
    "# 5. Cross-sectional attention\n",
    "f_21 = [r for r in results if r.name.startswith(\"F_\") and r.horizon == \"21D\"]\n",
    "if a_21 and f_21:\n",
    "    delta = f_21[0].ic_mean - a_21[0].ic_mean\n",
    "    verdict = \"YES (+%.4f)\" % delta if delta > 0.005 else \"NO (delta=%.4f)\" % delta\n",
    "    print(\"5. Cross-sectional attention helps? %s\" % verdict)\n",
    "\n",
    "# 6. Production survival\n",
    "print(\"\\n--- Production Survival ---\")\n",
    "for r in results:\n",
    "    if r.ic_mean > 0 and r.prod_ic > 0:\n",
    "        ratio = r.prod_ic / r.ic_mean if r.ic_mean > 1e-8 else 0\n",
    "        survived = \"SURVIVED\" if ratio >= 0.9 else \"DEGRADED\"\n",
    "        print(\"  %s/%s: WF IC=%.4f -> Prod IC=%.4f (%.0f%%) [%s]\" % (\n",
    "            r.name, r.horizon, r.ic_mean, r.prod_ic, ratio * 100, survived))\n",
    "\n",
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if passing:\n",
    "    print(\"RECOMMENDATION: Deploy %s\" % best.name)\n",
    "elif warning_results:\n",
    "    print(\"RECOMMENDATION: Cautiously deploy %s (WARN status)\" % warning_results[0].name)\n",
    "else:\n",
    "    print(\"RECOMMENDATION: No viable strategy. Review data/features.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}