{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIHAqYsnsBVE"
      },
      "source": [
        "f# Multi-Strategy Benchmark (Extended)\n",
        "\n",
        "Compare **15 alpha extraction strategies** under identical walk-forward conditions.\n",
        "\n",
        "| ID | Strategy | Architecture |\n",
        "|----|----------|-------------|\n",
        "| A | LSTM Baseline | Price-only temporal LSTM |\n",
        "| B | NLP Only | Sentiment MLP |\n",
        "| C | Late Ensemble | A + B with ridge meta |\n",
        "| D | Residual Sentiment | Market-residualized NLP |\n",
        "| E | Gated Hybrid | Gated price-NLP fusion |\n",
        "| E1 | Attention Hybrid | Cross-attention price/NLP |\n",
        "| E2 | Additive Residual | T + alpha*S fusion |\n",
        "| F | CS-Attention LSTM | Temporal + stock attention |\n",
        "| F1 | Temporal Fusion | Simplified TFT |\n",
        "| G | Transformer | Encoder-only transformer |\n",
        "| G1 | Efficient Transformer | Linear attention O(n*d) |\n",
        "| H | Random Forest | sklearn RF (no torch) |\n",
        "| I | LightGBM | Gradient boosted trees (no torch) |\n",
        "| J | Short Horizon NLP | NLP MLP 5D only |\n",
        "| K | Short Horizon Hybrid | Gated hybrid 5D only |\n",
        "\n",
        "**Evaluation:** IC, Sharpe, R2, per-stock R2, directional accuracy, calibration, market-level prediction, backtest PnL, DM statistical tests.\n",
        "\n",
        "**Goal:** Determine which structure produces real, production-surviving alpha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPIu613_sBVF"
      },
      "source": [
        "!pip install -q yfinance lightgbm torch optuna pyarrow scikit-learn scipy pandas numpy matplotlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poi3Y1rksBVF",
        "outputId": "b5e6fd6b-fa49-4548-9c92-73b4a5453291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content\")\n",
        "!rm -rf AI-stock-investment-tool\n",
        "\n",
        "REPO = \"https://github.com/kevin6598/AI-stock-investment-tool.git\"\n",
        "ret = os.system(\"git clone %s 2>/dev/null\" % REPO)\n",
        "if ret != 0:\n",
        "    from getpass import getpass\n",
        "    token = getpass(\"GitHub token (repo scope): \")\n",
        "    os.system(\"git clone https://%s@github.com/kevin6598/AI-stock-investment-tool.git\" % token)\n",
        "    del token\n",
        "\n",
        "os.chdir(\"/content/AI-stock-investment-tool\")\n",
        "!git log --oneline -3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m899e4a5\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD -> \u001b[m\u001b[1;32mmaster\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/master\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/HEAD\u001b[m\u001b[33m)\u001b[m Add checkpoint/resume support to benchmark for runtime timeout recovery\n",
            "\u001b[33m2434132\u001b[m Optimize benchmark performance: remove train inference, vectorize sequences, reduce epochs\n",
            "\u001b[33m0138e4a\u001b[m Add real-time progress display to benchmark run_all and run_walk_forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2CCu28RsBVF",
        "outputId": "327c56e8-1f32-4566-e177-20128954b4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch, sys\n",
        "print(\"Python: %s\" % sys.version)\n",
        "print(\"PyTorch: %s\" % torch.__version__)\n",
        "print(\"CUDA: %s\" % torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU: %s\" % torch.cuda.get_device_name(0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PyTorch: 2.9.0+cu128\n",
            "CUDA: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDFDTi7RsBVG"
      },
      "source": [
        "## 1. Dataset & Benchmark Configuration\n",
        "\n",
        "**Dataset presets** -- choose universe size, market, and data period.\n",
        "Walk-forward parameters auto-adjust based on data period length.\n",
        "\n",
        "| Preset | Universe | Tickers | Best for |\n",
        "|--------|----------|---------|----------|\n",
        "| default | S&P subset + KOSPI/KOSDAQ | ~100 | Quick test (~30 min) |\n",
        "| extended | Larger S&P + Korean | ~160 | Thorough benchmark (~60 min) |\n",
        "| custom | User-defined | variable | Focused analysis |\n",
        "\n",
        "| Period | Train Years | Horizons | Est. Folds |\n",
        "|--------|-------------|----------|------------|\n",
        "| 5y | 2 | 5D, 21D | ~4 |\n",
        "| 10y | 3 | 5D, 21D, 63D | ~10 |\n",
        "| 15y | 4 | 5D, 21D, 63D | ~16 |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiE3PZKEsBVG",
        "outputId": "43d797e3-170e-455e-9222-4c663567e075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# ==============================================\n",
        "# DATASET CONFIGURATION -- CHANGE THESE VALUES\n",
        "# ==============================================\n",
        "\n",
        "# Universe: \"default\" (~100 tickers), \"extended\" (~160), \"custom\"\n",
        "UNIVERSE = \"extended\"\n",
        "\n",
        "# Market filter: \"ALL\" (KOSPI+KOSDAQ+NASDAQ), \"US\" (NASDAQ/NYSE only), \"KR\" (KOSPI+KOSDAQ only)\n",
        "MARKET = \"ALL\"\n",
        "\n",
        "# Data period: \"5y\", \"10y\", \"15y\"\n",
        "PERIOD = \"10y\"\n",
        "\n",
        "# Custom tickers (only used when UNIVERSE=\"custom\")\n",
        "CUSTOM_TICKERS = [\n",
        "    # US Tech\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\",\n",
        "    # US Finance\n",
        "    \"JPM\", \"GS\", \"V\", \"MA\",\n",
        "    # US Healthcare\n",
        "    \"JNJ\", \"UNH\", \"LLY\", \"PFE\",\n",
        "    # KOSPI\n",
        "    \"005930.KS\", \"000660.KS\", \"035420.KS\", \"005380.KS\", \"051910.KS\",\n",
        "    # KOSDAQ\n",
        "    \"293490.KQ\", \"247540.KQ\", \"086520.KQ\",\n",
        "]\n",
        "\n",
        "# ==============================================\n",
        "# RUN MODE -- controls speed vs thoroughness\n",
        "# ==============================================\n",
        "# \"quick\"    : 8 key strategies, 2 horizons, fewer folds (~20-30 min)\n",
        "# \"standard\" : all 15 strategies, auto horizons (~60-90 min)\n",
        "# \"full\"     : all 15 strategies, all horizons, more folds (~120-180 min)\n",
        "RUN_MODE = \"standard\"\n",
        "\n",
        "# Strategy subset (None = use RUN_MODE default, or list specific keys)\n",
        "# e.g. [\"A\", \"C\", \"E\", \"E1\", \"G\", \"H\", \"I\"] for a focused comparison\n",
        "STRATEGY_KEYS = None\n",
        "\n",
        "# Email notification when benchmark completes\n",
        "NOTIFY_EMAIL = \"seo.kevin6598@gmail.com\"  # set to None to disable\n",
        "\n",
        "# ==============================================\n",
        "# BENCHMARK CONFIGURATION (auto-adjusted)\n",
        "# ==============================================\n",
        "_period_years = {\"5y\": 5, \"10y\": 10, \"15y\": 15}.get(PERIOD, 5)\n",
        "\n",
        "# Run mode presets\n",
        "if RUN_MODE == \"quick\":\n",
        "    _max_epochs = 8\n",
        "    _early_stop = 3\n",
        "    if _period_years >= 10:\n",
        "        _train_years = 3\n",
        "        _test_months = 6\n",
        "        _step_months = 12   # larger steps = fewer folds\n",
        "        _val_months = 3\n",
        "        _horizons = [5, 21]  # skip 63D for speed\n",
        "    else:\n",
        "        _train_years = 2\n",
        "        _test_months = 4\n",
        "        _step_months = 6\n",
        "        _val_months = 2\n",
        "        _horizons = [5, 21]\n",
        "    _default_strategies = [\"A\", \"B\", \"C\", \"E\", \"E1\", \"G\", \"H\", \"I\"]\n",
        "elif RUN_MODE == \"full\":\n",
        "    _max_epochs = 15\n",
        "    _early_stop = 4\n",
        "    if _period_years >= 15:\n",
        "        _train_years = 4\n",
        "        _test_months = 6\n",
        "        _step_months = 4     # smaller steps = more folds\n",
        "        _val_months = 3\n",
        "        _horizons = [5, 21, 63]\n",
        "    elif _period_years >= 10:\n",
        "        _train_years = 3\n",
        "        _test_months = 6\n",
        "        _step_months = 4\n",
        "        _val_months = 3\n",
        "        _horizons = [5, 21, 63]\n",
        "    else:\n",
        "        _train_years = 2\n",
        "        _test_months = 4\n",
        "        _step_months = 3\n",
        "        _val_months = 2\n",
        "        _horizons = [5, 21]\n",
        "    _default_strategies = None  # all\n",
        "else:  # standard\n",
        "    _max_epochs = 10\n",
        "    _early_stop = 3\n",
        "    if _period_years >= 10:\n",
        "        _train_years = 3\n",
        "        _test_months = 6\n",
        "        _step_months = 6\n",
        "        _val_months = 3\n",
        "        _horizons = [5, 21, 63]\n",
        "    else:\n",
        "        _train_years = 2\n",
        "        _test_months = 4\n",
        "        _step_months = 4\n",
        "        _val_months = 2\n",
        "        _horizons = [5, 21]\n",
        "    _default_strategies = None  # all\n",
        "\n",
        "# User override for strategy subset\n",
        "STRATEGY_KEYS = STRATEGY_KEYS if STRATEGY_KEYS is not None else _default_strategies\n",
        "\n",
        "CONFIG = {\n",
        "    \"horizons\": _horizons,\n",
        "    \"walk_forward\": {\n",
        "        \"train_years\": _train_years,\n",
        "        \"test_months\": _test_months,\n",
        "        \"step_months\": _step_months,\n",
        "        \"val_months\": _val_months,\n",
        "        \"embargo_days\": 5,\n",
        "    },\n",
        "    \"max_epochs\": _max_epochs,\n",
        "    \"early_stop_patience\": _early_stop,\n",
        "    \"ranking_weight\": 0.5,\n",
        "    \"max_params\": 1_500_000,\n",
        "}\n",
        "\n",
        "print(\"=== Dataset Configuration ===\")\n",
        "print(\"Universe: %s  |  Market: %s  |  Period: %s (%dy)\" % (\n",
        "    UNIVERSE, MARKET, PERIOD, _period_years))\n",
        "print(\"\\n=== Run Mode: %s ===\" % RUN_MODE.upper())\n",
        "if STRATEGY_KEYS:\n",
        "    print(\"Strategies: %d selected %s\" % (len(STRATEGY_KEYS), STRATEGY_KEYS))\n",
        "else:\n",
        "    print(\"Strategies: ALL 15\")\n",
        "print(\"Horizons: %s\" % _horizons)\n",
        "print(\"Walk-forward: train=%dy, test=%dmo, step=%dmo, val=%dmo\" % (\n",
        "    _train_years, _test_months, _step_months, _val_months))\n",
        "print(\"Epochs: max=%d, early_stop=%d\" % (_max_epochs, _early_stop))\n",
        "if NOTIFY_EMAIL:\n",
        "    print(\"\\nEmail notification: %s\" % NOTIFY_EMAIL)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Dataset Configuration ===\n",
            "Universe: extended  |  Market: ALL  |  Period: 10y (10y)\n",
            "\n",
            "=== Run Mode: STANDARD ===\n",
            "Strategies: ALL 15\n",
            "Horizons: [5, 21, 63]\n",
            "Walk-forward: train=3y, test=6mo, step=6mo, val=3mo\n",
            "Epochs: max=10, early_stop=3\n",
            "\n",
            "Email notification: seo.kevin6598@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfCe5cdZsBVG"
      },
      "source": [
        "## 2. Standardized Data Pipeline\n",
        "\n",
        "Downloads OHLCV data via yfinance, builds features (technical, sentiment, macro, fundamental, risk),\n",
        "and caches the result to Google Drive for fast re-runs.\n",
        "\n",
        "First run may take **15-30 min** depending on universe size. Subsequent runs load from cache instantly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PgN0XA-sBVG",
        "outputId": "3f2198a0-6536-46fd-85dc-984d3ea1401e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Try mounting Google Drive (optional - falls back to local storage)\n",
        "DRIVE_MOUNTED = False\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', timeout_ms=60000)\n",
        "    DRIVE_MOUNTED = True\n",
        "    DRIVE_DIR = \"/content/drive/MyDrive/ai_stock_tool\"\n",
        "    print(\"Google Drive mounted.\")\n",
        "except Exception as _drive_err:\n",
        "    print(\"Drive mount failed: %s\" % str(_drive_err)[:80])\n",
        "    print(\"Using local storage instead (data will NOT persist across sessions).\")\n",
        "    DRIVE_DIR = \"/content/ai_stock_tool\"\n",
        "\n",
        "ARTIFACT_DIR = os.path.join(DRIVE_DIR, \"artifacts\")\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "\n",
        "# Cache path based on universe, market, period\n",
        "_cache_name = \"benchmark_%s_%s_%s.parquet\" % (UNIVERSE, MARKET, PERIOD)\n",
        "DATA_PATH = os.path.join(DRIVE_DIR, _cache_name)\n",
        "print(\"Data path: %s\" % DATA_PATH)\n",
        "print(\"Artifacts: %s\" % ARTIFACT_DIR)\n",
        "\n",
        "if os.path.exists(DATA_PATH):\n",
        "    print(\"\\nFound cached dataset, loading...\")\n",
        "    panel = pd.read_parquet(DATA_PATH)\n",
        "    print(\"Loaded from cache: %s\" % str(panel.shape))\n",
        "else:\n",
        "    print(\"\\nNo cached dataset found. Building from scratch...\")\n",
        "    print(\"This may take 15-30 min depending on universe size.\\n\")\n",
        "\n",
        "    from data.stock_api import get_historical_data, get_stock_info\n",
        "    from data.universe_manager import UniverseManager\n",
        "    from training.feature_engineering import build_panel_dataset, cross_sectional_normalize\n",
        "\n",
        "    # --- Resolve ticker list ---\n",
        "    um = UniverseManager()\n",
        "    if UNIVERSE == \"extended\":\n",
        "        um._members = UniverseManager.load_extended_universe()\n",
        "\n",
        "    if UNIVERSE == \"custom\":\n",
        "        tickers = CUSTOM_TICKERS\n",
        "    else:\n",
        "        tickers = um.get_universe_by_market(MARKET)\n",
        "\n",
        "    print(\"Target: %d tickers (universe=%s, market=%s, period=%s)\" % (\n",
        "        len(tickers), UNIVERSE, MARKET, PERIOD))\n",
        "\n",
        "    # --- Download OHLCV + company info ---\n",
        "    import time as _time\n",
        "    stock_dfs = {}\n",
        "    stock_infos = {}\n",
        "    failed = []\n",
        "    t0 = _time.time()\n",
        "\n",
        "    for i, ticker in enumerate(tickers):\n",
        "        if (i + 1) % 10 == 0 or i == 0:\n",
        "            elapsed = _time.time() - t0\n",
        "            print(\"  [%d/%d] %s (%.0fs elapsed)\" % (i + 1, len(tickers), ticker, elapsed))\n",
        "        try:\n",
        "            df = get_historical_data(ticker, period=PERIOD)\n",
        "            if df.empty:\n",
        "                failed.append(ticker)\n",
        "                continue\n",
        "            stock_dfs[ticker] = df\n",
        "            info = get_stock_info(ticker) or {}\n",
        "            stock_infos[ticker] = info\n",
        "        except Exception as ex:\n",
        "            failed.append(ticker)\n",
        "            print(\"    FAILED: %s -- %s\" % (ticker, str(ex)[:80]))\n",
        "\n",
        "    dl_time = _time.time() - t0\n",
        "    print(\"\\nDownloaded: %d/%d tickers in %.0f sec\" % (\n",
        "        len(stock_dfs), len(tickers), dl_time))\n",
        "    if failed:\n",
        "        print(\"Failed (%d): %s%s\" % (\n",
        "            len(failed), \", \".join(failed[:20]),\n",
        "            \" ...\" if len(failed) > 20 else \"\"))\n",
        "\n",
        "    # --- Market index ---\n",
        "    market_ticker = um.get_market_ticker(list(stock_dfs.keys()))\n",
        "    print(\"\\nMarket index: %s\" % market_ticker)\n",
        "    market_df = get_historical_data(market_ticker, period=PERIOD)\n",
        "    if market_df.empty:\n",
        "        print(\"WARNING: Market index download failed\")\n",
        "        market_df = None\n",
        "\n",
        "    # --- Build feature panel ---\n",
        "    horizons_days = CONFIG[\"horizons\"]\n",
        "    print(\"\\nBuilding features (horizons=%s)...\" % horizons_days)\n",
        "    t1 = _time.time()\n",
        "    panel = build_panel_dataset(stock_dfs, stock_infos, market_df, horizons_days)\n",
        "    print(\"Raw panel: %s (%.0f sec)\" % (str(panel.shape), _time.time() - t1))\n",
        "\n",
        "    # Cross-sectional normalization\n",
        "    panel = cross_sectional_normalize(panel)\n",
        "    print(\"Normalized: %s\" % str(panel.shape))\n",
        "\n",
        "    # Save for future runs\n",
        "    try:\n",
        "        panel.to_parquet(DATA_PATH)\n",
        "        _size_mb = os.path.getsize(DATA_PATH) / 1e6\n",
        "        print(\"\\nCached to: %s (%.1f MB)\" % (DATA_PATH, _size_mb))\n",
        "        if not DRIVE_MOUNTED:\n",
        "            print(\"NOTE: Local cache only -- will be lost when runtime disconnects.\")\n",
        "    except Exception as _save_err:\n",
        "        print(\"Cache save failed: %s\" % str(_save_err)[:80])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted.\n",
            "Data path: /content/drive/MyDrive/ai_stock_tool/benchmark_extended_ALL_10y.parquet\n",
            "Artifacts: /content/drive/MyDrive/ai_stock_tool/artifacts\n",
            "\n",
            "Found cached dataset, loading...\n",
            "Loaded from cache: (346696, 124)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QViF2MLlsBVG",
        "outputId": "89ff693b-2807-40f7-b0d9-136ad44d1763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "valid_tickers = panel.index.get_level_values(1).unique().tolist()\n",
        "print(\"Panel: %s\" % str(panel.shape))\n",
        "print(\"Tickers: %d\" % len(valid_tickers))\n",
        "\n",
        "date_min = panel.index.get_level_values(0).min()\n",
        "date_max = panel.index.get_level_values(0).max()\n",
        "data_span_months = (date_max - date_min).days / 30.44\n",
        "print(\"Date range: %s to %s (%.0f months)\" % (\n",
        "    date_min.date(), date_max.date(), data_span_months))\n",
        "\n",
        "# --- Market Composition ---\n",
        "kr_kospi = sorted([t for t in valid_tickers if t.upper().endswith(\".KS\")])\n",
        "kr_kosdaq = sorted([t for t in valid_tickers if t.upper().endswith(\".KQ\")])\n",
        "us_tickers = sorted([t for t in valid_tickers\n",
        "                     if not t.upper().endswith((\".KS\", \".KQ\"))])\n",
        "\n",
        "print(\"\\n=== Market Composition ===\")\n",
        "print(\"NYSE/NASDAQ: %d tickers\" % len(us_tickers))\n",
        "print(\"KOSPI (.KS): %d tickers\" % len(kr_kospi))\n",
        "print(\"KOSDAQ (.KQ): %d tickers\" % len(kr_kosdaq))\n",
        "\n",
        "if kr_kospi:\n",
        "    print(\"\\nKOSPI: %s\" % \", \".join(kr_kospi))\n",
        "if kr_kosdaq:\n",
        "    print(\"KOSDAQ: %s\" % \", \".join(kr_kosdaq))\n",
        "if us_tickers and len(us_tickers) <= 30:\n",
        "    print(\"US: %s\" % \", \".join(us_tickers))\n",
        "elif us_tickers:\n",
        "    print(\"US (first 30): %s ...\" % \", \".join(us_tickers[:30]))\n",
        "\n",
        "# --- Per-ticker data coverage ---\n",
        "ticker_counts = panel.groupby(level=1).size()\n",
        "print(\"\\n=== Data Coverage ===\")\n",
        "print(\"Avg samples/ticker: %.0f\" % ticker_counts.mean())\n",
        "print(\"Min: %d (%s)  Max: %d (%s)\" % (\n",
        "    ticker_counts.min(), ticker_counts.idxmin(),\n",
        "    ticker_counts.max(), ticker_counts.idxmax()))\n",
        "\n",
        "thin = ticker_counts[ticker_counts < 500]\n",
        "if len(thin) > 0:\n",
        "    print(\"Tickers with < 500 samples (%d): %s\" % (\n",
        "        len(thin), \", \".join(thin.index.tolist()[:15])))\n",
        "\n",
        "# --- Fold estimate ---\n",
        "wf = CONFIG[\"walk_forward\"]\n",
        "train_months = wf[\"train_years\"] * 12\n",
        "val_months = wf.get(\"val_months\", 3)\n",
        "test_months = wf[\"test_months\"]\n",
        "step_months = wf[\"step_months\"]\n",
        "min_needed = train_months + val_months + test_months + 1\n",
        "available_after_first = data_span_months - min_needed\n",
        "est_folds = max(0, 1 + int(available_after_first / step_months))\n",
        "print(\"\\n=== Walk-Forward Folds ===\")\n",
        "print(\"train=%dmo + val=%dmo + test=%dmo = %dmo minimum\" % (\n",
        "    train_months, val_months, test_months, min_needed))\n",
        "print(\"Expected folds: ~%d (step=%dmo over %.0f months)\" % (\n",
        "    est_folds, step_months, data_span_months))\n",
        "if est_folds == 0:\n",
        "    print(\"WARNING: No folds possible! Reduce train_years or increase data period.\")\n",
        "\n",
        "# --- Feature columns ---\n",
        "feature_cols = [\n",
        "    c for c in panel.columns\n",
        "    if not c.startswith(\"fwd_return_\")\n",
        "    and not c.startswith(\"residual_return_\")\n",
        "    and not c.startswith(\"ranked_target_\")\n",
        "    and c not in (\"_close\", \"ticker_id\")\n",
        "]\n",
        "\n",
        "price_cols = [c for c in feature_cols if not c.startswith(\"nlp_\")]\n",
        "nlp_cols = [c for c in feature_cols if c.startswith(\"nlp_\")]\n",
        "print(\"\\n=== Features ===\")\n",
        "print(\"Total: %d  (Price: %d, NLP: %d)\" % (\n",
        "    len(feature_cols), len(price_cols), len(nlp_cols)))\n",
        "\n",
        "# Check required targets\n",
        "for h in CONFIG[\"horizons\"]:\n",
        "    tc = \"fwd_return_%dd\" % h\n",
        "    if tc in panel.columns:\n",
        "        non_null = panel[tc].notna().sum()\n",
        "        print(\"  %s: %d non-null (%.1f%%)\" % (\n",
        "            tc, non_null, non_null / len(panel) * 100))\n",
        "    else:\n",
        "        print(\"  WARNING: %s not found!\" % tc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Panel: (346696, 124)\n",
            "Tickers: 160\n",
            "Date range: 2017-02-13 to 2025-11-12 (105 months)\n",
            "\n",
            "=== Market Composition ===\n",
            "NYSE/NASDAQ: 139 tickers\n",
            "KOSPI (.KS): 15 tickers\n",
            "KOSDAQ (.KQ): 6 tickers\n",
            "\n",
            "KOSPI: 000270.KS, 000660.KS, 003670.KS, 005380.KS, 005930.KS, 006400.KS, 028260.KS, 035420.KS, 035720.KS, 051910.KS, 055550.KS, 068270.KS, 105560.KS, 207940.KS, 373220.KS\n",
            "KOSDAQ: 086520.KQ, 112040.KQ, 196170.KQ, 247540.KQ, 263750.KQ, 293490.KQ\n",
            "US (first 30): AAPL, ABBV, ABT, ADBE, AEP, AMAT, AMD, AMGN, AMT, AMZN, AON, APD, AVGO, AXP, AZO, BA, BAC, BDX, BKNG, BLK, BMY, C, CAT, CB, CDNS, CHTR, CL, CMCSA, CME, COP ...\n",
            "\n",
            "=== Data Coverage ===\n",
            "Avg samples/ticker: 2167\n",
            "Min: 672 (373220.KS)  Max: 2200 (AAPL)\n",
            "\n",
            "=== Walk-Forward Folds ===\n",
            "train=36mo + val=3mo + test=6mo = 46mo minimum\n",
            "Expected folds: ~10 (step=6mo over 105 months)\n",
            "\n",
            "=== Features ===\n",
            "Total: 114  (Price: 87, NLP: 27)\n",
            "  fwd_return_5d: 346690 non-null (100.0%)\n",
            "  fwd_return_21d: 346690 non-null (100.0%)\n",
            "  fwd_return_63d: 346690 non-null (100.0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFlFdU9EsBVG",
        "outputId": "4ea76cef-8c95-4bdc-9803-a15676c77bad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Precompute derived features for all strategies\n",
        "\n",
        "# Sentiment residual (for Strategy D)\n",
        "market_feat = None\n",
        "for cand in [\"market_return\", \"market_return_21d\", \"spy_return_21d\"]:\n",
        "    if cand in panel.columns:\n",
        "        market_feat = cand\n",
        "        break\n",
        "\n",
        "if market_feat:\n",
        "    print(\"Market return feature: %s\" % market_feat)\n",
        "else:\n",
        "    print(\"WARNING: No market return feature found for residualization\")\n",
        "\n",
        "# Volatility proxy\n",
        "vol_feat = None\n",
        "for cand in [\"volatility_21d\", \"realized_vol_21d\", \"atr_pct\"]:\n",
        "    if cand in panel.columns:\n",
        "        vol_feat = cand\n",
        "        break\n",
        "\n",
        "if vol_feat:\n",
        "    print(\"Volatility feature: %s\" % vol_feat)\n",
        "else:\n",
        "    print(\"WARNING: No volatility feature found\")\n",
        "\n",
        "# Data quality check\n",
        "nan_pct = panel[feature_cols].isna().mean().mean() * 100\n",
        "print(\"\\nNaN rate: %.2f%%\" % nan_pct)\n",
        "print(\"Data pipeline ready.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: No market return feature found for residualization\n",
            "Volatility feature: volatility_21d\n",
            "\n",
            "NaN rate: 0.00%\n",
            "Data pipeline ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI3ED3QSsBVI"
      },
      "source": [
        "## 3. Strategy Definitions\n",
        "\n",
        "All 15 strategies with identical interface: `train()`, `predict()`, `num_parameters()`.\n",
        "\n",
        "- **A-F**: Neural temporal/NLP models (require PyTorch)\n",
        "- **E1, E2**: Novel fusion architectures (cross-attention, additive residual)\n",
        "- **F1**: Simplified Temporal Fusion Transformer\n",
        "- **G, G1**: Transformer variants (standard + linear attention)\n",
        "- **H, I**: Tree-based models (no torch required)\n",
        "- **J, K**: Short-horizon specialists (5D only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gfsMio5sBVI",
        "outputId": "7c05b1c4-8f7e-4afb-cc8f-be9fcd9eb1a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from training.strategy_benchmark import (\n",
        "    BenchmarkConfig, BenchmarkEvaluator, STRATEGY_REGISTRY,\n",
        "    save_benchmark_results, run_integrity_checks,\n",
        "    ExtendedMetrics, DMTestResult,\n",
        ")\n",
        "\n",
        "config = BenchmarkConfig.from_dict(CONFIG)\n",
        "\n",
        "# Filter strategies based on STRATEGY_KEYS\n",
        "if STRATEGY_KEYS is not None:\n",
        "    selected_registry = {k: v for k, v in STRATEGY_REGISTRY.items() if k in STRATEGY_KEYS}\n",
        "    missing = set(STRATEGY_KEYS) - set(selected_registry.keys())\n",
        "    if missing:\n",
        "        print(\"WARNING: Unknown strategy keys: %s\" % missing)\n",
        "else:\n",
        "    selected_registry = STRATEGY_REGISTRY\n",
        "\n",
        "print(\"Strategies to benchmark (%d / %d):\" % (len(selected_registry), len(STRATEGY_REGISTRY)))\n",
        "print(\"-\" * 55)\n",
        "for key, cls in sorted(selected_registry.items()):\n",
        "    sh = getattr(cls, 'supported_horizons', None)\n",
        "    h_info = \"all horizons\" if sh is None else \"%s only\" % sh\n",
        "    print(\"  %-3s: %-28s (%s)\" % (key, cls.name, h_info))\n",
        "\n",
        "# Estimate total evaluations\n",
        "n_strats = len(selected_registry)\n",
        "n_horizons = len(config.horizons)\n",
        "# Short-horizon strategies only run at 5D\n",
        "short_only = sum(1 for cls in selected_registry.values()\n",
        "                 if getattr(cls, 'supported_horizons', None) == [5])\n",
        "n_evals = n_strats * n_horizons - short_only * (n_horizons - 1)\n",
        "print(\"\\nEstimated evaluations: %d (strategies x horizons)\" % n_evals)\n",
        "print(\"Estimated folds per eval: ~%d\" % est_folds)\n",
        "print(\"Total training runs: ~%d\" % (n_evals * est_folds))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strategies to benchmark (15 / 15):\n",
            "-------------------------------------------------------\n",
            "  A  : A_LSTM_Baseline              (all horizons)\n",
            "  B  : B_NLP_Only                   (all horizons)\n",
            "  C  : C_Late_Ensemble              (all horizons)\n",
            "  D  : D_Residual_Sentiment         (all horizons)\n",
            "  E  : E_Gated_Hybrid               (all horizons)\n",
            "  E1 : E1_Attention_Hybrid          (all horizons)\n",
            "  E2 : E2_Additive_Residual         (all horizons)\n",
            "  F  : F_CS_Attention_LSTM          (all horizons)\n",
            "  F1 : F1_Temporal_Fusion           (all horizons)\n",
            "  G  : G_Transformer                (all horizons)\n",
            "  G1 : G1_Efficient_Transformer     (all horizons)\n",
            "  H  : H_Random_Forest              (all horizons)\n",
            "  I  : I_LightGBM                   (all horizons)\n",
            "  J  : J_Short_NLP_5D               ([5] only)\n",
            "  K  : K_Short_Hybrid_5D            ([5] only)\n",
            "\n",
            "Estimated evaluations: 41 (strategies x horizons)\n",
            "Estimated folds per eval: ~10\n",
            "Total training runs: ~410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im9yApfVsBVI"
      },
      "source": [
        "## 4. Run Benchmark\n",
        "\n",
        "Walk-forward evaluation for selected strategies at configured horizons.\n",
        "\n",
        "**Checkpoint/Resume:** Results are saved per-strategy to `ARTIFACT_DIR/checkpoints/`.\n",
        "If the runtime times out, simply re-run this cell -- completed strategies will be\n",
        "loaded from checkpoint and only remaining strategies will be computed.\n",
        "Set `CLEAR_CHECKPOINTS = True` to discard previous results and start fresh.\n",
        "\n",
        "**Estimated runtime (T4 GPU):**\n",
        "\n",
        "| Run Mode | Strategies | Horizons | Folds (10y) | Est. Time |\n",
        "|----------|-----------|----------|-------------|-----------|\n",
        "| `quick` | 8 key | 5D, 21D | ~5 | **20-30 min** |\n",
        "| `standard` | all 15 | 5D, 21D, 63D | ~10 | **60-90 min** |\n",
        "| `full` | all 15 | 5D, 21D, 63D | ~14 | **120-180 min** |\n",
        "\n",
        "Email notification is sent to `NOTIFY_EMAIL` when the benchmark completes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asXSW33ZsBVI",
        "outputId": "524f268b-7375-45b9-f842-f0763169c9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\", datefmt=\"%H:%M:%S\")\n",
        "\n",
        "evaluator = BenchmarkEvaluator(panel, feature_cols, config)\n",
        "\n",
        "# Checkpoint directory -- saves each strategy result to disk after completion.\n",
        "# On runtime timeout, re-run this cell to resume from the last checkpoint.\n",
        "CHECKPOINT_DIR = os.path.join(ARTIFACT_DIR, \"checkpoints\")\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# To force a full re-run (discard previous checkpoints), set CLEAR_CHECKPOINTS = True\n",
        "CLEAR_CHECKPOINTS = False\n",
        "if CLEAR_CHECKPOINTS:\n",
        "    import glob as _glob\n",
        "    for _f in _glob.glob(os.path.join(CHECKPOINT_DIR, \"*.pkl\")):\n",
        "        os.remove(_f)\n",
        "    print(\"Cleared all checkpoints.\")\n",
        "\n",
        "# Show existing checkpoints\n",
        "_existing = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith(\".pkl\")]\n",
        "if _existing:\n",
        "    print(\"Found %d checkpoint(s) from previous run -- will resume:\" % len(_existing))\n",
        "    for _f in sorted(_existing):\n",
        "        print(\"  %s\" % _f)\n",
        "else:\n",
        "    print(\"No checkpoints found -- starting fresh run.\")\n",
        "\n",
        "strategy_classes = list(selected_registry.values())\n",
        "n_horizons_eff = len(config.horizons)\n",
        "print(\"\\nRunning %d strategies x %d horizons (mode=%s)...\" % (\n",
        "    len(strategy_classes), n_horizons_eff, RUN_MODE))\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import time\n",
        "t0 = time.time()\n",
        "results = evaluator.run_all(strategy_classes, checkpoint_dir=CHECKPOINT_DIR)\n",
        "total_time = time.time() - t0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Benchmark complete in %.1f min\" % (total_time / 60))\n",
        "print(\"Total evaluations: %d\" % len(results))\n",
        "print(\"Strategies with extended metrics: %d\" % sum(1 for r in results if r.extended))\n",
        "\n",
        "# --- Email notification ---\n",
        "if NOTIFY_EMAIL:\n",
        "    _benchmark_summary = (\n",
        "        \"Benchmark complete in %.1f min\\n\"\n",
        "        \"Mode: %s | Universe: %s | Market: %s | Period: %s\\n\"\n",
        "        \"Strategies: %d | Evaluations: %d\\n\\n\"\n",
        "        % (total_time / 60, RUN_MODE, UNIVERSE, MARKET, PERIOD,\n",
        "           len(strategy_classes), len(results))\n",
        "    )\n",
        "    # Top 5 results\n",
        "    _top = sorted(results, key=lambda r: r.composite, reverse=True)[:5]\n",
        "    _benchmark_summary += \"=== Top 5 by Composite ===\\n\"\n",
        "    for _r in _top:\n",
        "        _benchmark_summary += \"  %s/%s: IC=%.4f Sharpe=%.2f Composite=%.4f [%s]\\n\" % (\n",
        "            _r.name, _r.horizon, _r.ic_mean, _r.sharpe, _r.composite, _r.status)\n",
        "\n",
        "    try:\n",
        "        import smtplib\n",
        "        from email.mime.text import MIMEText\n",
        "        from google.colab import auth\n",
        "        import google.auth\n",
        "        import google.auth.transport.requests\n",
        "        from googleapiclient.discovery import build\n",
        "        import base64\n",
        "\n",
        "        auth.authenticate_user()\n",
        "        creds, _ = google.auth.default()\n",
        "        creds.refresh(google.auth.transport.requests.Request())\n",
        "        service = build('gmail', 'v1', credentials=creds)\n",
        "\n",
        "        msg = MIMEText(_benchmark_summary)\n",
        "        msg['to'] = NOTIFY_EMAIL\n",
        "        msg['subject'] = '[Benchmark] %s/%s/%s done - %.0fmin' % (\n",
        "            UNIVERSE, MARKET, PERIOD, total_time / 60)\n",
        "        raw = base64.urlsafe_b64encode(msg.as_bytes()).decode()\n",
        "        service.users().messages().send(\n",
        "            userId='me', body={'raw': raw}).execute()\n",
        "        print(\"Email sent to %s\" % NOTIFY_EMAIL)\n",
        "    except Exception as mail_err:\n",
        "        print(\"Email notification failed: %s\" % str(mail_err)[:100])\n",
        "        print(\"(Summary printed above instead)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoints found -- starting fresh run.\n",
            "\n",
            "Running 15 strategies x 3 horizons (mode=standard)...\n",
            "============================================================\n",
            "\n",
            ">>> [1/41] Running: A_LSTM_Baseline / 5D  |  elapsed 0.0min  |  ETA --\n",
            "      fold 1/10 ..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu8inMkBsBVI"
      },
      "source": [
        "## 5. Strategy Comparison Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOwPd5UGsBVI"
      },
      "source": [
        "import math\n",
        "\n",
        "# Build comparison table\n",
        "rows = []\n",
        "for r in results:\n",
        "    rows.append({\n",
        "        \"Strategy\": r.name,\n",
        "        \"Horizon\": r.horizon,\n",
        "        \"IC\": round(r.ic_mean, 4),\n",
        "        \"ICIR\": round(r.icir, 2),\n",
        "        \"Sharpe\": round(r.sharpe, 2),\n",
        "        \"IC_std\": round(r.ic_std, 4),\n",
        "        \"Prod IC\": round(r.prod_ic, 4),\n",
        "        \"Overfit\": round(r.overfit_score, 3),\n",
        "        \"Composite\": round(r.composite, 4),\n",
        "        \"Params\": r.param_count,\n",
        "        \"Time(s)\": round(r.train_time, 1),\n",
        "        \"Status\": r.status,\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(rows)\n",
        "print(\"\\nStrategy Benchmark Results (sorted by Composite):\")\n",
        "print(\"=\" * 100)\n",
        "display(df_results)\n",
        "\n",
        "# Summary by status\n",
        "print(\"\\nStatus Summary:\")\n",
        "for status in [\"PASS\", \"WARN\", \"FAIL\"]:\n",
        "    count = sum(1 for r in results if r.status == status)\n",
        "    names = [r.name + \"/\" + r.horizon for r in results if r.status == status]\n",
        "    print(\"  %s (%d): %s\" % (status, count, \", \".join(names) if names else \"none\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuTZTTKbsBVI"
      },
      "source": [
        "## 5a. Extended Metrics Table\n",
        "\n",
        "Regression accuracy, directional metrics, calibration, and market-level predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQms_R_NsBVI"
      },
      "source": [
        "# Extended Metrics: Regression, Directional, Calibration, Market-level\n",
        "ext_rows = []\n",
        "for r in results:\n",
        "    if r.extended is None:\n",
        "        continue\n",
        "    e = r.extended\n",
        "    ext_rows.append({\n",
        "        \"Strategy\": r.name,\n",
        "        \"Horizon\": r.horizon,\n",
        "        \"RMSE\": round(e.rmse, 6),\n",
        "        \"R2\": round(e.r_squared, 4),\n",
        "        \"Hit%\": round(e.hit_ratio * 100, 1),\n",
        "        \"Prec\": round(e.precision, 3),\n",
        "        \"Recall\": round(e.recall, 3),\n",
        "        \"F1\": round(e.f1, 3),\n",
        "        \"Cal.Slope\": round(e.calib_slope, 3),\n",
        "        \"Mkt.R2\": round(e.market_r2, 4),\n",
        "        \"Mkt.Dir%\": round(e.market_direction_accuracy * 100, 1),\n",
        "    })\n",
        "\n",
        "if ext_rows:\n",
        "    df_ext = pd.DataFrame(ext_rows)\n",
        "    print(\"Extended Metrics:\")\n",
        "    print(\"=\" * 120)\n",
        "    display(df_ext)\n",
        "else:\n",
        "    print(\"No extended metrics available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEyMPEhSsBVI"
      },
      "source": [
        "# Per-Stock R2 Summary\n",
        "r2_rows = []\n",
        "for r in results:\n",
        "    if r.extended is None:\n",
        "        continue\n",
        "    e = r.extended\n",
        "    r2_rows.append({\n",
        "        \"Strategy\": r.name,\n",
        "        \"Horizon\": r.horizon,\n",
        "        \"Mean R2\": round(e.mean_stock_r2, 4),\n",
        "        \"Median R2\": round(e.median_stock_r2, 4),\n",
        "        \"% Positive\": round(e.pct_r2_positive, 1),\n",
        "        \"% > 0.05\": round(e.pct_r2_above_005, 1),\n",
        "        \"N Stocks\": len(e.stock_r2_values),\n",
        "    })\n",
        "\n",
        "if r2_rows:\n",
        "    df_r2 = pd.DataFrame(r2_rows)\n",
        "    print(\"Per-Stock R2 Summary:\")\n",
        "    print(\"=\" * 90)\n",
        "    display(df_r2)\n",
        "else:\n",
        "    print(\"No per-stock R2 data available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ordW4aq4sBVI"
      },
      "source": [
        "# Backtest Results: Long-Only and Long-Short\n",
        "bt_rows = []\n",
        "for r in results:\n",
        "    if r.extended is None:\n",
        "        continue\n",
        "    e = r.extended\n",
        "    bt_rows.append({\n",
        "        \"Strategy\": r.name,\n",
        "        \"Horizon\": r.horizon,\n",
        "        \"L/O CAGR\": \"%.2f%%\" % (e.lo_cagr * 100),\n",
        "        \"L/O Sharpe\": round(e.lo_sharpe, 2),\n",
        "        \"L/O MaxDD\": \"%.2f%%\" % (e.lo_max_dd * 100),\n",
        "        \"L/S CAGR\": \"%.2f%%\" % (e.ls_cagr * 100),\n",
        "        \"L/S Sharpe\": round(e.ls_sharpe, 2),\n",
        "        \"L/S MaxDD\": \"%.2f%%\" % (e.ls_max_dd * 100),\n",
        "    })\n",
        "\n",
        "if bt_rows:\n",
        "    df_bt = pd.DataFrame(bt_rows)\n",
        "    print(\"Backtest Results (Long-Only and Long-Short 20/20):\")\n",
        "    print(\"=\" * 100)\n",
        "    display(df_bt)\n",
        "else:\n",
        "    print(\"No backtest data available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2mU15wOsBVI"
      },
      "source": [
        "# Diebold-Mariano Test Matrix\n",
        "dm_results = BenchmarkEvaluator.compute_dm_tests(results)\n",
        "\n",
        "if dm_results:\n",
        "    # Display as table\n",
        "    dm_rows = []\n",
        "    for dm in dm_results:\n",
        "        dm_rows.append({\n",
        "            \"A\": dm.strategy_a.split(\"_\")[0],\n",
        "            \"B\": dm.strategy_b.split(\"_\")[0],\n",
        "            \"Horizon\": dm.horizon,\n",
        "            \"DM Stat\": round(dm.dm_stat, 2),\n",
        "            \"p-value\": round(dm.p_value, 4),\n",
        "            \"Better\": dm.better.split(\"_\")[0],\n",
        "            \"Sig?\": \"*\" if dm.p_value < 0.05 else (\".\" if dm.p_value < 0.10 else \"\"),\n",
        "        })\n",
        "    df_dm = pd.DataFrame(dm_rows)\n",
        "    print(\"Diebold-Mariano Tests (* = p<0.05, . = p<0.10):\")\n",
        "    print(\"=\" * 80)\n",
        "    display(df_dm)\n",
        "\n",
        "    # Heatmap per horizon\n",
        "    import matplotlib.pyplot as plt\n",
        "    horizons = sorted(set(dm.horizon for dm in dm_results))\n",
        "    fig_dm, axes_dm = plt.subplots(1, len(horizons), figsize=(8 * len(horizons), 6))\n",
        "    if len(horizons) == 1:\n",
        "        axes_dm = [axes_dm]\n",
        "\n",
        "    for ax, h in zip(axes_dm, horizons):\n",
        "        h_dm = [dm for dm in dm_results if dm.horizon == h]\n",
        "        names = sorted(set(\n",
        "            [dm.strategy_a.split(\"_\")[0] for dm in h_dm] +\n",
        "            [dm.strategy_b.split(\"_\")[0] for dm in h_dm]\n",
        "        ))\n",
        "        n = len(names)\n",
        "        pval_matrix = np.ones((n, n))\n",
        "        name_to_idx = {nm: i for i, nm in enumerate(names)}\n",
        "\n",
        "        for dm in h_dm:\n",
        "            ia = name_to_idx.get(dm.strategy_a.split(\"_\")[0])\n",
        "            ib = name_to_idx.get(dm.strategy_b.split(\"_\")[0])\n",
        "            if ia is not None and ib is not None:\n",
        "                pval_matrix[ia, ib] = dm.p_value\n",
        "                pval_matrix[ib, ia] = dm.p_value\n",
        "\n",
        "        im = ax.imshow(pval_matrix, cmap=\"RdYlGn\", vmin=0, vmax=0.2)\n",
        "        ax.set_xticks(range(n))\n",
        "        ax.set_xticklabels(names, rotation=45, fontsize=7, ha=\"right\")\n",
        "        ax.set_yticks(range(n))\n",
        "        ax.set_yticklabels(names, fontsize=7)\n",
        "        ax.set_title(\"DM p-values: %s\" % h, fontweight=\"bold\")\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if i != j:\n",
        "                    ax.text(j, i, \"%.2f\" % pval_matrix[i, j],\n",
        "                            ha=\"center\", va=\"center\", fontsize=6,\n",
        "                            color=\"white\" if pval_matrix[i, j] < 0.05 else \"black\")\n",
        "\n",
        "    plt.colorbar(im, ax=axes_dm[-1], shrink=0.7, label=\"p-value\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"dm_test_heatmap.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"DM test heatmap saved.\")\n",
        "else:\n",
        "    print(\"No DM test results (need fold predictions from multiple strategies).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEZVIPhWsBVI"
      },
      "source": [
        "## 6. Visualization Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Fl_Ei-sBVI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "fig = plt.figure(figsize=(20, 16))\n",
        "gs_layout = gridspec.GridSpec(2, 3, hspace=0.35, wspace=0.3)\n",
        "\n",
        "# --- Panel 1: IC Comparison Bar Chart ---\n",
        "ax1 = fig.add_subplot(gs_layout[0, 0])\n",
        "labels = [\"%s\\n%s\" % (r.name.split(\"_\", 1)[-1][:12], r.horizon) for r in results]\n",
        "ics = [r.ic_mean for r in results]\n",
        "colors = [\"#4CAF50\" if r.status == \"PASS\" else \"#FFC107\" if r.status == \"WARN\" else \"#F44336\"\n",
        "          for r in results]\n",
        "ax1.barh(range(len(results)), ics, color=colors, edgecolor=\"white\")\n",
        "ax1.set_yticks(range(len(results)))\n",
        "ax1.set_yticklabels(labels, fontsize=7)\n",
        "ax1.set_xlabel(\"Cross-Sectional IC\")\n",
        "ax1.set_title(\"IC Comparison\", fontweight=\"bold\")\n",
        "ax1.axvline(x=0, color=\"gray\", linewidth=0.5)\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# --- Panel 2: IC Stability (fold ICs per strategy) ---\n",
        "ax2 = fig.add_subplot(gs_layout[0, 1])\n",
        "cmap = plt.colormaps[\"tab20\"]\n",
        "for i, r in enumerate(results):\n",
        "    if r.fold_metrics:\n",
        "        fold_ics = [f.ic for f in r.fold_metrics]\n",
        "        x_positions = [i] * len(fold_ics)\n",
        "        ax2.scatter(x_positions, fold_ics, color=cmap(i % 20), s=30, zorder=3, alpha=0.7)\n",
        "        ax2.plot([i, i], [min(fold_ics), max(fold_ics)],\n",
        "                 color=cmap(i % 20), linewidth=2, alpha=0.5)\n",
        "ax2.set_xticks(range(len(results)))\n",
        "ax2.set_xticklabels([r.name.split(\"_\")[0] + \"/\" + r.horizon for r in results],\n",
        "                     rotation=90, fontsize=6, ha=\"center\")\n",
        "ax2.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "ax2.set_ylabel(\"IC per fold\")\n",
        "ax2.set_title(\"IC Stability (per fold)\", fontweight=\"bold\")\n",
        "ax2.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "# --- Panel 3: Composite Score Bar ---\n",
        "ax3 = fig.add_subplot(gs_layout[0, 2])\n",
        "composites = [r.composite if not math.isinf(r.composite) else 0 for r in results]\n",
        "ax3.barh(range(len(results)), composites, color=colors, edgecolor=\"white\")\n",
        "ax3.set_yticks(range(len(results)))\n",
        "ax3.set_yticklabels(labels, fontsize=7)\n",
        "ax3.set_xlabel(\"Composite Score\")\n",
        "ax3.set_title(\"Composite Score\", fontweight=\"bold\")\n",
        "ax3.axvline(x=0, color=\"gray\", linewidth=0.5)\n",
        "ax3.invert_yaxis()\n",
        "\n",
        "# --- Panel 4: Gate Activation ---\n",
        "ax4 = fig.add_subplot(gs_layout[1, 0])\n",
        "gate_data = [(r.name, r.horizon, r.gate_stats) for r in results if r.gate_stats]\n",
        "if gate_data:\n",
        "    g_labels = [\"%s/%s\" % (n, h) for n, h, _ in gate_data]\n",
        "    g_means = []\n",
        "    g_stds = []\n",
        "    for _, _, gstat in gate_data:\n",
        "        if isinstance(gstat, dict):\n",
        "            g_means.append(gstat.get(\"gate_mean\", 0))\n",
        "            g_stds.append(gstat.get(\"gate_std\", 0))\n",
        "        else:\n",
        "            g_means.append(0.5)\n",
        "            g_stds.append(0)\n",
        "    ax4.barh(g_labels, g_means, xerr=g_stds, color=\"#2196F3\", capsize=5)\n",
        "    ax4.set_xlabel(\"Gate Activation\")\n",
        "    ax4.set_title(\"Gate Distribution (Hybrid)\", fontweight=\"bold\")\n",
        "    ax4.set_xlim(0, 1)\n",
        "else:\n",
        "    ax4.text(0.5, 0.5, \"No gate stats\\navailable\",\n",
        "             transform=ax4.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n",
        "    ax4.set_title(\"Gate Distribution\", fontweight=\"bold\")\n",
        "\n",
        "# --- Panel 5: Ensemble Weights ---\n",
        "ax5 = fig.add_subplot(gs_layout[1, 1])\n",
        "ens_data = [(r.name, r.horizon, r.ensemble_weights) for r in results if r.ensemble_weights]\n",
        "if ens_data:\n",
        "    for i, (name, horizon, w) in enumerate(ens_data):\n",
        "        x = [0, 1]\n",
        "        vals = [w.get(\"lstm\", 0), w.get(\"nlp\", 0)]\n",
        "        ax5.bar([v + i * 0.3 for v in x], vals, width=0.25,\n",
        "                label=\"%s/%s\" % (name.split(\"_\")[0], horizon))\n",
        "    ax5.set_xticks([0, 1])\n",
        "    ax5.set_xticklabels([\"LSTM weight\", \"NLP weight\"])\n",
        "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n",
        "    ax5.legend(fontsize=8)\n",
        "    ax5.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "else:\n",
        "    ax5.text(0.5, 0.5, \"No ensemble weights\\navailable\",\n",
        "             transform=ax5.transAxes, ha=\"center\", va=\"center\", fontsize=14, color=\"gray\")\n",
        "    ax5.set_title(\"Ensemble Weights\", fontweight=\"bold\")\n",
        "\n",
        "# --- Panel 6: Horizon Sensitivity ---\n",
        "ax6 = fig.add_subplot(gs_layout[1, 2])\n",
        "strategy_names = sorted(set(r.name for r in results))\n",
        "horizon_labels = sorted(set(r.horizon for r in results))\n",
        "x_pos = np.arange(len(strategy_names))\n",
        "width = 0.8 / max(len(horizon_labels), 1)\n",
        "\n",
        "for j, h in enumerate(horizon_labels):\n",
        "    h_ics = []\n",
        "    for sn in strategy_names:\n",
        "        match = [r for r in results if r.name == sn and r.horizon == h]\n",
        "        h_ics.append(match[0].ic_mean if match else 0)\n",
        "    offset = (j - len(horizon_labels) / 2 + 0.5) * width\n",
        "    ax6.bar(x_pos + offset, h_ics, width, label=h)\n",
        "\n",
        "ax6.set_xticks(x_pos)\n",
        "ax6.set_xticklabels([n.split(\"_\")[0] for n in strategy_names],\n",
        "                     rotation=45, fontsize=7, ha=\"right\")\n",
        "ax6.set_ylabel(\"IC\")\n",
        "h_str = \" vs \".join(horizon_labels)\n",
        "ax6.set_title(\"Horizon Sensitivity (%s)\" % h_str, fontweight=\"bold\")\n",
        "ax6.legend(fontsize=8)\n",
        "ax6.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "ax6.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "fig.suptitle(\"Multi-Strategy Benchmark Dashboard (15 Models)\", fontsize=16, fontweight=\"bold\", y=1.01)\n",
        "plt.savefig(os.path.join(ARTIFACT_DIR, \"strategy_benchmark.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Dashboard saved.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RfIWKqNsBVI"
      },
      "source": [
        "## 6a. Extended Visualizations\n",
        "\n",
        "Five additional panels: Per-Stock R2 Histogram, Pred vs Actual Scatter, Calibration Slope, Rolling R2, Cumulative PnL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g1u9qZ5sBVJ"
      },
      "source": [
        "# --- Visualization 1: Per-Stock R2 Histogram ---\n",
        "ext_results = [r for r in results if r.extended and r.extended.stock_r2_values]\n",
        "n_ext = len(ext_results)\n",
        "\n",
        "if n_ext > 0:\n",
        "    ncols = min(5, n_ext)\n",
        "    nrows = (n_ext + ncols - 1) // ncols\n",
        "    fig_r2h, axes_r2h = plt.subplots(nrows, ncols, figsize=(4 * ncols, 3 * nrows))\n",
        "    if n_ext == 1:\n",
        "        axes_flat = [axes_r2h]\n",
        "    else:\n",
        "        axes_flat = axes_r2h.flatten() if hasattr(axes_r2h, 'flatten') else [axes_r2h]\n",
        "\n",
        "    for idx, r in enumerate(ext_results):\n",
        "        if idx >= len(axes_flat):\n",
        "            break\n",
        "        ax = axes_flat[idx]\n",
        "        vals = list(r.extended.stock_r2_values.values())\n",
        "        ax.hist(vals, bins=20, color=\"#2196F3\", edgecolor=\"white\", alpha=0.8)\n",
        "        ax.axvline(x=0, color=\"red\", linewidth=1, linestyle=\"--\")\n",
        "        ax.axvline(x=np.median(vals), color=\"green\", linewidth=1, linestyle=\"-\",\n",
        "                   label=\"median=%.3f\" % np.median(vals))\n",
        "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n",
        "        ax.set_xlabel(\"R2\", fontsize=8)\n",
        "        ax.legend(fontsize=6)\n",
        "\n",
        "    for idx in range(n_ext, len(axes_flat)):\n",
        "        axes_flat[idx].set_visible(False)\n",
        "\n",
        "    fig_r2h.suptitle(\"Per-Stock R2 Distribution\", fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"per_stock_r2_histogram.png\"),\n",
        "                dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Per-stock R2 histogram saved.\")\n",
        "else:\n",
        "    print(\"No per-stock R2 data for visualization.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DumFoiwisBVJ"
      },
      "source": [
        "# --- Visualization 2: Pred vs Actual Scatter ---\n",
        "scatter_results = [r for r in results if r.fold_predictions]\n",
        "\n",
        "if scatter_results:\n",
        "    n_sc = len(scatter_results)\n",
        "    ncols = min(5, n_sc)\n",
        "    nrows = (n_sc + ncols - 1) // ncols\n",
        "    fig_sc, axes_sc = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n",
        "    if n_sc == 1:\n",
        "        axes_flat = [axes_sc]\n",
        "    else:\n",
        "        axes_flat = axes_sc.flatten() if hasattr(axes_sc, 'flatten') else [axes_sc]\n",
        "\n",
        "    for idx, r in enumerate(scatter_results):\n",
        "        if idx >= len(axes_flat):\n",
        "            break\n",
        "        ax = axes_flat[idx]\n",
        "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n",
        "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n",
        "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n",
        "        p, a = all_p[valid], all_a[valid]\n",
        "\n",
        "        if len(p) > 5000:\n",
        "            idx_sub = np.random.choice(len(p), 5000, replace=False)\n",
        "            p_plot, a_plot = p[idx_sub], a[idx_sub]\n",
        "        else:\n",
        "            p_plot, a_plot = p, a\n",
        "\n",
        "        ax.scatter(p_plot, a_plot, alpha=0.1, s=3, color=\"#2196F3\")\n",
        "\n",
        "        if len(p) > 10:\n",
        "            coef = np.polyfit(p, a, 1)\n",
        "            x_line = np.linspace(p.min(), p.max(), 50)\n",
        "            ax.plot(x_line, coef[0] * x_line + coef[1], \"r-\", linewidth=1.5,\n",
        "                    label=\"slope=%.2f\" % coef[0])\n",
        "\n",
        "        ax.set_title(\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon), fontsize=9)\n",
        "        ax.set_xlabel(\"Predicted\", fontsize=8)\n",
        "        ax.set_ylabel(\"Actual\", fontsize=8)\n",
        "        ax.legend(fontsize=7)\n",
        "\n",
        "    for idx in range(n_sc, len(axes_flat)):\n",
        "        axes_flat[idx].set_visible(False)\n",
        "\n",
        "    fig_sc.suptitle(\"Prediction vs Actual\", fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"pred_vs_actual_scatter.png\"),\n",
        "                dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Pred vs actual scatter saved.\")\n",
        "else:\n",
        "    print(\"No fold predictions for scatter plot.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCSWU-D8sBVJ"
      },
      "source": [
        "# --- Visualization 3: Calibration Slope Bar Chart ---\n",
        "cal_results = [r for r in results if r.extended is not None]\n",
        "\n",
        "if cal_results:\n",
        "    fig_cal, ax_cal = plt.subplots(figsize=(10, max(4, len(cal_results) * 0.4)))\n",
        "    labels_cal = [\"%s/%s\" % (r.name.split(\"_\")[0], r.horizon) for r in cal_results]\n",
        "    slopes = [r.extended.calib_slope for r in cal_results]\n",
        "    colors_cal = [\"#4CAF50\" if abs(s - 1.0) < 0.3 else \"#FFC107\" if abs(s - 1.0) < 0.6\n",
        "                  else \"#F44336\" for s in slopes]\n",
        "\n",
        "    y_pos = range(len(cal_results))\n",
        "    ax_cal.barh(y_pos, slopes, color=colors_cal, edgecolor=\"white\")\n",
        "    ax_cal.set_yticks(y_pos)\n",
        "    ax_cal.set_yticklabels(labels_cal, fontsize=8)\n",
        "    ax_cal.axvline(x=1.0, color=\"blue\", linewidth=2, linestyle=\"--\", label=\"Ideal (slope=1.0)\")\n",
        "    ax_cal.set_xlabel(\"Calibration Slope\")\n",
        "    ax_cal.set_title(\"Calibration: Pred vs Actual Regression Slope\", fontweight=\"bold\")\n",
        "    ax_cal.legend(fontsize=9)\n",
        "    ax_cal.invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"calibration_slope.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Calibration slope chart saved.\")\n",
        "else:\n",
        "    print(\"No calibration data for visualization.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZme929sBVJ"
      },
      "source": [
        "# --- Visualization 4: Rolling R2 (126-sample window) ---\n",
        "rolling_results = [r for r in results if r.fold_predictions]\n",
        "\n",
        "if rolling_results:\n",
        "    fig_roll, ax_roll = plt.subplots(figsize=(14, 6))\n",
        "    window = 126\n",
        "\n",
        "    for r in rolling_results:\n",
        "        all_p = np.concatenate([fp.predictions for fp in r.fold_predictions])\n",
        "        all_a = np.concatenate([fp.actuals for fp in r.fold_predictions])\n",
        "        valid = ~(np.isnan(all_p) | np.isnan(all_a))\n",
        "        p, a = all_p[valid], all_a[valid]\n",
        "\n",
        "        if len(p) < window + 10:\n",
        "            continue\n",
        "\n",
        "        rolling_r2 = []\n",
        "        for i in range(window, len(p)):\n",
        "            p_w = p[i - window:i]\n",
        "            a_w = a[i - window:i]\n",
        "            ss_res = np.sum((p_w - a_w) ** 2)\n",
        "            ss_tot = np.sum((a_w - np.mean(a_w)) ** 2)\n",
        "            r2 = 1.0 - ss_res / ss_tot if ss_tot > 1e-10 else 0.0\n",
        "            rolling_r2.append(r2)\n",
        "\n",
        "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n",
        "        ax_roll.plot(rolling_r2, label=label, alpha=0.7, linewidth=1)\n",
        "\n",
        "    ax_roll.axhline(y=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "    ax_roll.set_xlabel(\"Sample Index\")\n",
        "    ax_roll.set_ylabel(\"Rolling R2 (window=%d)\" % window)\n",
        "    ax_roll.set_title(\"Rolling R2 Across Walk-Forward Test Periods\", fontweight=\"bold\")\n",
        "    ax_roll.legend(fontsize=7, ncol=3, loc=\"upper right\")\n",
        "    ax_roll.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"rolling_r2.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Rolling R2 chart saved.\")\n",
        "else:\n",
        "    print(\"No fold predictions for rolling R2.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cckn_ofsBVJ"
      },
      "source": [
        "# --- Visualization 5: Cumulative PnL Curves ---\n",
        "pnl_results = [r for r in results\n",
        "               if r.extended is not None\n",
        "               and r.extended.lo_equity is not None\n",
        "               and len(r.extended.lo_equity) > 1]\n",
        "\n",
        "if pnl_results:\n",
        "    fig_pnl, (ax_lo, ax_ls) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    for r in pnl_results:\n",
        "        label = \"%s/%s\" % (r.name.split(\"_\")[0], r.horizon)\n",
        "        ax_lo.plot(r.extended.lo_equity, label=label, alpha=0.7, linewidth=1)\n",
        "        if r.extended.ls_equity is not None and len(r.extended.ls_equity) > 1:\n",
        "            ax_ls.plot(r.extended.ls_equity, label=label, alpha=0.7, linewidth=1)\n",
        "\n",
        "    ax_lo.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "    ax_lo.set_xlabel(\"Trading Day\")\n",
        "    ax_lo.set_ylabel(\"Equity\")\n",
        "    ax_lo.set_title(\"Long-Only Cumulative PnL\", fontweight=\"bold\")\n",
        "    ax_lo.legend(fontsize=6, ncol=2)\n",
        "    ax_lo.grid(alpha=0.3)\n",
        "\n",
        "    ax_ls.axhline(y=1.0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "    ax_ls.set_xlabel(\"Trading Day\")\n",
        "    ax_ls.set_ylabel(\"Equity\")\n",
        "    ax_ls.set_title(\"Long-Short (20/20) Cumulative PnL\", fontweight=\"bold\")\n",
        "    ax_ls.legend(fontsize=6, ncol=2)\n",
        "    ax_ls.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(ARTIFACT_DIR, \"cumulative_pnl.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(\"Cumulative PnL curves saved.\")\n",
        "else:\n",
        "    print(\"No equity curve data for PnL visualization.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XinyUSQesBVJ"
      },
      "source": [
        "## 7. Diagnostic Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RQ0LvNJsBVJ"
      },
      "source": [
        "# Save full benchmark results to JSON\n",
        "save_path = save_benchmark_results(\n",
        "    results,\n",
        "    path=os.path.join(ARTIFACT_DIR, \"strategy_benchmark_results.json\"),\n",
        ")\n",
        "print(\"Results saved to: %s\" % save_path)\n",
        "\n",
        "# Print per-strategy detail\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DETAILED RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "for r in results:\n",
        "    print(\"\\n--- %s / %s [%s] ---\" % (r.name, r.horizon, r.status))\n",
        "    print(\"  IC: %.4f +/- %.4f  ICIR: %.2f\" % (r.ic_mean, r.ic_std, r.icir))\n",
        "    print(\"  Sharpe: %.2f  MaxDD: %.4f\" % (r.sharpe, r.max_drawdown))\n",
        "    print(\"  Overfit: %.3f  Composite: %.4f\" % (r.overfit_score, r.composite))\n",
        "    print(\"  Prod IC: %.4f  Params: %d  Time: %.1fs\" % (\n",
        "        r.prod_ic, r.param_count, r.train_time))\n",
        "    if r.fold_metrics:\n",
        "        fold_ics = [f.ic for f in r.fold_metrics]\n",
        "        print(\"  Fold ICs: %s\" % [round(x, 4) for x in fold_ics])\n",
        "    if r.extended:\n",
        "        e = r.extended\n",
        "        print(\"  R2: %.4f  Hit%%: %.1f%%  Cal.Slope: %.3f\" % (\n",
        "            e.r_squared, e.hit_ratio * 100, e.calib_slope))\n",
        "        print(\"  L/O Sharpe: %.2f  L/S Sharpe: %.2f\" % (e.lo_sharpe, e.ls_sharpe))\n",
        "    if r.gate_stats:\n",
        "        print(\"  Gate: mean=%.3f std=%.3f\" % (\n",
        "            r.gate_stats.get(\"gate_mean\", 0), r.gate_stats.get(\"gate_std\", 0)))\n",
        "    if r.ensemble_weights:\n",
        "        w = r.ensemble_weights\n",
        "        print(\"  Ensemble: lstm=%.3f nlp=%.3f intercept=%.4f\" % (\n",
        "            w.get(\"lstm\", 0), w.get(\"nlp\", 0), w.get(\"intercept\", 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rCfYVyfsBVJ"
      },
      "source": [
        "## 8. Experimental Integrity Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hmPxPyBsBVJ"
      },
      "source": [
        "warnings = run_integrity_checks(results)\n",
        "\n",
        "if warnings:\n",
        "    print(\"INTEGRITY WARNINGS (%d):\" % len(warnings))\n",
        "    for w in warnings:\n",
        "        print(\"  [!] %s\" % w)\n",
        "else:\n",
        "    print(\"All integrity checks passed.\")\n",
        "\n",
        "# Additional checks\n",
        "print(\"\\nConsistency Checks:\")\n",
        "\n",
        "for h in sorted(set(r.horizon for r in results)):\n",
        "    fold_counts = [len(r.fold_metrics) for r in results if r.horizon == h]\n",
        "    if len(set(fold_counts)) > 1:\n",
        "        print(\"  [!] Inconsistent fold counts at %s: %s\" % (h, fold_counts))\n",
        "    else:\n",
        "        print(\"  [OK] %s: %d folds for all strategies\" % (h, fold_counts[0] if fold_counts else 0))\n",
        "\n",
        "for r in results:\n",
        "    if r.param_count > CONFIG[\"max_params\"]:\n",
        "        print(\"  [!] %s: %d params > %d limit\" % (r.name, r.param_count, CONFIG[\"max_params\"]))\n",
        "\n",
        "print(\"\\nIntegrity check complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ltX_KEjsBVJ"
      },
      "source": [
        "## Summary & Decision\n",
        "\n",
        "This benchmark answers:\n",
        "\n",
        "1. **Does sentiment add incremental alpha?** Compare A vs C/E\n",
        "2. **Is hybrid destructive or additive?** Compare A vs E/E1/E2\n",
        "3. **Is ensemble safer than fusion?** Compare C vs E\n",
        "4. **Cross-attention vs additive fusion?** Compare E1 vs E2\n",
        "5. **Transformer vs LSTM?** Compare G vs A\n",
        "6. **Trees vs neural networks?** Compare H/I vs A\n",
        "7. **Which structure survives production retrain?** Check Prod IC column\n",
        "8. **Statistical significance?** DM test p-values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5FzOs9osBVJ"
      },
      "source": [
        "# Extended decision summary\n",
        "print(\"=\" * 60)\n",
        "print(\"PRICE PREDICTION SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Best by extended metrics\n",
        "ext_results_all = [r for r in results if r.extended is not None]\n",
        "if ext_results_all:\n",
        "    best_r2 = max(ext_results_all, key=lambda r: r.extended.mean_stock_r2)\n",
        "    print(\"\\nBest by Mean Stock R2: %s/%s (%.4f)\" % (\n",
        "        best_r2.name, best_r2.horizon, best_r2.extended.mean_stock_r2))\n",
        "\n",
        "    best_hit = max(ext_results_all, key=lambda r: r.extended.hit_ratio)\n",
        "    print(\"Best by Directional Accuracy: %s/%s (%.1f%%)\" % (\n",
        "        best_hit.name, best_hit.horizon, best_hit.extended.hit_ratio * 100))\n",
        "\n",
        "    best_cal = min(ext_results_all, key=lambda r: abs(r.extended.calib_slope - 1.0))\n",
        "    print(\"Best Calibration (slope closest to 1): %s/%s (%.3f)\" % (\n",
        "        best_cal.name, best_cal.horizon, best_cal.extended.calib_slope))\n",
        "\n",
        "    best_lo = max(ext_results_all, key=lambda r: r.extended.lo_sharpe)\n",
        "    print(\"Highest Sharpe (L/O): %s/%s (%.2f)\" % (\n",
        "        best_lo.name, best_lo.horizon, best_lo.extended.lo_sharpe))\n",
        "\n",
        "    best_ls = max(ext_results_all, key=lambda r: r.extended.ls_sharpe)\n",
        "    print(\"Highest Sharpe (L/S): %s/%s (%.2f)\" % (\n",
        "        best_ls.name, best_ls.horizon, best_ls.extended.ls_sharpe))\n",
        "\n",
        "# DM significance vs baseline\n",
        "if dm_results:\n",
        "    baseline_name = \"A_LSTM_Baseline\"\n",
        "    sig_improvements = [dm for dm in dm_results\n",
        "                        if dm.p_value < 0.05\n",
        "                        and (dm.strategy_a == baseline_name or dm.strategy_b == baseline_name)\n",
        "                        and dm.better != baseline_name]\n",
        "    if sig_improvements:\n",
        "        print(\"\\nDM test: significant improvements over baseline:\")\n",
        "        for dm in sig_improvements:\n",
        "            print(\"  %s beats %s at %s (p=%.4f)\" % (\n",
        "                dm.better, baseline_name, dm.horizon, dm.p_value))\n",
        "    else:\n",
        "        print(\"\\nDM test: no strategy significantly beats baseline (p<0.05)\")\n",
        "\n",
        "# Key comparisons\n",
        "print(\"\\n--- Key Comparisons ---\")\n",
        "\n",
        "# Sentiment alpha\n",
        "a_21 = [r for r in results if r.name.startswith(\"A_\") and r.horizon == \"21D\"]\n",
        "c_21 = [r for r in results if r.name.startswith(\"C_\") and r.horizon == \"21D\"]\n",
        "e_21 = [r for r in results if r.name.startswith(\"E_\") and r.horizon == \"21D\"]\n",
        "if a_21 and c_21:\n",
        "    delta = c_21[0].ic_mean - a_21[0].ic_mean\n",
        "    verdict = \"YES (+%.4f IC)\" % delta if delta > 0.005 else \"NO (delta=%.4f)\" % delta\n",
        "    print(\"1. Sentiment adds alpha? %s\" % verdict)\n",
        "\n",
        "# Hybrid vs baseline\n",
        "if a_21 and e_21:\n",
        "    delta = e_21[0].ic_mean - a_21[0].ic_mean\n",
        "    verdict = \"ADDITIVE (+%.4f)\" % delta if delta > 0 else \"DESTRUCTIVE (%.4f)\" % delta\n",
        "    print(\"2. Hybrid vs LSTM? %s\" % verdict)\n",
        "\n",
        "# Cross-attention vs additive\n",
        "e1_21 = [r for r in results if r.name.startswith(\"E1\") and r.horizon == \"21D\"]\n",
        "e2_21 = [r for r in results if r.name.startswith(\"E2\") and r.horizon == \"21D\"]\n",
        "if e1_21 and e2_21:\n",
        "    if e1_21[0].ic_mean > e2_21[0].ic_mean:\n",
        "        print(\"3. Cross-attn vs Additive? CROSS-ATTN (IC %.4f vs %.4f)\" % (\n",
        "            e1_21[0].ic_mean, e2_21[0].ic_mean))\n",
        "    else:\n",
        "        print(\"3. Cross-attn vs Additive? ADDITIVE (IC %.4f vs %.4f)\" % (\n",
        "            e2_21[0].ic_mean, e1_21[0].ic_mean))\n",
        "\n",
        "# Transformer vs LSTM\n",
        "g_21 = [r for r in results if r.name.startswith(\"G_\") and r.horizon == \"21D\"]\n",
        "if a_21 and g_21:\n",
        "    delta = g_21[0].ic_mean - a_21[0].ic_mean\n",
        "    verdict = \"TRANSFORMER (+%.4f)\" % delta if delta > 0 else \"LSTM (%.4f)\" % delta\n",
        "    print(\"4. Transformer vs LSTM? %s\" % verdict)\n",
        "\n",
        "# Trees vs neural\n",
        "h_21 = [r for r in results if r.name.startswith(\"H_\") and r.horizon == \"21D\"]\n",
        "i_21 = [r for r in results if r.name.startswith(\"I_\") and r.horizon == \"21D\"]\n",
        "if a_21 and h_21 and i_21:\n",
        "    best_tree = max([h_21[0], i_21[0]], key=lambda r: r.ic_mean)\n",
        "    delta = best_tree.ic_mean - a_21[0].ic_mean\n",
        "    verdict = \"TREES (+%.4f)\" % delta if delta > 0 else \"NEURAL (%.4f)\" % delta\n",
        "    print(\"5. Trees vs Neural? %s (best tree: %s)\" % (verdict, best_tree.name))\n",
        "\n",
        "# Production survival\n",
        "print(\"\\n--- Production Survival ---\")\n",
        "for r in results:\n",
        "    if r.ic_mean > 0 and r.prod_ic > 0:\n",
        "        ratio = r.prod_ic / r.ic_mean if r.ic_mean > 1e-8 else 0\n",
        "        survived = \"SURVIVED\" if ratio >= 0.9 else \"DEGRADED\"\n",
        "        print(\"  %s/%s: WF IC=%.4f -> Prod IC=%.4f (%.0f%%) [%s]\" % (\n",
        "            r.name, r.horizon, r.ic_mean, r.prod_ic, ratio * 100, survived))\n",
        "\n",
        "# Final recommendation\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "passing = [r for r in results if r.status == \"PASS\"]\n",
        "if passing:\n",
        "    best = passing[0]\n",
        "    print(\"RECOMMENDATION: Deploy %s\" % best.name)\n",
        "    print(\"  Composite: %.4f  IC: %.4f  Prod IC: %.4f\" % (\n",
        "        best.composite, best.ic_mean, best.prod_ic))\n",
        "    if best.extended:\n",
        "        print(\"  R2: %.4f  Hit%%: %.1f%%  L/S Sharpe: %.2f\" % (\n",
        "            best.extended.r_squared, best.extended.hit_ratio * 100,\n",
        "            best.extended.ls_sharpe))\n",
        "else:\n",
        "    warning_results = [r for r in results if r.status == \"WARN\"]\n",
        "    if warning_results:\n",
        "        print(\"RECOMMENDATION: Cautiously deploy %s (WARN status)\" % warning_results[0].name)\n",
        "    else:\n",
        "        print(\"RECOMMENDATION: No viable strategy. Review data/features.\")\n",
        "print(\"=\" * 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Per-Market Performance Analysis\n",
        "\n",
        "Break down strategy performance by market (US vs KOSPI vs KOSDAQ) to identify\n",
        "market-specific alpha and cross-market generalization."
      ],
      "metadata": {
        "id": "Sp2wdQtRsBVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Per-market R2 breakdown using fold predictions\n",
        "def _classify_market(ticker):\n",
        "    t = ticker.upper()\n",
        "    if t.endswith(\".KS\"):\n",
        "        return \"KOSPI\"\n",
        "    elif t.endswith(\".KQ\"):\n",
        "        return \"KOSDAQ\"\n",
        "    return \"US\"\n",
        "\n",
        "market_perf_rows = []\n",
        "for r in results:\n",
        "    if r.extended is None or not r.extended.stock_r2_values:\n",
        "        continue\n",
        "    # Group stock R2 by market\n",
        "    market_r2s = {}\n",
        "    for ticker, r2_val in r.extended.stock_r2_values.items():\n",
        "        mkt = _classify_market(ticker)\n",
        "        if mkt not in market_r2s:\n",
        "            market_r2s[mkt] = []\n",
        "        market_r2s[mkt].append(r2_val)\n",
        "\n",
        "    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n",
        "        vals = market_r2s.get(mkt, [])\n",
        "        if not vals:\n",
        "            continue\n",
        "        market_perf_rows.append({\n",
        "            \"Strategy\": r.name.split(\"_\")[0],\n",
        "            \"Horizon\": r.horizon,\n",
        "            \"Market\": mkt,\n",
        "            \"N Stocks\": len(vals),\n",
        "            \"Mean R2\": round(np.mean(vals), 4),\n",
        "            \"Median R2\": round(np.median(vals), 4),\n",
        "            \"% Positive\": round(sum(1 for v in vals if v > 0) / len(vals) * 100, 1),\n",
        "        })\n",
        "\n",
        "if market_perf_rows:\n",
        "    df_mkt = pd.DataFrame(market_perf_rows)\n",
        "    print(\"=== Per-Market R2 Breakdown ===\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n",
        "        sub = df_mkt[df_mkt[\"Market\"] == mkt]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "        print(\"\\n--- %s ---\" % mkt)\n",
        "        display(sub.drop(columns=[\"Market\"]).reset_index(drop=True))\n",
        "\n",
        "    # Best strategy per market\n",
        "    print(\"\\n=== Best Strategy per Market (by Mean R2) ===\")\n",
        "    for mkt in [\"US\", \"KOSPI\", \"KOSDAQ\"]:\n",
        "        sub = df_mkt[df_mkt[\"Market\"] == mkt]\n",
        "        if sub.empty:\n",
        "            print(\"  %s: No data\" % mkt)\n",
        "            continue\n",
        "        best_idx = sub[\"Mean R2\"].idxmax()\n",
        "        best = sub.loc[best_idx]\n",
        "        print(\"  %s: %s/%s (Mean R2=%.4f, %d stocks)\" % (\n",
        "            mkt, best[\"Strategy\"], best[\"Horizon\"],\n",
        "            best[\"Mean R2\"], best[\"N Stocks\"]))\n",
        "else:\n",
        "    print(\"No per-market data (need extended metrics with stock R2 values).\")"
      ],
      "metadata": {
        "id": "S9KinlkLsBVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Per-market R2 comparison visualization\n",
        "if market_perf_rows:\n",
        "    df_mkt = pd.DataFrame(market_perf_rows)\n",
        "    markets_present = [m for m in [\"US\", \"KOSPI\", \"KOSDAQ\"] if m in df_mkt[\"Market\"].values]\n",
        "    n_markets = len(markets_present)\n",
        "\n",
        "    if n_markets > 0:\n",
        "        fig_mkt, axes_mkt = plt.subplots(1, n_markets, figsize=(7 * n_markets, 6))\n",
        "        if n_markets == 1:\n",
        "            axes_mkt = [axes_mkt]\n",
        "\n",
        "        for ax, mkt in zip(axes_mkt, markets_present):\n",
        "            sub = df_mkt[df_mkt[\"Market\"] == mkt].copy()\n",
        "            sub[\"Label\"] = sub[\"Strategy\"] + \"/\" + sub[\"Horizon\"]\n",
        "            sub = sub.sort_values(\"Mean R2\", ascending=True)\n",
        "\n",
        "            colors_mkt = [\"#4CAF50\" if v > 0 else \"#F44336\" for v in sub[\"Mean R2\"]]\n",
        "            ax.barh(sub[\"Label\"], sub[\"Mean R2\"], color=colors_mkt, edgecolor=\"white\")\n",
        "            ax.axvline(x=0, color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
        "            ax.set_xlabel(\"Mean Stock R2\")\n",
        "            ax.set_title(\"%s (%d stocks)\" % (mkt, sub[\"N Stocks\"].iloc[0]), fontweight=\"bold\")\n",
        "            ax.tick_params(axis=\"y\", labelsize=7)\n",
        "\n",
        "        plt.suptitle(\"Per-Market Strategy Performance\", fontsize=14, fontweight=\"bold\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(ARTIFACT_DIR, \"per_market_performance.png\"),\n",
        "                    dpi=150, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "        print(\"Per-market performance chart saved.\")\n",
        "\n",
        "    # Cross-market generalization heatmap\n",
        "    pivot = df_mkt.pivot_table(\n",
        "        values=\"Mean R2\", index=[\"Strategy\", \"Horizon\"],\n",
        "        columns=\"Market\", aggfunc=\"first\")\n",
        "    if pivot.shape[1] >= 2:\n",
        "        fig_gen, ax_gen = plt.subplots(figsize=(8, max(4, len(pivot) * 0.35)))\n",
        "        im = ax_gen.imshow(pivot.values, cmap=\"RdYlGn\", aspect=\"auto\",\n",
        "                           vmin=-0.05, vmax=0.1)\n",
        "        ax_gen.set_xticks(range(pivot.shape[1]))\n",
        "        ax_gen.set_xticklabels(pivot.columns, fontsize=10)\n",
        "        ax_gen.set_yticks(range(pivot.shape[0]))\n",
        "        ylabels = [\"%s/%s\" % (s, h) for s, h in pivot.index]\n",
        "        ax_gen.set_yticklabels(ylabels, fontsize=7)\n",
        "        ax_gen.set_title(\"Cross-Market Generalization (Mean Stock R2)\", fontweight=\"bold\")\n",
        "\n",
        "        for i in range(pivot.shape[0]):\n",
        "            for j in range(pivot.shape[1]):\n",
        "                val = pivot.values[i, j]\n",
        "                if not np.isnan(val):\n",
        "                    ax_gen.text(j, i, \"%.3f\" % val, ha=\"center\", va=\"center\",\n",
        "                                fontsize=7, color=\"white\" if val > 0.05 else \"black\")\n",
        "\n",
        "        plt.colorbar(im, ax=ax_gen, shrink=0.7, label=\"Mean R2\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(ARTIFACT_DIR, \"cross_market_heatmap.png\"),\n",
        "                    dpi=150, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "        print(\"Cross-market heatmap saved.\")"
      ],
      "metadata": {
        "id": "MuPXF0wDsBVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}