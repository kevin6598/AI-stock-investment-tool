{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumable Quantitative Research Pipeline\n",
    "\n",
    "A fully automated, restart-safe research pipeline for systematic strategy discovery.\n",
    "\n",
    "**Pipeline Steps:**\n",
    "1. Data Layer — Load & clean OHLCV data\n",
    "2. Feature Engine — Momentum, volatility, regime features + cross-sectional deciles\n",
    "3. Candidate Generator — Decile conditions, decision trees, logistic rank model\n",
    "4. Edge Evaluation — Win rate, Sharpe, lift, expectancy per candidate\n",
    "5. Walk-Forward Validation — Rolling 3Y train / 1Y test\n",
    "6. Overfitting Control — Stability filtering, bootstrap CI\n",
    "7. Strategy Scoring — Composite rank and final selection\n",
    "8. Output — Ranked table, equity curves, portfolio combination\n",
    "\n",
    "**Key Feature:** Every step saves progress to Google Drive. If the runtime disconnects, re-run the notebook and it resumes from the last completed step.\n",
    "\n",
    "| Runtime | Est. Time (100 tickers, 10Y) |\n",
    "|---------|------------------------------|\n",
    "| T4 GPU  | ~60-90 min                   |\n",
    "| CPU     | ~120-180 min                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q yfinance pandas numpy scikit-learn scipy matplotlib pyarrow joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import logging\n",
    "import warnings\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Optional, Dict, Tuple\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    \"\"\"Central configuration for the entire pipeline.\"\"\"\n",
    "    # --- Data ---\n",
    "    tickers: List[str] = field(default_factory=lambda: [\n",
    "        # US Large Cap\n",
    "        \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "        \"JPM\", \"JNJ\", \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"BAC\", \"NFLX\",\n",
    "        \"ADBE\", \"CRM\", \"XOM\", \"VZ\", \"KO\", \"INTC\", \"PEP\", \"ABT\", \"CSCO\",\n",
    "        \"COST\", \"MRK\", \"WMT\", \"AVGO\", \"ACN\", \"CVX\", \"NKE\", \"LLY\", \"MCD\",\n",
    "        \"QCOM\", \"UPS\", \"BMY\", \"LIN\", \"NEE\", \"ORCL\", \"RTX\", \"HON\", \"TXN\",\n",
    "        \"AMD\", \"PYPL\", \"CMCSA\", \"TMO\", \"DHR\",\n",
    "    ])\n",
    "    market_ticker: str = \"SPY\"\n",
    "    data_period: str = \"10y\"\n",
    "\n",
    "    # --- Features ---\n",
    "    momentum_windows: List[int] = field(default_factory=lambda: [5, 20, 60, 120])\n",
    "    volatility_windows: List[int] = field(default_factory=lambda: [20, 60])\n",
    "    regime_window: int = 60\n",
    "    n_decile_bins: int = 10\n",
    "\n",
    "    # --- Candidates ---\n",
    "    max_combo_features: int = 2\n",
    "    min_sample_size: int = 300\n",
    "    candidate_batch_size: int = 500\n",
    "    # Decision tree\n",
    "    tree_max_depth: int = 2\n",
    "    tree_min_samples_leaf: int = 500\n",
    "    n_trees: int = 20\n",
    "    # Logistic rank\n",
    "    logistic_top_pct: float = 0.20\n",
    "\n",
    "    # --- Forward return ---\n",
    "    forward_days: int = 21  # 1-month forward return\n",
    "\n",
    "    # --- Walk-Forward ---\n",
    "    wf_train_years: int = 3\n",
    "    wf_test_months: int = 12\n",
    "    wf_step_months: int = 6\n",
    "    wf_embargo_days: int = 5\n",
    "\n",
    "    # --- Overfitting ---\n",
    "    min_stability: float = 0.5\n",
    "    min_sharpe: float = 0.3\n",
    "    min_win_rate: float = 0.50\n",
    "    bootstrap_n: int = 1000\n",
    "    bootstrap_ci: float = 0.95\n",
    "\n",
    "    # --- Scoring ---\n",
    "    w_stability: float = 0.30\n",
    "    w_sharpe: float = 0.30\n",
    "    w_lift: float = 0.20\n",
    "    w_sample: float = 0.20\n",
    "\n",
    "    # --- Paths ---\n",
    "    drive_root: str = \"/content/drive/MyDrive/quant_pipeline\"\n",
    "\n",
    "    # --- Random seed ---\n",
    "    seed: int = 42\n",
    "\n",
    "    @property\n",
    "    def data_dir(self): return os.path.join(self.drive_root, \"data\")\n",
    "    @property\n",
    "    def features_dir(self): return os.path.join(self.drive_root, \"features\")\n",
    "    @property\n",
    "    def candidates_dir(self): return os.path.join(self.drive_root, \"candidates\")\n",
    "    @property\n",
    "    def evaluation_dir(self): return os.path.join(self.drive_root, \"evaluation\")\n",
    "    @property\n",
    "    def walkforward_dir(self): return os.path.join(self.drive_root, \"walkforward\")\n",
    "    @property\n",
    "    def logs_dir(self): return os.path.join(self.drive_root, \"logs\")\n",
    "    @property\n",
    "    def state_path(self): return os.path.join(self.drive_root, \"state.json\")\n",
    "\n",
    "\n",
    "CFG = PipelineConfig()\n",
    "print(\"Config created. Drive root: %s\" % CFG.drive_root)\n",
    "print(\"Tickers: %d | Period: %s | Forward: %dD\" % (\n",
    "    len(CFG.tickers), CFG.data_period, CFG.forward_days))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persistence & Resume System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "DRIVE_MOUNTED = False\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', timeout_ms=60000)\n",
    "    DRIVE_MOUNTED = True\n",
    "    print(\"Google Drive mounted.\")\n",
    "except Exception as e:\n",
    "    print(\"Drive mount failed: %s\" % str(e)[:80])\n",
    "    print(\"Using local storage (data lost on disconnect).\")\n",
    "    CFG.drive_root = \"/content/quant_pipeline\"\n",
    "\n",
    "# Create all directories\n",
    "for d in [CFG.data_dir, CFG.features_dir, CFG.candidates_dir,\n",
    "          CFG.evaluation_dir, CFG.walkforward_dir, CFG.logs_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "print(\"Directories ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressTracker:\n",
    "    \"\"\"JSON-based checkpoint system for resumable execution.\"\"\"\n",
    "\n",
    "    def __init__(self, state_path: str):\n",
    "        self.state_path = state_path\n",
    "        self.state = self._load()\n",
    "\n",
    "    def _load(self) -> dict:\n",
    "        if os.path.exists(self.state_path):\n",
    "            with open(self.state_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        return {\"completed_steps\": {}, \"metadata\": {}}\n",
    "\n",
    "    def _save(self):\n",
    "        with open(self.state_path, 'w') as f:\n",
    "            json.dump(self.state, f, indent=2, default=str)\n",
    "\n",
    "    def is_completed(self, step_name: str) -> bool:\n",
    "        return self.state[\"completed_steps\"].get(step_name, False)\n",
    "\n",
    "    def mark_completed(self, step_name: str, metadata: dict = None):\n",
    "        self.state[\"completed_steps\"][step_name] = True\n",
    "        if metadata:\n",
    "            self.state[\"metadata\"][step_name] = metadata\n",
    "        self._save()\n",
    "        print(\"  [CHECKPOINT] %s completed.\" % step_name)\n",
    "\n",
    "    def get_metadata(self, step_name: str) -> dict:\n",
    "        return self.state[\"metadata\"].get(step_name, {})\n",
    "\n",
    "    def reset(self, step_name: str = None):\n",
    "        if step_name:\n",
    "            self.state[\"completed_steps\"].pop(step_name, None)\n",
    "            self.state[\"metadata\"].pop(step_name, None)\n",
    "        else:\n",
    "            self.state = {\"completed_steps\": {}, \"metadata\": {}}\n",
    "        self._save()\n",
    "\n",
    "    def summary(self):\n",
    "        completed = [k for k, v in self.state[\"completed_steps\"].items() if v]\n",
    "        print(\"=== Progress Summary ===\")\n",
    "        if completed:\n",
    "            for s in completed:\n",
    "                print(\"  [DONE] %s\" % s)\n",
    "        else:\n",
    "            print(\"  No steps completed yet.\")\n",
    "\n",
    "\n",
    "tracker = ProgressTracker(CFG.state_path)\n",
    "tracker.summary()\n",
    "\n",
    "# Uncomment to force re-run from scratch:\n",
    "# tracker.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "import logging\n",
    "\n",
    "log_file = os.path.join(CFG.logs_dir, \"pipeline.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler(log_file, mode='a'),\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"pipeline\")\n",
    "logger.info(\"Pipeline started. Log file: %s\" % log_file)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Layer\n",
    "\n",
    "Downloads OHLCV data via yfinance. Saves cleaned data to `data/processed.parquet`.\n",
    "\n",
    "**Safeguards:**\n",
    "- No lookahead bias (forward returns computed separately)\n",
    "- Proper datetime index\n",
    "- Survivorship bias warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "STEP = \"data_load\"\n",
    "processed_path = os.path.join(CFG.data_dir, \"processed.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s already completed. Loading from cache.\" % STEP)\n",
    "    ohlcv_panel = pd.read_parquet(processed_path)\n",
    "    market_df = pd.read_parquet(os.path.join(CFG.data_dir, \"market.parquet\"))\n",
    "    print(\"Loaded: %s\" % str(ohlcv_panel.shape))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # WARNING: Survivorship bias -- this universe only includes currently listed tickers.\n",
    "    # For production research, use a point-in-time universe with delisted stocks.\n",
    "\n",
    "    all_dfs = []\n",
    "    failed = []\n",
    "    for i, ticker in enumerate(CFG.tickers):\n",
    "        if (i + 1) % 10 == 0 or i == 0:\n",
    "            print(\"  [%d/%d] %s\" % (i + 1, len(CFG.tickers), ticker))\n",
    "        try:\n",
    "            df = yf.download(ticker, period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "            if df.empty or len(df) < 252:\n",
    "                failed.append(ticker)\n",
    "                continue\n",
    "            # Flatten MultiIndex columns if present\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            df = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
    "            df.columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index = df.index.tz_localize(None)\n",
    "            df[\"ticker\"] = ticker\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            failed.append(ticker)\n",
    "            print(\"    FAIL: %s -- %s\" % (ticker, str(e)[:60]))\n",
    "\n",
    "    ohlcv_panel = pd.concat(all_dfs)\n",
    "    ohlcv_panel = ohlcv_panel.set_index([ohlcv_panel.index, \"ticker\"])\n",
    "    ohlcv_panel.index.names = [\"date\", \"ticker\"]\n",
    "    ohlcv_panel = ohlcv_panel.sort_index()\n",
    "\n",
    "    # Market index\n",
    "    market_df = yf.download(CFG.market_ticker, period=CFG.data_period, progress=False, auto_adjust=True)\n",
    "    if isinstance(market_df.columns, pd.MultiIndex):\n",
    "        market_df.columns = market_df.columns.get_level_values(0)\n",
    "    market_df = market_df[[\"Close\"]].copy()\n",
    "    market_df.columns = [\"close\"]\n",
    "    market_df.index = pd.to_datetime(market_df.index)\n",
    "    market_df.index = market_df.index.tz_localize(None)\n",
    "\n",
    "    # Save\n",
    "    ohlcv_panel.to_parquet(processed_path)\n",
    "    market_df.to_parquet(os.path.join(CFG.data_dir, \"market.parquet\"))\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    meta = {\"n_tickers\": len(all_dfs), \"failed\": failed, \"rows\": len(ohlcv_panel), \"time_sec\": elapsed}\n",
    "    tracker.mark_completed(STEP, meta)\n",
    "\n",
    "    print(\"\\nDownloaded: %d/%d tickers in %.0fs\" % (len(all_dfs), len(CFG.tickers), elapsed))\n",
    "    if failed:\n",
    "        print(\"Failed: %s\" % failed)\n",
    "\n",
    "# Summary\n",
    "valid_tickers = ohlcv_panel.index.get_level_values(1).unique().tolist()\n",
    "dates = ohlcv_panel.index.get_level_values(0).unique()\n",
    "print(\"\\nPanel: %s | Tickers: %d\" % (str(ohlcv_panel.shape), len(valid_tickers)))\n",
    "print(\"Date range: %s to %s\" % (dates.min().date(), dates.max().date()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engine\n",
    "\n",
    "Generates momentum, volatility, and regime features, then converts to cross-sectional deciles.\n",
    "\n",
    "Each feature group is saved separately and tracked in `state.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_momentum_features(close_df: pd.DataFrame, windows: list) -> pd.DataFrame:\n",
    "    \"\"\"Compute momentum (return) features for each window.\"\"\"\n",
    "    feats = {}\n",
    "    for w in windows:\n",
    "        feats[\"mom_%dd\" % w] = close_df.pct_change(w)\n",
    "    return pd.DataFrame(feats, index=close_df.index)\n",
    "\n",
    "\n",
    "def compute_volatility_features(close_df: pd.DataFrame, windows: list) -> pd.DataFrame:\n",
    "    \"\"\"Compute volatility features.\"\"\"\n",
    "    daily_ret = close_df.pct_change()\n",
    "    feats = {}\n",
    "    for w in windows:\n",
    "        feats[\"vol_%dd\" % w] = daily_ret.rolling(w).std()\n",
    "    # Volatility change (short / long)\n",
    "    if len(windows) >= 2:\n",
    "        short_w, long_w = windows[0], windows[-1]\n",
    "        short_vol = daily_ret.rolling(short_w).std()\n",
    "        long_vol = daily_ret.rolling(long_w).std()\n",
    "        feats[\"vol_change\"] = short_vol / long_vol.replace(0, np.nan) - 1.0\n",
    "    return pd.DataFrame(feats, index=close_df.index)\n",
    "\n",
    "\n",
    "def compute_regime_features(market_close: pd.Series, regime_window: int) -> pd.DataFrame:\n",
    "    \"\"\"Compute market regime features.\"\"\"\n",
    "    market_ret = market_close.pct_change()\n",
    "    feats = {}\n",
    "    feats[\"market_mom_%dd\" % regime_window] = market_close.pct_change(regime_window)\n",
    "    feats[\"market_vol_%dd\" % regime_window] = market_ret.rolling(regime_window).std()\n",
    "    # Binary regime: 1 = bull (positive momentum + low vol), 0 = bear\n",
    "    mom = feats[\"market_mom_%dd\" % regime_window]\n",
    "    vol = feats[\"market_vol_%dd\" % regime_window]\n",
    "    vol_median = vol.rolling(252, min_periods=60).median()\n",
    "    feats[\"regime_bull\"] = ((mom > 0) & (vol < vol_median)).astype(float)\n",
    "    return pd.DataFrame(feats, index=market_close.index)\n",
    "\n",
    "\n",
    "def compute_market_relative_return(stock_ret: pd.Series, market_ret: pd.Series) -> pd.Series:\n",
    "    \"\"\"Stock return minus market return.\"\"\"\n",
    "    return stock_ret - market_ret\n",
    "\n",
    "\n",
    "def to_cross_sectional_deciles(feature_series: pd.Series, date_index, n_bins: int = 10) -> pd.Series:\n",
    "    \"\"\"Convert a feature to rolling cross-sectional decile ranks (0-9).\"\"\"\n",
    "    def rank_date(group):\n",
    "        valid = group.dropna()\n",
    "        if len(valid) < n_bins:\n",
    "            return pd.Series(np.nan, index=group.index)\n",
    "        ranks = valid.rank(method='first')\n",
    "        deciles = pd.cut(ranks, bins=n_bins, labels=False)\n",
    "        return deciles.reindex(group.index)\n",
    "    return feature_series.groupby(level=date_index).transform(rank_date)\n",
    "\n",
    "\n",
    "print(\"Feature functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"features\"\n",
    "features_path = os.path.join(CFG.features_dir, \"all_features.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s already completed. Loading.\" % STEP)\n",
    "    feature_panel = pd.read_parquet(features_path)\n",
    "    print(\"Loaded features: %s\" % str(feature_panel.shape))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "    all_features = []\n",
    "\n",
    "    # Market returns for relative features & regime\n",
    "    market_close = market_df[\"close\"]\n",
    "    market_ret_20d = market_close.pct_change(20)\n",
    "\n",
    "    # Regime features (date-level, will broadcast to all tickers)\n",
    "    regime_feats = compute_regime_features(market_close, CFG.regime_window)\n",
    "\n",
    "    for ticker in valid_tickers:\n",
    "        try:\n",
    "            tdata = ohlcv_panel.loc[(slice(None), ticker), :].droplevel(1)\n",
    "            close = tdata[\"close\"]\n",
    "\n",
    "            # Momentum\n",
    "            mom = compute_momentum_features(close, CFG.momentum_windows)\n",
    "\n",
    "            # Market-relative return\n",
    "            stock_20d_ret = close.pct_change(20)\n",
    "            mkt_20d_aligned = market_ret_20d.reindex(close.index, method='ffill')\n",
    "            mom[\"market_relative_20d\"] = stock_20d_ret - mkt_20d_aligned\n",
    "\n",
    "            # Volatility\n",
    "            vol = compute_volatility_features(close, CFG.volatility_windows)\n",
    "\n",
    "            # Regime (broadcast market-level to stock dates)\n",
    "            reg = regime_feats.reindex(close.index, method='ffill')\n",
    "\n",
    "            # Forward return (target) -- shifted properly to avoid lookahead\n",
    "            fwd_ret = close.pct_change(CFG.forward_days).shift(-CFG.forward_days)\n",
    "\n",
    "            # Combine\n",
    "            combined = pd.concat([mom, vol, reg], axis=1)\n",
    "            combined[\"fwd_return\"] = fwd_ret\n",
    "            combined[\"ticker\"] = ticker\n",
    "            combined.index.name = \"date\"\n",
    "            all_features.append(combined)\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Feature error for %s: %s\" % (ticker, str(e)[:60]))\n",
    "\n",
    "    feature_panel = pd.concat(all_features)\n",
    "    feature_panel = feature_panel.reset_index().set_index([\"date\", \"ticker\"]).sort_index()\n",
    "\n",
    "    # Drop rows where all features are NaN\n",
    "    feat_cols = [c for c in feature_panel.columns if c != \"fwd_return\"]\n",
    "    feature_panel = feature_panel.dropna(subset=feat_cols, how='all')\n",
    "\n",
    "    print(\"Raw features: %s\" % str(feature_panel.shape))\n",
    "\n",
    "    # Cross-sectional deciles for each feature\n",
    "    logger.info(\"Computing cross-sectional deciles...\")\n",
    "    for col in feat_cols:\n",
    "        decile_col = col + \"_decile\"\n",
    "        feature_panel[decile_col] = to_cross_sectional_deciles(\n",
    "            feature_panel[col], \"date\", CFG.n_decile_bins\n",
    "        )\n",
    "\n",
    "    # Save\n",
    "    feature_panel.to_parquet(features_path)\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\n",
    "        \"n_features\": len(feat_cols),\n",
    "        \"n_rows\": len(feature_panel),\n",
    "        \"time_sec\": elapsed,\n",
    "    })\n",
    "    print(\"Features saved (%.0fs): %s\" % (elapsed, str(feature_panel.shape)))\n",
    "    gc.collect()\n",
    "\n",
    "# List feature columns\n",
    "feat_cols = [c for c in feature_panel.columns if c != \"fwd_return\" and not c.endswith(\"_decile\")]\n",
    "decile_cols = [c for c in feature_panel.columns if c.endswith(\"_decile\")]\n",
    "print(\"\\nRaw features (%d): %s\" % (len(feat_cols), feat_cols))\n",
    "print(\"Decile features (%d): %s\" % (len(decile_cols), decile_cols))\n",
    "print(\"Forward return NaN: %.1f%%\" % (feature_panel[\"fwd_return\"].isna().mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Candidate Generator\n",
    "\n",
    "Three methods:\n",
    "- **A. Decile Conditions** — Single and 2-feature decile combinations\n",
    "- **B. Decision Tree** — Shallow trees (depth=2) generate leaf-based strategies\n",
    "- **C. Logistic Rank** — Top quantile of logistic regression predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4A. Decile Condition Generator ===\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "STEP = \"candidates_decile\"\n",
    "decile_candidates_path = os.path.join(CFG.candidates_dir, \"decile_candidates.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "    decile_candidates = pd.read_parquet(decile_candidates_path)\n",
    "    print(\"Loaded %d decile candidates.\" % len(decile_candidates))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Work with rows that have forward returns\n",
    "    valid_data = feature_panel.dropna(subset=[\"fwd_return\"]).copy()\n",
    "    n_bins = CFG.n_decile_bins\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    # --- Single feature conditions ---\n",
    "    logger.info(\"Generating 1-feature decile conditions...\")\n",
    "    for col in decile_cols:\n",
    "        for decile_val in range(n_bins):\n",
    "            mask = valid_data[col] == decile_val\n",
    "            n_trades = mask.sum()\n",
    "            if n_trades < CFG.min_sample_size:\n",
    "                continue\n",
    "            ret = valid_data.loc[mask, \"fwd_return\"]\n",
    "            candidates.append({\n",
    "                \"strategy_id\": \"%s_d%d\" % (col, decile_val),\n",
    "                \"type\": \"single_decile\",\n",
    "                \"features\": col,\n",
    "                \"condition\": \"== %d\" % decile_val,\n",
    "                \"n_trades\": int(n_trades),\n",
    "                \"mean_return\": float(ret.mean()),\n",
    "                \"win_rate\": float((ret > 0).mean()),\n",
    "            })\n",
    "\n",
    "    logger.info(\"  Single conditions: %d\" % len(candidates))\n",
    "\n",
    "    # --- 2-feature combinations (top & bottom deciles only for efficiency) ---\n",
    "    logger.info(\"Generating 2-feature decile combinations...\")\n",
    "    extreme_deciles = [0, 1, n_bins - 2, n_bins - 1]  # top/bottom 2 deciles\n",
    "    n_before = len(candidates)\n",
    "    batch_count = 0\n",
    "\n",
    "    for col_a, col_b in combinations(decile_cols, 2):\n",
    "        for da in extreme_deciles:\n",
    "            for db in extreme_deciles:\n",
    "                mask = (valid_data[col_a] == da) & (valid_data[col_b] == db)\n",
    "                n_trades = mask.sum()\n",
    "                if n_trades < CFG.min_sample_size:\n",
    "                    continue\n",
    "                ret = valid_data.loc[mask, \"fwd_return\"]\n",
    "                candidates.append({\n",
    "                    \"strategy_id\": \"%s_d%d_AND_%s_d%d\" % (col_a, da, col_b, db),\n",
    "                    \"type\": \"combo_decile\",\n",
    "                    \"features\": \"%s, %s\" % (col_a, col_b),\n",
    "                    \"condition\": \"%s==%d AND %s==%d\" % (col_a, da, col_b, db),\n",
    "                    \"n_trades\": int(n_trades),\n",
    "                    \"mean_return\": float(ret.mean()),\n",
    "                    \"win_rate\": float((ret > 0).mean()),\n",
    "                })\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count % 50 == 0:\n",
    "            print(\"    Processed %d feature pairs, %d candidates so far\" % (\n",
    "                batch_count, len(candidates)))\n",
    "\n",
    "    logger.info(\"  Combo conditions: %d\" % (len(candidates) - n_before))\n",
    "    logger.info(\"  Total decile candidates: %d\" % len(candidates))\n",
    "\n",
    "    decile_candidates = pd.DataFrame(candidates)\n",
    "    decile_candidates.to_parquet(decile_candidates_path)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_candidates\": len(candidates), \"time_sec\": elapsed})\n",
    "    print(\"Decile candidates: %d (%.0fs)\" % (len(candidates), elapsed))\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nDecile candidates: %d\" % len(decile_candidates))\n",
    "if len(decile_candidates) > 0:\n",
    "    print(decile_candidates[[\"type\", \"n_trades\", \"mean_return\", \"win_rate\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4B. Decision Tree Generator ===\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "\n",
    "STEP = \"candidates_tree\"\n",
    "tree_candidates_path = os.path.join(CFG.candidates_dir, \"tree_candidates.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "    tree_candidates = pd.read_parquet(tree_candidates_path)\n",
    "    print(\"Loaded %d tree candidates.\" % len(tree_candidates))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "\n",
    "    valid_data = feature_panel.dropna(subset=[\"fwd_return\"] + feat_cols).copy()\n",
    "    X = valid_data[feat_cols].values.astype(np.float32)\n",
    "    # Binary target: positive return = 1\n",
    "    y = (valid_data[\"fwd_return\"].values > 0).astype(int)\n",
    "\n",
    "    tree_strats = []\n",
    "\n",
    "    for tree_idx in range(CFG.n_trees):\n",
    "        # Random feature subset for diversity\n",
    "        n_feat_subset = max(3, len(feat_cols) // 2)\n",
    "        feat_subset_idx = np.random.choice(len(feat_cols), n_feat_subset, replace=False)\n",
    "        feat_subset_names = [feat_cols[i] for i in feat_subset_idx]\n",
    "        X_sub = X[:, feat_subset_idx]\n",
    "\n",
    "        # Sample rows for diversity\n",
    "        sample_idx = np.random.choice(len(X_sub), min(len(X_sub), 50000), replace=False)\n",
    "\n",
    "        tree = DecisionTreeClassifier(\n",
    "            max_depth=CFG.tree_max_depth,\n",
    "            min_samples_leaf=CFG.tree_min_samples_leaf,\n",
    "            random_state=CFG.seed + tree_idx,\n",
    "        )\n",
    "        tree.fit(X_sub[sample_idx], y[sample_idx])\n",
    "\n",
    "        # Each leaf = candidate strategy\n",
    "        leaf_ids = tree.apply(X_sub)\n",
    "        unique_leaves = np.unique(leaf_ids)\n",
    "\n",
    "        for leaf in unique_leaves:\n",
    "            leaf_mask_full = tree.apply(X) == leaf  # apply on full data\n",
    "            # Actually we need to apply on the subset columns\n",
    "            leaf_mask_full = tree.apply(X[:, feat_subset_idx]) == leaf\n",
    "            n_trades = leaf_mask_full.sum()\n",
    "            if n_trades < CFG.min_sample_size:\n",
    "                continue\n",
    "            ret = valid_data[\"fwd_return\"].values[leaf_mask_full]\n",
    "            tree_strats.append({\n",
    "                \"strategy_id\": \"tree_%d_leaf_%d\" % (tree_idx, leaf),\n",
    "                \"type\": \"decision_tree\",\n",
    "                \"features\": \", \".join(feat_subset_names[:5]),\n",
    "                \"condition\": \"tree_%d/leaf_%d\" % (tree_idx, leaf),\n",
    "                \"n_trades\": int(n_trades),\n",
    "                \"mean_return\": float(np.nanmean(ret)),\n",
    "                \"win_rate\": float((ret > 0).mean()),\n",
    "            })\n",
    "\n",
    "        # Save tree model\n",
    "        tree_path = os.path.join(CFG.candidates_dir, \"tree_%d.pkl\" % tree_idx)\n",
    "        with open(tree_path, 'wb') as f:\n",
    "            pickle.dump({\"tree\": tree, \"features\": feat_subset_names}, f)\n",
    "\n",
    "        if (tree_idx + 1) % 5 == 0:\n",
    "            print(\"  Tree %d/%d done, %d candidates so far\" % (\n",
    "                tree_idx + 1, CFG.n_trees, len(tree_strats)))\n",
    "\n",
    "    tree_candidates = pd.DataFrame(tree_strats)\n",
    "    tree_candidates.to_parquet(tree_candidates_path)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_candidates\": len(tree_strats), \"time_sec\": elapsed})\n",
    "    print(\"Tree candidates: %d (%.0fs)\" % (len(tree_strats), elapsed))\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nTree candidates: %d\" % len(tree_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === 4C. Logistic Rank Model ===\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\n\nSTEP = \"candidates_logistic\"\nlogistic_candidates_path = os.path.join(CFG.candidates_dir, \"logistic_candidates.parquet\")\n\nif tracker.is_completed(STEP):\n    logger.info(\"[SKIP] %s\" % STEP)\n    logistic_candidates = pd.read_parquet(logistic_candidates_path)\n    print(\"Loaded %d logistic candidates.\" % len(logistic_candidates))\nelse:\n    logger.info(\"[RUN] %s\" % STEP)\n    t0 = time.time()\n\n    valid_data = feature_panel.dropna(subset=[\"fwd_return\"] + feat_cols).copy()\n    X = valid_data[feat_cols].values.astype(np.float32)\n    y = (valid_data[\"fwd_return\"].values > 0).astype(int)\n\n    # Standardize\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    # Train/test split by time (80/20)\n    dates_sorted = valid_data.index.get_level_values(0)\n    split_date = dates_sorted.unique()[int(len(dates_sorted.unique()) * 0.8)]\n    train_mask = dates_sorted <= split_date\n    test_mask = dates_sorted > split_date\n\n    lr = LogisticRegression(\n        max_iter=1000, C=0.1, penalty='l2',\n        random_state=CFG.seed, solver='lbfgs',\n    )\n    lr.fit(X_scaled[train_mask], y[train_mask])\n\n    # Predict probability\n    proba = lr.predict_proba(X_scaled)[:, 1]\n\n    # Strategy = top 20% by predicted probability\n    threshold = np.percentile(proba, (1 - CFG.logistic_top_pct) * 100)\n    top_mask = proba >= threshold\n\n    # Also create quintile-based strategies\n    logistic_strats = []\n    quintile_edges = np.percentile(proba, [0, 20, 40, 60, 80, 100])\n\n    for q in range(5):\n        q_mask = (proba >= quintile_edges[q]) & (proba < quintile_edges[q + 1])\n        if q == 4:  # include right edge for top quintile\n            q_mask = proba >= quintile_edges[q]\n        n_trades = q_mask.sum()\n        if n_trades < CFG.min_sample_size:\n            continue\n        ret = valid_data[\"fwd_return\"].values[q_mask]\n        logistic_strats.append({\n            \"strategy_id\": \"logistic_q%d\" % (q + 1),\n            \"type\": \"logistic_rank\",\n            \"features\": \"all_features\",\n            \"condition\": \"logistic_quintile_%d\" % (q + 1),\n            \"n_trades\": int(n_trades),\n            \"mean_return\": float(np.nanmean(ret)),\n            \"win_rate\": float((ret > 0).mean()),\n        })\n\n    # Save model + quintile edges for consistent reconstruction across resume\n    model_path = os.path.join(CFG.candidates_dir, \"logistic_model.pkl\")\n    with open(model_path, 'wb') as f:\n        pickle.dump({\"model\": lr, \"scaler\": scaler, \"features\": feat_cols,\n                     \"quintile_edges\": quintile_edges.tolist()}, f)\n\n    logistic_candidates = pd.DataFrame(logistic_strats)\n    logistic_candidates.to_parquet(logistic_candidates_path)\n\n    elapsed = time.time() - t0\n    tracker.mark_completed(STEP, {\"n_candidates\": len(logistic_strats), \"time_sec\": elapsed})\n    print(\"Logistic candidates: %d (%.0fs)\" % (len(logistic_strats), elapsed))\n    gc.collect()\n\nprint(\"\\nLogistic candidates: %d\" % len(logistic_candidates))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Merge all candidates ===\n",
    "\n",
    "all_candidates = pd.concat([\n",
    "    decile_candidates, tree_candidates, logistic_candidates\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"=== All Candidates ===\")\n",
    "print(\"Total: %d\" % len(all_candidates))\n",
    "print(\"\\nBy type:\")\n",
    "print(all_candidates[\"type\"].value_counts())\n",
    "print(\"\\nTop 10 by mean return:\")\n",
    "print(all_candidates.nlargest(10, \"mean_return\")[\n",
    "    [\"strategy_id\", \"type\", \"n_trades\", \"mean_return\", \"win_rate\"]\n",
    "].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Edge Evaluation Engine\n",
    "\n",
    "For each candidate, compute:\n",
    "- Win rate, mean return, Sharpe ratio, max drawdown\n",
    "- Lift (vs unconditional mean), expectancy, sample size\n",
    "\n",
    "Results saved incrementally — already-evaluated strategies are skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_strategy_edge(returns: np.ndarray) -> dict:\n",
    "    \"\"\"Compute edge metrics for a strategy's return series.\"\"\"\n",
    "    returns = returns[~np.isnan(returns)]\n",
    "    n = len(returns)\n",
    "    if n < 30:\n",
    "        return None\n",
    "\n",
    "    mean_ret = float(np.mean(returns))\n",
    "    std_ret = float(np.std(returns, ddof=1))\n",
    "    win_rate = float((returns > 0).mean())\n",
    "    avg_win = float(np.mean(returns[returns > 0])) if (returns > 0).any() else 0.0\n",
    "    avg_loss = float(np.mean(returns[returns <= 0])) if (returns <= 0).any() else 0.0\n",
    "\n",
    "    # Sharpe (annualized, assuming ~21 trading days per period)\n",
    "    sharpe = (mean_ret / std_ret * np.sqrt(252 / max(1, 21))) if std_ret > 1e-8 else 0.0\n",
    "\n",
    "    # Max drawdown from cumulative returns\n",
    "    cum = np.cumsum(returns)\n",
    "    running_max = np.maximum.accumulate(cum)\n",
    "    drawdowns = cum - running_max\n",
    "    max_dd = float(np.min(drawdowns)) if len(drawdowns) > 0 else 0.0\n",
    "\n",
    "    # Expectancy: avg_win * win_rate + avg_loss * (1 - win_rate)\n",
    "    expectancy = avg_win * win_rate + avg_loss * (1 - win_rate)\n",
    "\n",
    "    return {\n",
    "        \"n_trades\": n,\n",
    "        \"mean_return\": mean_ret,\n",
    "        \"std_return\": std_ret,\n",
    "        \"win_rate\": win_rate,\n",
    "        \"avg_win\": avg_win,\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"sharpe\": float(sharpe),\n",
    "        \"max_drawdown\": max_dd,\n",
    "        \"expectancy\": float(expectancy),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Edge evaluation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "STEP = \"edge_evaluation\"\neval_path = os.path.join(CFG.evaluation_dir, \"edge_results.parquet\")\n\n# Columns expected in edge_results (for empty DataFrame guard)\n_EDGE_COLS = [\"strategy_id\", \"type\", \"n_trades\", \"mean_return\", \"std_return\",\n              \"win_rate\", \"avg_win\", \"avg_loss\", \"sharpe\", \"max_drawdown\",\n              \"expectancy\", \"lift\"]\n\nif tracker.is_completed(STEP):\n    logger.info(\"[SKIP] %s\" % STEP)\n    edge_results = pd.read_parquet(eval_path)\n    print(\"Loaded %d edge results.\" % len(edge_results))\nelse:\n    logger.info(\"[RUN] %s\" % STEP)\n    t0 = time.time()\n\n    # BUG-C FIX: Use same filtering as candidate generation (drop NaN in feat_cols too)\n    valid_data = feature_panel.dropna(subset=[\"fwd_return\"] + feat_cols).copy()\n    unconditional_mean = valid_data[\"fwd_return\"].mean()\n    logger.info(\"Unconditional mean return: %.6f\" % unconditional_mean)\n\n    # Check for already-evaluated (incremental resume)\n    existing_ids = set()\n    if os.path.exists(eval_path):\n        existing_df = pd.read_parquet(eval_path)\n        existing_ids = set(existing_df[\"strategy_id\"].values)\n        eval_rows = existing_df.to_dict('records')\n        logger.info(\"Resuming: %d already evaluated.\" % len(existing_ids))\n    else:\n        eval_rows = []\n\n    to_evaluate = all_candidates[~all_candidates[\"strategy_id\"].isin(existing_ids)]\n    logger.info(\"Evaluating %d new candidates...\" % len(to_evaluate))\n\n    for idx, (_, row) in enumerate(to_evaluate.iterrows()):\n        sid = row[\"strategy_id\"]\n        stype = row[\"type\"]\n\n        # Reconstruct strategy mask based on type\n        try:\n            if stype == \"single_decile\":\n                col = row[\"features\"]\n                decile_val = int(row[\"condition\"].split(\"== \")[1])\n                mask = valid_data[col] == decile_val\n            elif stype == \"combo_decile\":\n                parts = row[\"condition\"].split(\" AND \")\n                col_a, val_a = parts[0].split(\"==\")\n                col_b, val_b = parts[1].split(\"==\")\n                mask = (valid_data[col_a.strip()] == int(val_a)) & (valid_data[col_b.strip()] == int(val_b))\n            elif stype == \"decision_tree\":\n                tree_idx_str = sid.split(\"_\")[1]\n                leaf_id = int(sid.split(\"_\")[3])\n                tree_path = os.path.join(CFG.candidates_dir, \"tree_%s.pkl\" % tree_idx_str)\n                with open(tree_path, 'rb') as f:\n                    tree_data = pickle.load(f)\n                # BUG-D FIX: Validate all tree features exist\n                missing = [fn for fn in tree_data[\"features\"] if fn not in feat_cols]\n                if missing:\n                    logger.warning(\"Tree %s missing features: %s\" % (sid, missing))\n                    continue\n                tree_feat_idx = [feat_cols.index(fn) for fn in tree_data[\"features\"]]\n                X_full = valid_data[feat_cols].values[:, tree_feat_idx].astype(np.float32)\n                np.nan_to_num(X_full, copy=False)\n                # BUG-A FIX: Wrap numpy bool array in pd.Series for safe .loc indexing\n                mask = pd.Series(tree_data[\"tree\"].apply(X_full) == leaf_id, index=valid_data.index)\n            elif stype == \"logistic_rank\":\n                model_path = os.path.join(CFG.candidates_dir, \"logistic_model.pkl\")\n                with open(model_path, 'rb') as f:\n                    lr_data = pickle.load(f)\n                X_full = valid_data[feat_cols].values.astype(np.float32)\n                np.nan_to_num(X_full, copy=False)\n                X_scaled = lr_data[\"scaler\"].transform(X_full)\n                proba = lr_data[\"model\"].predict_proba(X_scaled)[:, 1]\n                q_num = int(sid.split(\"_q\")[1])\n                # BUG-B FIX: Use saved quintile edges instead of recomputing\n                edges = lr_data.get(\"quintile_edges\",\n                                    np.percentile(proba, [0, 20, 40, 60, 80, 100]).tolist())\n                if q_num == 5:\n                    mask = pd.Series(proba >= edges[q_num - 1], index=valid_data.index)\n                else:\n                    mask = pd.Series((proba >= edges[q_num - 1]) & (proba < edges[q_num]),\n                                     index=valid_data.index)\n            else:\n                continue\n\n            returns = valid_data.loc[mask, \"fwd_return\"].values\n            edge = evaluate_strategy_edge(returns)\n            if edge is None:\n                continue\n\n            # Compute lift\n            edge[\"lift\"] = edge[\"mean_return\"] - unconditional_mean\n            edge[\"strategy_id\"] = sid\n            edge[\"type\"] = stype\n            eval_rows.append(edge)\n\n        except Exception as e:\n            logger.warning(\"Eval error for %s: %s\" % (sid, str(e)[:60]))\n\n        # Incremental save every 200 strategies\n        if (idx + 1) % 200 == 0:\n            pd.DataFrame(eval_rows).to_parquet(eval_path)\n            print(\"  Evaluated %d/%d, saved checkpoint\" % (idx + 1, len(to_evaluate)))\n\n    # BUG-F FIX: Ensure DataFrame always has expected columns\n    if eval_rows:\n        edge_results = pd.DataFrame(eval_rows)\n    else:\n        edge_results = pd.DataFrame(columns=_EDGE_COLS)\n    edge_results.to_parquet(eval_path)\n\n    elapsed = time.time() - t0\n    tracker.mark_completed(STEP, {\"n_evaluated\": len(edge_results), \"time_sec\": elapsed})\n    print(\"Edge evaluation: %d strategies (%.0fs)\" % (len(edge_results), elapsed))\n    gc.collect()\n\nprint(\"\\n=== Edge Results Summary ===\")\nprint(\"Total evaluated: %d\" % len(edge_results))\nif len(edge_results) > 0:\n    print(edge_results[[\"mean_return\", \"win_rate\", \"sharpe\", \"lift\", \"expectancy\"]].describe())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Walk-Forward Validation\n",
    "\n",
    "Rolling walk-forward: 3-year train, 1-year test, slide by 6 months.\n",
    "\n",
    "Pre-filters to top candidates by in-sample edge, then validates out-of-sample.\n",
    "Resumes from last unfinished fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from dateutil.relativedelta import relativedelta\n\nSTEP = \"walk_forward\"\nwf_results_path = os.path.join(CFG.walkforward_dir, \"wf_results.parquet\")\n\n# Columns expected in wf_results (for empty DataFrame guard)\n_WF_COLS = [\"strategy_id\", \"fold_idx\", \"n_trades\", \"mean_return\", \"std_return\",\n            \"win_rate\", \"avg_win\", \"avg_loss\", \"sharpe\", \"max_drawdown\",\n            \"expectancy\", \"test_start\", \"test_end\"]\n\nif tracker.is_completed(STEP):\n    logger.info(\"[SKIP] %s\" % STEP)\n    wf_results = pd.read_parquet(wf_results_path)\n    print(\"Loaded %d walk-forward results.\" % len(wf_results))\nelse:\n    logger.info(\"[RUN] %s\" % STEP)\n    t0 = time.time()\n\n    # Pre-filter: top candidates by edge (sharpe > 0.2 or top 200)\n    if len(edge_results) > 200:\n        top_candidates = edge_results.nlargest(200, \"sharpe\")[\"strategy_id\"].tolist()\n    else:\n        top_candidates = edge_results[edge_results[\"sharpe\"] > 0.2][\"strategy_id\"].tolist()\n        if len(top_candidates) < 20:\n            top_candidates = edge_results.nlargest(min(50, len(edge_results)), \"sharpe\")[\"strategy_id\"].tolist()\n\n    logger.info(\"Walk-forward on %d candidates\" % len(top_candidates))\n\n    valid_data = feature_panel.dropna(subset=[\"fwd_return\"]).copy()\n    all_dates = valid_data.index.get_level_values(0).unique().sort_values()\n    min_date = all_dates.min()\n    max_date = all_dates.max()\n\n    # Generate fold boundaries\n    folds = []\n    train_start = min_date\n    while True:\n        train_end = train_start + relativedelta(years=CFG.wf_train_years)\n        test_start = train_end + pd.Timedelta(days=CFG.wf_embargo_days)\n        test_end = test_start + relativedelta(months=CFG.wf_test_months)\n        if test_end > max_date:\n            break\n        folds.append((train_start, train_end, test_start, test_end))\n        train_start += relativedelta(months=CFG.wf_step_months)\n\n    logger.info(\"Folds: %d\" % len(folds))\n    for i, (ts, te, vs, ve) in enumerate(folds):\n        print(\"  Fold %d: train [%s, %s] test [%s, %s]\" % (\n            i, ts.date(), te.date(), vs.date(), ve.date()))\n\n    # Load existing partial results for resume\n    wf_rows = []\n    completed_keys = set()\n    partial_path = os.path.join(CFG.walkforward_dir, \"wf_partial.parquet\")\n    if os.path.exists(partial_path):\n        partial_df = pd.read_parquet(partial_path)\n        wf_rows = partial_df.to_dict('records')\n        completed_keys = set(zip(partial_df[\"strategy_id\"], partial_df[\"fold_idx\"].astype(int)))\n        logger.info(\"Resuming: %d fold results loaded.\" % len(completed_keys))\n\n    # BUG-E FIX: build_mask as a standalone function with explicit sid parameter\n    def build_mask(data, stype, cand_row, sid):\n        \"\"\"Build strategy boolean mask on given data slice.\"\"\"\n        if stype == \"single_decile\":\n            col = cand_row[\"features\"]\n            dv = int(cand_row[\"condition\"].split(\"== \")[1])\n            return data[col] == dv\n        elif stype == \"combo_decile\":\n            parts = cand_row[\"condition\"].split(\" AND \")\n            ca, va = parts[0].split(\"==\")\n            cb, vb = parts[1].split(\"==\")\n            return (data[ca.strip()] == int(va)) & (data[cb.strip()] == int(vb))\n        elif stype == \"decision_tree\":\n            tree_num = sid.split(\"_\")[1]\n            leaf_id = int(sid.split(\"_\")[3])\n            tp = os.path.join(CFG.candidates_dir, \"tree_%s.pkl\" % tree_num)\n            with open(tp, 'rb') as f:\n                td = pickle.load(f)\n            # BUG-D FIX: Validate tree features\n            missing = [fn for fn in td[\"features\"] if fn not in feat_cols]\n            if missing:\n                raise ValueError(\"Tree features missing: %s\" % missing)\n            fi = [feat_cols.index(fn) for fn in td[\"features\"]]\n            X = data[feat_cols].values[:, fi].astype(np.float32)\n            np.nan_to_num(X, copy=False)\n            return pd.Series(td[\"tree\"].apply(X) == leaf_id, index=data.index)\n        elif stype == \"logistic_rank\":\n            mp = os.path.join(CFG.candidates_dir, \"logistic_model.pkl\")\n            with open(mp, 'rb') as f:\n                ld = pickle.load(f)\n            X = data[feat_cols].values.astype(np.float32)\n            np.nan_to_num(X, copy=False)\n            proba = ld[\"model\"].predict_proba(ld[\"scaler\"].transform(X))[:, 1]\n            q_num = int(sid.split(\"_q\")[1])\n            # BUG-B FIX: Use saved quintile edges for consistency\n            edges = ld.get(\"quintile_edges\",\n                           np.percentile(proba, [0, 20, 40, 60, 80, 100]).tolist())\n            if q_num == 5:\n                return pd.Series(proba >= edges[q_num - 1], index=data.index)\n            return pd.Series((proba >= edges[q_num - 1]) & (proba < edges[q_num]), index=data.index)\n        return pd.Series(False, index=data.index)\n\n    total_evals = len(top_candidates) * len(folds)\n    done_count = len(completed_keys)\n\n    for fold_idx, (train_start, train_end, test_start, test_end) in enumerate(folds):\n        dates_idx = valid_data.index.get_level_values(0)\n        train_mask = (dates_idx >= train_start) & (dates_idx < train_end)\n        test_mask = (dates_idx >= test_start) & (dates_idx < test_end)\n        train_data = valid_data[train_mask]\n        test_data = valid_data[test_mask]\n\n        for sid in top_candidates:\n            if (sid, fold_idx) in completed_keys:\n                continue\n\n            try:\n                cand_row = all_candidates[all_candidates[\"strategy_id\"] == sid].iloc[0]\n                stype = cand_row[\"type\"]\n\n                test_mask_strat = build_mask(test_data, stype, cand_row, sid)\n                test_returns = test_data.loc[test_mask_strat, \"fwd_return\"].values\n\n                if len(test_returns) < 20:\n                    continue\n\n                edge = evaluate_strategy_edge(test_returns)\n                if edge is None:\n                    continue\n\n                edge[\"strategy_id\"] = sid\n                edge[\"fold_idx\"] = fold_idx\n                edge[\"test_start\"] = str(test_start.date())\n                edge[\"test_end\"] = str(test_end.date())\n                wf_rows.append(edge)\n\n            except Exception as e:\n                pass  # silently skip errors\n\n            done_count += 1\n\n        # Checkpoint after each fold\n        if wf_rows:\n            pd.DataFrame(wf_rows).to_parquet(partial_path)\n        print(\"  Fold %d complete. Progress: %d/%d\" % (fold_idx, done_count, total_evals))\n\n    # BUG-F FIX: Ensure DataFrame always has expected columns\n    if wf_rows:\n        wf_results = pd.DataFrame(wf_rows)\n    else:\n        wf_results = pd.DataFrame(columns=_WF_COLS)\n    wf_results.to_parquet(wf_results_path)\n\n    # Clean up partial file\n    if os.path.exists(partial_path):\n        os.remove(partial_path)\n\n    elapsed = time.time() - t0\n    tracker.mark_completed(STEP, {\"n_results\": len(wf_results), \"n_folds\": len(folds), \"time_sec\": elapsed})\n    print(\"Walk-forward: %d results across %d folds (%.0fs)\" % (len(wf_results), len(folds), elapsed))\n    gc.collect()\n\nprint(\"\\nWalk-forward results: %d\" % len(wf_results))\nif len(wf_results) > 0:\n    n_strategies_wf = wf_results[\"strategy_id\"].nunique()\n    n_folds_wf = wf_results[\"fold_idx\"].nunique()\n    print(\"Strategies: %d | Folds: %d\" % (n_strategies_wf, n_folds_wf))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Overfitting Control\n",
    "\n",
    "Filters strategies using:\n",
    "- Stability score across folds (reject if performance sign flips)\n",
    "- Sharpe consistency (reject if unstable)\n",
    "- Win rate collapse detection\n",
    "- Bootstrap confidence interval for win rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"overfitting_control\"\n",
    "filtered_path = os.path.join(CFG.evaluation_dir, \"filtered_strategies.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "    filtered_strategies = pd.read_parquet(filtered_path)\n",
    "    print(\"Loaded %d filtered strategies.\" % len(filtered_strategies))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "    t0 = time.time()\n",
    "\n",
    "    if len(wf_results) == 0:\n",
    "        print(\"No walk-forward results. Skipping.\")\n",
    "        filtered_strategies = pd.DataFrame()\n",
    "    else:\n",
    "        # Aggregate per strategy across folds\n",
    "        strategy_stats = []\n",
    "        for sid, group in wf_results.groupby(\"strategy_id\"):\n",
    "            n_folds = len(group)\n",
    "            if n_folds < 2:\n",
    "                continue\n",
    "\n",
    "            fold_returns = group[\"mean_return\"].values\n",
    "            fold_sharpes = group[\"sharpe\"].values\n",
    "            fold_win_rates = group[\"win_rate\"].values\n",
    "\n",
    "            # Stability: fraction of folds with positive return\n",
    "            stability = float((fold_returns > 0).mean())\n",
    "\n",
    "            # Sharpe stats\n",
    "            mean_sharpe = float(np.mean(fold_sharpes))\n",
    "            sharpe_std = float(np.std(fold_sharpes, ddof=1))\n",
    "\n",
    "            # Win rate stats\n",
    "            mean_win_rate = float(np.mean(fold_win_rates))\n",
    "            min_win_rate = float(np.min(fold_win_rates))\n",
    "\n",
    "            # Sign flip detection\n",
    "            sign_flips = int(np.sum(np.diff(np.sign(fold_returns)) != 0))\n",
    "\n",
    "            # Bootstrap CI for win rate (using all fold trade counts)\n",
    "            all_n_trades = group[\"n_trades\"].values\n",
    "            total_trades = int(all_n_trades.sum())\n",
    "            total_wins = int((fold_win_rates * all_n_trades).sum())\n",
    "\n",
    "            bootstrap_wins = np.random.binomial(total_trades, total_wins / max(1, total_trades), CFG.bootstrap_n)\n",
    "            bootstrap_wr = bootstrap_wins / total_trades\n",
    "            ci_low = float(np.percentile(bootstrap_wr, (1 - CFG.bootstrap_ci) / 2 * 100))\n",
    "            ci_high = float(np.percentile(bootstrap_wr, (1 + CFG.bootstrap_ci) / 2 * 100))\n",
    "\n",
    "            strategy_stats.append({\n",
    "                \"strategy_id\": sid,\n",
    "                \"n_folds\": n_folds,\n",
    "                \"stability\": stability,\n",
    "                \"mean_sharpe\": mean_sharpe,\n",
    "                \"sharpe_std\": sharpe_std,\n",
    "                \"mean_win_rate\": mean_win_rate,\n",
    "                \"min_win_rate\": min_win_rate,\n",
    "                \"sign_flips\": sign_flips,\n",
    "                \"total_trades\": total_trades,\n",
    "                \"wr_ci_low\": ci_low,\n",
    "                \"wr_ci_high\": ci_high,\n",
    "                \"mean_return\": float(np.mean(fold_returns)),\n",
    "                \"mean_lift\": float(np.mean(fold_returns)),  # approx\n",
    "            })\n",
    "\n",
    "        stats_df = pd.DataFrame(strategy_stats)\n",
    "\n",
    "        # Apply filters\n",
    "        n_before = len(stats_df)\n",
    "        mask = (\n",
    "            (stats_df[\"stability\"] >= CFG.min_stability) &\n",
    "            (stats_df[\"mean_sharpe\"] >= CFG.min_sharpe) &\n",
    "            (stats_df[\"mean_win_rate\"] >= CFG.min_win_rate) &\n",
    "            (stats_df[\"wr_ci_low\"] >= 0.48)  # CI lower bound must be near 50%\n",
    "        )\n",
    "        filtered_strategies = stats_df[mask].copy()\n",
    "        filtered_strategies = filtered_strategies.sort_values(\"mean_sharpe\", ascending=False)\n",
    "\n",
    "        print(\"\\nOverfitting filters:\")\n",
    "        print(\"  Before: %d strategies\" % n_before)\n",
    "        print(\"  Stability >= %.1f: %d pass\" % (\n",
    "            CFG.min_stability, (stats_df[\"stability\"] >= CFG.min_stability).sum()))\n",
    "        print(\"  Sharpe >= %.1f: %d pass\" % (\n",
    "            CFG.min_sharpe, (stats_df[\"mean_sharpe\"] >= CFG.min_sharpe).sum()))\n",
    "        print(\"  Win rate >= %.2f: %d pass\" % (\n",
    "            CFG.min_win_rate, (stats_df[\"mean_win_rate\"] >= CFG.min_win_rate).sum()))\n",
    "        print(\"  CI lower >= 0.48: %d pass\" % ((stats_df[\"wr_ci_low\"] >= 0.48).sum()))\n",
    "        print(\"  After ALL filters: %d strategies\" % len(filtered_strategies))\n",
    "\n",
    "        filtered_strategies.to_parquet(filtered_path)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    tracker.mark_completed(STEP, {\"n_filtered\": len(filtered_strategies), \"time_sec\": elapsed})\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nFiltered strategies: %d\" % len(filtered_strategies))\n",
    "if len(filtered_strategies) > 0:\n",
    "    print(filtered_strategies[\n",
    "        [\"strategy_id\", \"stability\", \"mean_sharpe\", \"mean_win_rate\", \"wr_ci_low\", \"total_trades\"]\n",
    "    ].head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Strategy Scoring Engine\n",
    "\n",
    "Final composite score:\n",
    "```\n",
    "Score = 0.3 * Stability + 0.3 * Sharpe_norm + 0.2 * Lift_norm + 0.2 * SampleScore\n",
    "```\n",
    "\n",
    "Includes optional strategy clustering to remove redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = \"scoring\"\n",
    "scored_path = os.path.join(CFG.evaluation_dir, \"scored_strategies.parquet\")\n",
    "\n",
    "if tracker.is_completed(STEP):\n",
    "    logger.info(\"[SKIP] %s\" % STEP)\n",
    "    scored_strategies = pd.read_parquet(scored_path)\n",
    "    print(\"Loaded %d scored strategies.\" % len(scored_strategies))\n",
    "else:\n",
    "    logger.info(\"[RUN] %s\" % STEP)\n",
    "\n",
    "    if len(filtered_strategies) == 0:\n",
    "        print(\"No strategies passed filters. Check parameters or data.\")\n",
    "        scored_strategies = pd.DataFrame()\n",
    "    else:\n",
    "        df = filtered_strategies.copy()\n",
    "\n",
    "        # Normalize each component to [0, 1]\n",
    "        def normalize_col(s):\n",
    "            r = s.max() - s.min()\n",
    "            return (s - s.min()) / r if r > 1e-8 else pd.Series(0.5, index=s.index)\n",
    "\n",
    "        df[\"stability_norm\"] = normalize_col(df[\"stability\"])\n",
    "        df[\"sharpe_norm\"] = normalize_col(df[\"mean_sharpe\"])\n",
    "\n",
    "        # Lift: merge from edge_results\n",
    "        lift_map = edge_results.set_index(\"strategy_id\")[\"lift\"].to_dict()\n",
    "        df[\"lift\"] = df[\"strategy_id\"].map(lift_map).fillna(0)\n",
    "        df[\"lift_norm\"] = normalize_col(df[\"lift\"])\n",
    "\n",
    "        # Sample size score: log-scaled\n",
    "        df[\"sample_score\"] = normalize_col(np.log1p(df[\"total_trades\"]))\n",
    "\n",
    "        # Composite score\n",
    "        df[\"composite_score\"] = (\n",
    "            CFG.w_stability * df[\"stability_norm\"]\n",
    "            + CFG.w_sharpe * df[\"sharpe_norm\"]\n",
    "            + CFG.w_lift * df[\"lift_norm\"]\n",
    "            + CFG.w_sample * df[\"sample_score\"]\n",
    "        )\n",
    "\n",
    "        scored_strategies = df.sort_values(\"composite_score\", ascending=False).reset_index(drop=True)\n",
    "        scored_strategies[\"rank\"] = range(1, len(scored_strategies) + 1)\n",
    "        scored_strategies.to_parquet(scored_path)\n",
    "\n",
    "    tracker.mark_completed(STEP, {\"n_scored\": len(scored_strategies)})\n",
    "\n",
    "print(\"\\n=== RANKED STRATEGIES ===\")\n",
    "if len(scored_strategies) > 0:\n",
    "    display_cols = [\"rank\", \"strategy_id\", \"composite_score\", \"stability\",\n",
    "                    \"mean_sharpe\", \"mean_win_rate\", \"lift\", \"total_trades\"]\n",
    "    print(scored_strategies[display_cols].head(30).to_string(index=False))\n",
    "else:\n",
    "    print(\"No strategies to rank.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b. Strategy Clustering (Redundancy Removal)\n",
    "\n",
    "Cluster similar strategies and keep only the best per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "if len(scored_strategies) > 5:\n",
    "    logger.info(\"Clustering strategies for redundancy removal...\")\n",
    "\n",
    "    # Build return correlation matrix using walk-forward fold returns\n",
    "    pivot = wf_results.pivot_table(\n",
    "        values=\"mean_return\", index=\"fold_idx\", columns=\"strategy_id\", aggfunc=\"first\"\n",
    "    )\n",
    "    # Only include scored strategies\n",
    "    scored_ids = scored_strategies[\"strategy_id\"].tolist()\n",
    "    pivot = pivot[[c for c in pivot.columns if c in scored_ids]].dropna(axis=1, how='all')\n",
    "    pivot = pivot.fillna(0)\n",
    "\n",
    "    if pivot.shape[1] >= 5:\n",
    "        corr = pivot.corr().values\n",
    "        distance = 1 - np.abs(corr)\n",
    "        np.fill_diagonal(distance, 0)\n",
    "        distance = np.maximum(distance, 0)  # ensure non-negative\n",
    "\n",
    "        n_clusters = max(3, min(10, len(pivot.columns) // 3))\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=n_clusters, metric='precomputed', linkage='average'\n",
    "        )\n",
    "        labels = clustering.fit_predict(distance)\n",
    "\n",
    "        cluster_map = dict(zip(pivot.columns, labels))\n",
    "        scored_strategies[\"cluster\"] = scored_strategies[\"strategy_id\"].map(cluster_map)\n",
    "\n",
    "        # Best per cluster\n",
    "        best_per_cluster = scored_strategies.dropna(subset=[\"cluster\"]).groupby(\"cluster\").first()\n",
    "        deduped_ids = best_per_cluster[\"strategy_id\"].tolist()\n",
    "\n",
    "        print(\"\\n=== Clustered Strategies ===\")\n",
    "        print(\"Clusters: %d\" % n_clusters)\n",
    "        for c in range(n_clusters):\n",
    "            members = scored_strategies[scored_strategies[\"cluster\"] == c]\n",
    "            best = members.iloc[0][\"strategy_id\"] if len(members) > 0 else \"N/A\"\n",
    "            print(\"  Cluster %d: %d members, best=%s\" % (c, len(members), best))\n",
    "\n",
    "        print(\"\\nDeduplicated strategies: %d (from %d)\" % (len(deduped_ids), len(scored_strategies)))\n",
    "    else:\n",
    "        print(\"Not enough strategies for clustering. Keeping all.\")\n",
    "        deduped_ids = scored_strategies[\"strategy_id\"].tolist()\n",
    "else:\n",
    "    print(\"Fewer than 5 strategies. Skipping clustering.\")\n",
    "    deduped_ids = scored_strategies[\"strategy_id\"].tolist() if len(scored_strategies) > 0 else []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Output\n",
    "\n",
    "- Ranked strategy table\n",
    "- Stability diagnostics\n",
    "- Equity curves of top 5 strategies\n",
    "- Portfolio combination performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "if len(scored_strategies) == 0:\n",
    "    print(\"No strategies to visualize. Pipeline found no viable candidates.\")\n",
    "    print(\"Consider relaxing filter thresholds or adding more data.\")\n",
    "else:\n",
    "    top5 = scored_strategies.head(5)\n",
    "    print(\"=== TOP 5 STRATEGIES ===\")\n",
    "    print(top5[[\"rank\", \"strategy_id\", \"composite_score\", \"stability\",\n",
    "                \"mean_sharpe\", \"mean_win_rate\", \"total_trades\"]].to_string(index=False))\n",
    "\n",
    "    # === Figure: 4-panel dashboard ===\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "    gs = gridspec.GridSpec(2, 2, hspace=0.35, wspace=0.3)\n",
    "\n",
    "    # --- Panel 1: Composite score bar ---\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    top20 = scored_strategies.head(20)\n",
    "    colors = ['#4CAF50' if s >= 0.7 else '#FFC107' if s >= 0.4 else '#F44336'\n",
    "              for s in top20['composite_score']]\n",
    "    ax1.barh(range(len(top20)), top20['composite_score'], color=colors, edgecolor='white')\n",
    "    ax1.set_yticks(range(len(top20)))\n",
    "    ax1.set_yticklabels(top20['strategy_id'].str[:30], fontsize=7)\n",
    "    ax1.set_xlabel('Composite Score')\n",
    "    ax1.set_title('Strategy Rankings (Top 20)', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    # --- Panel 2: Stability diagnostics ---\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    for _, row in top5.iterrows():\n",
    "        sid = row['strategy_id']\n",
    "        fold_data = wf_results[wf_results['strategy_id'] == sid]\n",
    "        if len(fold_data) > 0:\n",
    "            ax2.plot(fold_data['fold_idx'], fold_data['sharpe'],\n",
    "                     'o-', label=sid[:25], linewidth=2, markersize=6)\n",
    "    ax2.axhline(y=0, color='gray', linewidth=0.5, linestyle='--')\n",
    "    ax2.set_xlabel('Fold')\n",
    "    ax2.set_ylabel('Sharpe Ratio')\n",
    "    ax2.set_title('Stability: Sharpe Across Folds (Top 5)', fontweight='bold')\n",
    "    ax2.legend(fontsize=7)\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "    # --- Panel 3: Equity curves ---\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "    valid_data = feature_panel.dropna(subset=['fwd_return']).copy()\n",
    "\n",
    "    for _, row in top5.iterrows():\n",
    "        sid = row['strategy_id']\n",
    "        # Build cumulative PnL from walk-forward test periods\n",
    "        fold_data = wf_results[wf_results['strategy_id'] == sid].sort_values('fold_idx')\n",
    "        if len(fold_data) > 0:\n",
    "            cum_ret = np.cumsum(fold_data['mean_return'].values)\n",
    "            ax3.plot(range(len(cum_ret)), cum_ret, 'o-', label=sid[:25], linewidth=2)\n",
    "\n",
    "    ax3.axhline(y=0, color='gray', linewidth=0.5, linestyle='--')\n",
    "    ax3.set_xlabel('Walk-Forward Fold')\n",
    "    ax3.set_ylabel('Cumulative Return')\n",
    "    ax3.set_title('Equity Curves (Top 5)', fontweight='bold')\n",
    "    ax3.legend(fontsize=7)\n",
    "    ax3.grid(alpha=0.3)\n",
    "\n",
    "    # --- Panel 4: Portfolio combination ---\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "    # Equal-weight portfolio of top 5\n",
    "    top5_ids = top5['strategy_id'].tolist()\n",
    "    portfolio_fold_data = wf_results[wf_results['strategy_id'].isin(top5_ids)]\n",
    "\n",
    "    if len(portfolio_fold_data) > 0:\n",
    "        portfolio_returns = portfolio_fold_data.groupby('fold_idx')['mean_return'].mean()\n",
    "        cum_portfolio = np.cumsum(portfolio_returns.values)\n",
    "\n",
    "        # Compare with best single strategy\n",
    "        best_sid = top5.iloc[0]['strategy_id']\n",
    "        best_fold = wf_results[wf_results['strategy_id'] == best_sid].sort_values('fold_idx')\n",
    "        cum_best = np.cumsum(best_fold['mean_return'].values)\n",
    "\n",
    "        ax4.plot(range(len(cum_portfolio)), cum_portfolio, 'b-', linewidth=2.5,\n",
    "                 label='Equal-Weight Portfolio (Top 5)')\n",
    "        ax4.plot(range(len(cum_best)), cum_best, 'r--', linewidth=1.5,\n",
    "                 label='Best Single: %s' % best_sid[:20])\n",
    "        ax4.fill_between(range(len(cum_portfolio)), 0, cum_portfolio,\n",
    "                         where=np.array(cum_portfolio) > 0, alpha=0.1, color='blue')\n",
    "\n",
    "        # Portfolio stats\n",
    "        port_sharpe = (\n",
    "            portfolio_returns.mean() / portfolio_returns.std() * np.sqrt(252 / 21)\n",
    "            if portfolio_returns.std() > 1e-8 else 0\n",
    "        )\n",
    "        ax4.text(0.05, 0.95,\n",
    "                 'Portfolio Sharpe: %.2f\\nTotal Return: %.2f%%' % (\n",
    "                     port_sharpe, cum_portfolio[-1] * 100),\n",
    "                 transform=ax4.transAxes, fontsize=9, verticalalignment='top',\n",
    "                 bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "    ax4.axhline(y=0, color='gray', linewidth=0.5, linestyle='--')\n",
    "    ax4.set_xlabel('Walk-Forward Fold')\n",
    "    ax4.set_ylabel('Cumulative Return')\n",
    "    ax4.set_title('Portfolio Combination', fontweight='bold')\n",
    "    ax4.legend(fontsize=8)\n",
    "    ax4.grid(alpha=0.3)\n",
    "\n",
    "    fig.suptitle('Quantitative Research Pipeline — Final Results',\n",
    "                 fontsize=16, fontweight='bold', y=1.01)\n",
    "    plt.savefig(os.path.join(CFG.drive_root, 'pipeline_results.png'),\n",
    "                dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Dashboard saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final Summary ===\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "tracker.summary()\n",
    "\n",
    "if len(scored_strategies) > 0:\n",
    "    print(\"\\n=== Top Strategy ===\")\n",
    "    best = scored_strategies.iloc[0]\n",
    "    print(\"  ID:           %s\" % best['strategy_id'])\n",
    "    print(\"  Composite:    %.4f\" % best['composite_score'])\n",
    "    print(\"  Stability:    %.2f\" % best['stability'])\n",
    "    print(\"  Sharpe:       %.2f\" % best['mean_sharpe'])\n",
    "    print(\"  Win Rate:     %.2f%%\" % (best['mean_win_rate'] * 100))\n",
    "    print(\"  Total Trades: %d\" % best['total_trades'])\n",
    "\n",
    "    print(\"\\n=== Portfolio (EW Top 5) ===\")\n",
    "    top5_ids = scored_strategies.head(5)['strategy_id'].tolist()\n",
    "    port_folds = wf_results[wf_results['strategy_id'].isin(top5_ids)]\n",
    "    if len(port_folds) > 0:\n",
    "        port_ret = port_folds.groupby('fold_idx')['mean_return'].mean()\n",
    "        print(\"  Mean Return:  %.4f\" % port_ret.mean())\n",
    "        port_s = port_ret.mean() / port_ret.std() * np.sqrt(252 / 21) if port_ret.std() > 1e-8 else 0\n",
    "        print(\"  Sharpe:       %.2f\" % port_s)\n",
    "        print(\"  Win Folds:    %d/%d\" % ((port_ret > 0).sum(), len(port_ret)))\n",
    "\n",
    "    # Save final report\n",
    "    report = {\n",
    "        \"pipeline_complete\": True,\n",
    "        \"n_tickers\": len(valid_tickers),\n",
    "        \"n_candidates_total\": len(all_candidates),\n",
    "        \"n_evaluated\": len(edge_results),\n",
    "        \"n_walk_forward\": len(wf_results),\n",
    "        \"n_filtered\": len(filtered_strategies),\n",
    "        \"n_scored\": len(scored_strategies),\n",
    "        \"top_strategy\": best['strategy_id'],\n",
    "        \"top_composite\": float(best['composite_score']),\n",
    "    }\n",
    "    with open(os.path.join(CFG.drive_root, 'report.json'), 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    print(\"\\nReport saved to: %s\" % os.path.join(CFG.drive_root, 'report.json'))\n",
    "else:\n",
    "    print(\"\\nNo viable strategies found. Consider:\")\n",
    "    print(\"  - Relaxing filter thresholds (min_stability, min_sharpe, min_win_rate)\")\n",
    "    print(\"  - Adding more tickers or longer data period\")\n",
    "    print(\"  - Reducing min_sample_size\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}